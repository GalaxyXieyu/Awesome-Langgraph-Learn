"""
ç®€åŒ–çš„æµ‹è¯• - åªæ˜¾ç¤ºåŸå§‹çš„customæ•°æ®
"""

import asyncio
import time
from graph import create_multi_agent_graph
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import HumanMessage
import json


async def test_raw_custom_stream():
    """æµ‹è¯•åŸå§‹custom streamæ•°æ®"""
    print("ğŸ§ª æµ‹è¯•åŸå§‹Custom Streamæ•°æ®")
    print("="*60)
    
    # åˆ›å»ºå›¾
    checkpointer = InMemorySaver()
    app = create_multi_agent_graph(checkpointer)
    
    # ç®€å•æµ‹è¯•ç”¨ä¾‹
    user_input = "è®¡ç®— 25 * 4 çš„ç»“æœ"
    
    print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
    print("-" * 50)
    print("ğŸ“¡ åŸå§‹Custom Streamæ•°æ®:")
    print("-" * 50)
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=user_input)],
        "user_input": user_input,
        "current_agent": "",
        "execution_path": [],
        "agent_results": {},
        "final_result": "",
        "iteration_count": 0,
        "max_iterations": 2,
        "context": {},
        "error_log": [],
        "supervisor_reasoning": "",
        "next_action": "",
        "task_completed": False
    }
    
    config = {"configurable": {"thread_id": f"test_{int(time.time())}"}}
    
    try:
        # åªä½¿ç”¨customæ¨¡å¼ï¼Œæ‰“å°åŸå§‹æ•°æ®
        async for chunk in app.astream(initial_state, config=config, stream_mode=["custom"]):
            if isinstance(chunk, tuple) and len(chunk) == 2:
                mode, data = chunk
                
                if mode == "custom":
                    # ç›´æ¥æ‰“å°åŸå§‹JSONæ•°æ®
                    print(json.dumps(data, ensure_ascii=False, indent=2))
                    print("---")  # åˆ†éš”ç¬¦
        
        print("âœ… æµ‹è¯•å®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_raw_custom_stream())