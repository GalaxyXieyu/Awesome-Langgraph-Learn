"""
LangGraph Custom Streamå¢å¼ºWriter - ä½¿ç”¨æŒ‡å—å’Œæœ€ä½³å®è·µ
"""

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

å¢å¼ºWriterç³»ç»Ÿè§£å†³äº†LangGraphå¤šæ¨¡å¼æµè¾“å‡ºçš„å¤æ‚æ€§é—®é¢˜ï¼š

### âŒ **ä¹‹å‰çš„é—®é¢˜**
```python
# éœ€è¦å¤„ç†å¤šç§ä¸åŒæ ¼å¼çš„è¾“å‡º
for chunk in app.stream(state, stream_mode=["updates", "messages", "custom"]):
    mode, data = chunk
    if mode == "updates":
        # å¤„ç†èŠ‚ç‚¹æ›´æ–°...
    elif mode == "messages": 
        # å¤„ç†LLM tokenæµ...
    elif mode == "custom":
        # å¤„ç†è‡ªå®šä¹‰æ•°æ®...
```

### âœ… **ç°åœ¨çš„è§£å†³æ–¹æ¡ˆ**
```python
# åªéœ€è¦å¤„ç†ä¸€ç§ç»Ÿä¸€æ ¼å¼
for chunk in app.stream(state, stream_mode=["custom"]):
    mode, unified_message = chunk
    if mode == "custom":
        # æ‰€æœ‰ç±»å‹æ¶ˆæ¯éƒ½æ˜¯ç»Ÿä¸€æ ¼å¼ï¼
        renderer.format_message(unified_message)
```

## ğŸš€ **å¿«é€Ÿå¼€å§‹**

### 1. åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨å¢å¼ºWriter

```python
from enhanced_writer import create_enhanced_writer

async def your_node(state, config=None):
    # åˆ›å»ºwriter
    writer = create_enhanced_writer("your_node", "Your Agent")
    
    # æ­¥éª¤å¼€å§‹
    writer.step_start("å¼€å§‹æ‰§è¡Œä»»åŠ¡")
    
    # è¿›åº¦æ›´æ–°
    writer.step_progress("æ­£åœ¨å¤„ç†...", 50)
    
    # AIæµå¼è¾“å‡º
    for i, chunk in enumerate(llm_stream):
        writer.ai_streaming(chunk, i)
    
    # å·¥å…·è°ƒç”¨
    writer.tool_call("calculator", {"expression": "2+3"})
    writer.tool_result("calculator", "5")
    
    # æ­¥éª¤å®Œæˆ
    writer.step_complete("ä»»åŠ¡å®Œæˆ")
    
    return state
```

### 2. å‰ç«¯ç»Ÿä¸€å¤„ç†

```python
class UnifiedRenderer:
    """å‰ç«¯ç»Ÿä¸€æ¶ˆæ¯æ¸²æŸ“å™¨"""
    
    def render_message(self, msg_dict):
        msg_type = msg_dict["message_type"]
        
        if msg_type == "ai_streaming":
            # æµå¼å†…å®¹ä¸æ¢è¡Œ
            print(msg_dict["content"], end='', flush=True)
        elif msg_type == "step_progress":
            # æ˜¾ç¤ºè¿›åº¦æ¡
            progress = msg_dict["metadata"]["progress"]
            print(f"â³ {msg_dict['content']} ({progress}%)")
        elif msg_type == "tool_call":
            # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
            tool_name = msg_dict["metadata"]["tool_name"]
            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
        # ... å…¶ä»–ç±»å‹çš„å¤„ç†
```

## ğŸ“‹ **æ¶ˆæ¯ç±»å‹å®Œæ•´åˆ—è¡¨**

| æ¶ˆæ¯ç±»å‹ | ç”¨é€” | å‰ç«¯å¤„ç†å»ºè®® |
|---------|------|-------------|
| `step_start` | æ­¥éª¤å¼€å§‹ | æ˜¾ç¤ºåŠ è½½çŠ¶æ€ |
| `step_progress` | æ­¥éª¤è¿›åº¦ | æ›´æ–°è¿›åº¦æ¡ |
| `step_complete` | æ­¥éª¤å®Œæˆ | éšè—åŠ è½½çŠ¶æ€ |
| `ai_thinking` | AIæ€è€ƒè¿‡ç¨‹ | æ˜¾ç¤ºæ€è€ƒåŠ¨ç”» |
| `ai_streaming` | AIæµå¼è¾“å‡º | æ‰“å­—æœºæ•ˆæœ |
| `ai_complete` | AIå›å¤å®Œæˆ | åœæ­¢æµå¼åŠ¨ç”» |
| `tool_call` | å·¥å…·è°ƒç”¨ | æ˜¾ç¤ºå·¥å…·å›¾æ ‡ |
| `tool_result` | å·¥å…·ç»“æœ | æ˜¾ç¤ºç»“æœå¡ç‰‡ |
| `agent_switch` | Agentåˆ‡æ¢ | æ˜¾ç¤ºåˆ‡æ¢åŠ¨ç”» |
| `final_result` | æœ€ç»ˆç»“æœ | é«˜äº®æ˜¾ç¤º |
| `error` | é”™è¯¯ä¿¡æ¯ | é”™è¯¯æç¤º |
| `debug` | è°ƒè¯•ä¿¡æ¯ | å¼€å‘æ¨¡å¼æ˜¾ç¤º |

## ğŸ¨ **å‰ç«¯UIå»ºè®®**

### Reactç¤ºä¾‹
```jsx
const MessageRenderer = ({ message }) => {
  const { message_type, content, metadata, timestamp } = message;
  
  switch (message_type) {
    case 'step_start':
      return <div className="step-start">ğŸš€ {content}</div>;
    
    case 'step_progress':
      return (
        <div className="progress-bar">
          <span>â³ {content}</span>
          <div className="bar">
            <div style={{width: `${metadata.progress}%`}} />
          </div>
        </div>
      );
    
    case 'ai_streaming':
      return <span className="streaming-text">{content}</span>;
    
    case 'tool_call':
      return (
        <div className="tool-call">
          ğŸ”§ è°ƒç”¨å·¥å…·: {metadata.tool_name}
          <pre>{JSON.stringify(metadata.tool_args, null, 2)}</pre>
        </div>
      );
    
    case 'final_result':
      return (
        <div className="final-result">
          ğŸ¯ <strong>{content}</strong>
        </div>
      );
    
    default:
      return <div>{content}</div>;
  }
};
```

## ğŸ”§ **é«˜çº§ç”¨æ³•**

### 1. è‡ªå®šä¹‰æ¶ˆæ¯ç±»å‹

```python
# æ‰©å±•MessageTypeæšä¸¾
class CustomMessageType(Enum):
    DATA_ANALYSIS = "data_analysis"
    CHART_GENERATION = "chart_generation"

# åœ¨writerä¸­ä½¿ç”¨
writer._create_unified_message(
    CustomMessageType.DATA_ANALYSIS,
    "æ­£åœ¨åˆ†ææ•°æ®...",
    data_points=1000,
    analysis_type="statistical"
)
```

### 2. æ‰¹é‡æ¶ˆæ¯å¤„ç†

```python
class BatchMessageProcessor:
    def __init__(self):
        self.message_buffer = []
        self.batch_size = 10
    
    def add_message(self, message):
        self.message_buffer.append(message)
        
        if len(self.message_buffer) >= self.batch_size:
            self.flush_batch()
    
    def flush_batch(self):
        # æ‰¹é‡å¤„ç†æ¶ˆæ¯ï¼Œæé«˜æ€§èƒ½
        for msg in self.message_buffer:
            self.process_message(msg)
        self.message_buffer.clear()
```

### 3. æ¶ˆæ¯è¿‡æ»¤å’Œè·¯ç”±

```python
class MessageFilter:
    def __init__(self):
        self.filters = {
            "debug": lambda msg: not self.is_production(),
            "tool_result": lambda msg: len(msg["content"]) < 1000,
            "ai_streaming": lambda msg: self.should_show_streaming()
        }
    
    def should_display(self, message):
        msg_type = message["message_type"]
        filter_func = self.filters.get(msg_type)
        
        if filter_func:
            return filter_func(message)
        
        return True  # é»˜è®¤æ˜¾ç¤º
```

## ğŸ¯ **æœ€ä½³å®è·µ**

### 1. æ€§èƒ½ä¼˜åŒ–
- æµå¼æ¶ˆæ¯ä½¿ç”¨`end=''`é¿å…ä¸å¿…è¦çš„æ¢è¡Œ
- æ‰¹é‡å¤„ç†éå…³é”®æ¶ˆæ¯å‡å°‘UIæ›´æ–°é¢‘ç‡
- é•¿æ–‡æœ¬å†…å®¹è¿›è¡Œæˆªæ–­æ˜¾ç¤º

### 2. ç”¨æˆ·ä½“éªŒ
- ä¸ºä¸åŒç±»å‹æ¶ˆæ¯è®¾ç½®ä¸åŒçš„è§†è§‰æ ·å¼
- ä½¿ç”¨è¿›åº¦æ¡å’ŒåŠ¨ç”»æä¾›åé¦ˆ
- é”™è¯¯æ¶ˆæ¯æä¾›æ˜ç¡®çš„è§£å†³å»ºè®®

### 3. å¼€å‘è°ƒè¯•
- ä¿ç•™æ¶ˆæ¯ç»Ÿè®¡åŠŸèƒ½ç”¨äºæ€§èƒ½åˆ†æ
- ä½¿ç”¨æ—¶é—´æˆ³è¿›è¡Œæ‰§è¡Œæ—¶é—´åˆ†æ
- æä¾›è¯¦ç»†çš„metadataç”¨äºé—®é¢˜æ’æŸ¥

### 4. æ‰©å±•æ€§
- æ¶ˆæ¯ç±»å‹ä½¿ç”¨æšä¸¾ä¾¿äºæ‰©å±•
- Writeræ¥å£ä¿æŒç®€æ´æ˜“ç”¨
- æ”¯æŒè‡ªå®šä¹‰metadataå­—æ®µ

## ğŸ” **ç›‘æ§å’Œåˆ†æ**

```python
class MessageAnalyzer:
    def __init__(self):
        self.stats = defaultdict(int)
        self.timings = defaultdict(list)
    
    def analyze_message(self, message):
        msg_type = message["message_type"]
        timestamp = message["timestamp"]
        
        # ç»Ÿè®¡æ¶ˆæ¯æ•°é‡
        self.stats[msg_type] += 1
        
        # è®°å½•æ—¶é—´
        if msg_type == "step_complete":
            duration = message["metadata"].get("duration", 0)
            self.timings[message["node_name"]].append(duration)
    
    def get_performance_report(self):
        return {
            "message_counts": dict(self.stats),
            "average_step_times": {
                node: sum(times) / len(times) 
                for node, times in self.timings.items()
            }
        }
```

è¿™ä¸ªå¢å¼ºWriterç³»ç»Ÿè®©ä½ çš„å‰ç«¯å¼€å‘å˜å¾—æå…¶ç®€å• - åªéœ€è¦å¤„ç†ä¸€ç§ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼ï¼Œå°±èƒ½å®Œç¾å±•ç¤ºæ‰€æœ‰ç±»å‹çš„agentè¾“å‡ºï¼