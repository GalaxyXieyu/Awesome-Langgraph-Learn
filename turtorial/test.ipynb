{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a746cb06",
   "metadata": {},
   "source": [
    "# Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e916bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------大纲生成节点---------------\n",
      "True\n",
      "---------------大纲生成节点---------------\n",
      "('updates', {'__interrupt__': (Interrupt(value={'question': '是否重新开始？', 'llm_output': 0}, id='4b8f8e6397d1ca73abe9b04429447bdb'),)})\n",
      "---------------用户同意---------------\n",
      "---------------大纲生成节点---------------\n",
      "True\n",
      "---------------大纲生成节点---------------\n",
      "---------------中断完成---------------\n",
      "False\n",
      "---------------中断完成---------------\n",
      "('updates', {'human_approval': None})\n",
      "('updates', {'__interrupt__': (Interrupt(value={'text_to_revise': 0}, id='1e9217035bc65f6fd7341f2ceaa6e6e5'),)})\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict\n",
    "import uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "class State(TypedDict):\n",
    "    llm_output: int\n",
    "\n",
    "\n",
    "\n",
    "async def human_approval(state: State) -> Command[Literal[\"human_node_1\", \"human_node_2\"]]:\n",
    "    is_approved = True\n",
    "    llm_output = 0\n",
    "    print(\"---------------大纲生成节点---------------\")\n",
    "    print(is_approved)\n",
    "    print(\"---------------大纲生成节点---------------\")\n",
    "    while is_approved:\n",
    "        llm_output = state[\"llm_output\"] + 1\n",
    "        is_approved = interrupt(\n",
    "            {\n",
    "                \"question\": \"是否重新开始？\",\n",
    "                # Surface the output that should be\n",
    "                # reviewed and approved by the human.\n",
    "                \"llm_output\": state[\"llm_output\"]\n",
    "            }\n",
    "        )\n",
    "        print(\"---------------中断完成---------------\")\n",
    "        print(is_approved)\n",
    "        print(\"---------------中断完成---------------\")\n",
    "    return Command(goto=\"human_node_1\")\n",
    "\n",
    "\n",
    "async def human_node_1(state: State):\n",
    "    value = interrupt({\"text_to_revise\": state[\"llm_output\"]})\n",
    "    return {\"llm_output\": value}\n",
    "\n",
    "\n",
    "async def human_node_2(state: State):\n",
    "    value = interrupt({\"text_to_revise\": state[\"llm_output\"]})\n",
    "    return {\"llm_output\": value}\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_edge(START, \"human_approval\")\n",
    "graph_builder.add_node(\"human_approval\", human_approval)\n",
    "graph_builder.add_node(\"human_node_1\", human_node_1)\n",
    "graph_builder.add_node(\"human_node_2\", human_node_2)\n",
    "graph_builder.add_edge(\"human_node_1\", END)\n",
    "graph_builder.add_edge(\"human_node_2\", END)\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# After running the graph and hitting the interrupt, the graph will pause.\n",
    "# Resume it with either an approval or rejection.\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"7\"}}\n",
    "async for chunk in graph.astream({\"llm_output\": 0}, config=thread_config,stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)\n",
    "print(\"---------------用户同意---------------\")\n",
    "async for chunk in graph.astream(Command(resume=False), config=thread_config,stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bdc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------大纲生成节点---------------\n",
      "1\n",
      "---------------大纲生成节点---------------\n",
      "---------------中断完成---------------\n",
      "True\n",
      "---------------中断完成---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 0,\n",
       " '__interrupt__': [Interrupt(value={'question': '是否重新开始？', 'llm_output': 0}, id='cc1af7b8ec4941cda5da6b553ee6e141')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa040c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------大纲生成节点---------------\n",
      "1\n",
      "---------------大纲生成节点---------------\n",
      "---------------中断完成---------------\n",
      "True\n",
      "---------------中断完成---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 0,\n",
       " '__interrupt__': [Interrupt(value={'question': '是否重新开始？', 'llm_output': 0}, id='cc1af7b8ec4941cda5da6b553ee6e141')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf2f96b",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from typing import Dict, Any, cast\n",
    "from graph import create_writing_assistant_graph\n",
    "from tools import load_knowledge_bases\n",
    "from langgraph.types import Command\n",
    "\n",
    "initial_state = {\n",
    "    \"topic\": \"Python异步编程最佳实践\",\n",
    "    \"user_id\": \"complete_streaming_test\",\n",
    "    \"max_words\": 600,\n",
    "    \"style\": \"technical\",\n",
    "    \"language\": \"zh\"\n",
    "}\n",
    "config: Dict[str, Any] = {\"configurable\": {\"thread_id\": \"complete_streaming_004\"}}\n",
    "\n",
    "\n",
    "# 生成大纲\n",
    "graph = create_writing_assistant_graph()\n",
    "async for chunk in graph.astream(initial_state, cast(Any, config), stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e505133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认大纲\n",
    "async for chunk in graph.astream(Command(goto=\"rag_enhancement\"), cast(Any, config), stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认搜索知识库\n",
    "async for chunk in graph.astream(Command(resume=\"yes\"), cast(Any, config), stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9210a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认联网搜索并开始生成\n",
    "async for chunk in graph.astream(Command(resume=\"yes\"), cast(Any, config), stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e21cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------大纲生成节点---------------\n",
      "1\n",
      "---------------大纲生成节点---------------\n",
      "---------------中断完成---------------\n",
      "True\n",
      "---------------中断完成---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 0,\n",
       " '__interrupt__': [Interrupt(value={'question': '是否重新开始？', 'llm_output': 0}, id='cc1af7b8ec4941cda5da6b553ee6e141')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
