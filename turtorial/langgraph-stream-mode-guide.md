# LangGraph Tasks Stream Mode æ·±åº¦è§£æ

## ğŸ“‹ æ¦‚è¿°

`tasks` æ˜¯ LangGraph æä¾›çš„ä¸€ç§é«˜çº§ stream mode,ç”¨äº**åœ¨ä»»åŠ¡çº§åˆ«è¿½è¸ªå·¥ä½œæµçš„æ‰§è¡ŒçŠ¶æ€**ã€‚æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æå…¶åŠŸèƒ½ã€ä½¿ç”¨åœºæ™¯ä»¥åŠä¸é¡¹ç›®ä¸­ä¸‰æ®µå¼ Writer çš„å¯¹æ¯”ã€‚

---

## ğŸ¯ Tasks Stream Mode æ ¸å¿ƒæ¦‚å¿µ

### å®šä¹‰

æ ¹æ® LangGraph å®˜æ–¹æ–‡æ¡£ï¼š

> **"tasks"**: Emit events when tasks start and finish, including their results and errors.

### å…³é”®ç‰¹æ€§

`tasks` stream mode ä¼šåœ¨ä»¥ä¸‹æ—¶æœºå‘é€äº‹ä»¶ï¼š

1. âœ… **ä»»åŠ¡å¼€å§‹** (Task Start)
2. âœ… **ä»»åŠ¡å®Œæˆ** (Task Finish)
3. âœ… **åŒ…å«ç»“æœ** (Results)
4. âœ… **åŒ…å«é”™è¯¯** (Errors)

---

## ğŸ“Š Tasks Mode è¯¦ç»†åˆ†æ

### 1. äº‹ä»¶ç»“æ„

`tasks` æ¨¡å¼è¾“å‡ºçš„äº‹ä»¶åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

```python
# ä»»åŠ¡å¼€å§‹äº‹ä»¶
{
    "event": "task_start",
    "name": "node_name",        # èŠ‚ç‚¹/ä»»åŠ¡åç§°
    "task_id": "uuid",          # ä»»åŠ¡å”¯ä¸€æ ‡è¯†
    "timestamp": "iso8601",     # å¼€å§‹æ—¶é—´æˆ³
    "metadata": {...}           # å…ƒæ•°æ®
}

# ä»»åŠ¡å®Œæˆäº‹ä»¶
{
    "event": "task_finish",
    "name": "node_name",
    "task_id": "uuid",
    "timestamp": "iso8601",
    "result": {...},            # ä»»åŠ¡æ‰§è¡Œç»“æœ
    "error": null,              # å¦‚æœæˆåŠŸï¼Œerror ä¸º null
    "duration": 1.23            # æ‰§è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
}

# ä»»åŠ¡é”™è¯¯äº‹ä»¶
{
    "event": "task_finish",
    "name": "node_name",
    "task_id": "uuid",
    "timestamp": "iso8601",
    "result": null,
    "error": {                  # é”™è¯¯ä¿¡æ¯
        "type": "ErrorType",
        "message": "Error description",
        "traceback": "..."
    }
}
```

---

### 2. ä½¿ç”¨ç¤ºä¾‹

#### åŸºç¡€ç”¨æ³•

```python
from langgraph.graph import StateGraph, START, END

# å®šä¹‰ graph
graph = StateGraph(State)
graph.add_node("planning", planning_node)
graph.add_node("searching", searching_node)
graph.add_node("analyzing", analyzing_node)
# ... æ·»åŠ è¾¹

compiled = graph.compile()

# ä½¿ç”¨ tasks stream mode
async for event in compiled.astream(
    input_data,
    stream_mode="tasks"  # å…³é”®å‚æ•°
):
    print(event)
```

#### è¾“å‡ºç¤ºä¾‹

```python
# 1. Planning ä»»åŠ¡å¼€å§‹
{
    'event': 'task_start',
    'name': 'planning',
    'task_id': 'planning:abc123',
    'timestamp': '2025-10-13T10:00:00.000Z'
}

# 2. Planning ä»»åŠ¡å®Œæˆ
{
    'event': 'task_finish',
    'name': 'planning',
    'task_id': 'planning:abc123',
    'timestamp': '2025-10-13T10:00:05.000Z',
    'result': {
        'plan_data': {...},
        'tasks': [...]
    },
    'error': None,
    'duration': 5.0
}

# 3. Searching ä»»åŠ¡å¼€å§‹
{
    'event': 'task_start',
    'name': 'searching',
    'task_id': 'searching:def456',
    'timestamp': '2025-10-13T10:00:05.100Z'
}

# 4. Searching ä»»åŠ¡å®Œæˆ
{
    'event': 'task_finish',
    'name': 'searching',
    'task_id': 'searching:def456',
    'timestamp': '2025-10-13T10:00:12.000Z',
    'result': {
        'search_results': {...}
    },
    'error': None,
    'duration': 6.9
}
```

---

### 3. ä¸å…¶ä»– Stream Modes å¯¹æ¯”

| ç‰¹æ€§ | tasks | updates | values | custom |
|------|-------|---------|--------|--------|
| **ç²’åº¦** | ä»»åŠ¡çº§ | èŠ‚ç‚¹çº§ | å®Œæ•´çŠ¶æ€ | è‡ªå®šä¹‰ |
| **å¼€å§‹äº‹ä»¶** | âœ… | âŒ | âŒ | âš ï¸ æ‰‹åŠ¨ |
| **ç»“æŸäº‹ä»¶** | âœ… | âŒ | âŒ | âš ï¸ æ‰‹åŠ¨ |
| **æ‰§è¡Œæ—¶é•¿** | âœ… | âŒ | âŒ | âŒ |
| **é”™è¯¯æ•è·** | âœ… | âš ï¸ | âš ï¸ | âš ï¸ æ‰‹åŠ¨ |
| **ç»“æœæ•°æ®** | âœ… | âœ… | âœ… | âš ï¸ æ‰‹åŠ¨ |
| **ä¸šåŠ¡è¯­ä¹‰** | âš ï¸ æœ‰é™ | âš ï¸ æœ‰é™ | âŒ | âœ… å®Œå…¨ |

---

## ğŸ” Tasks Mode çš„ç‹¬ç‰¹ä»·å€¼

### 1. è‡ªåŠ¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª

ä¸ `updates` æ¨¡å¼ä¸åŒï¼Œ`tasks` æ¨¡å¼**è‡ªåŠ¨æä¾›å¼€å§‹å’Œç»“æŸäº‹ä»¶**ï¼š

```python
# updates æ¨¡å¼ - ä»…åœ¨èŠ‚ç‚¹å®Œæˆåè¾“å‡º
async for chunk in graph.astream(input, stream_mode="updates"):
    print(chunk)
    # {'planning': {'plan_data': {...}}}  # åªæœ‰ç»“æœ

# tasks æ¨¡å¼ - å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_start':
        print(f"å¼€å§‹: {event['name']}")
    elif event['event'] == 'task_finish':
        print(f"å®Œæˆ: {event['name']}, è€—æ—¶: {event['duration']}s")
```

### 2. å†…ç½®é”™è¯¯å¤„ç†

```python
async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_finish':
        if event['error']:
            # è‡ªåŠ¨æ•è·å¹¶ç»“æ„åŒ–é”™è¯¯ä¿¡æ¯
            print(f"ä»»åŠ¡å¤±è´¥: {event['name']}")
            print(f"é”™è¯¯ç±»å‹: {event['error']['type']}")
            print(f"é”™è¯¯ä¿¡æ¯: {event['error']['message']}")
        else:
            print(f"ä»»åŠ¡æˆåŠŸ: {event['name']}")
```

### 3. æ€§èƒ½ç›‘æ§

```python
# æ”¶é›†æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é•¿
durations = {}

async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_finish':
        durations[event['name']] = event['duration']

# åˆ†ææ€§èƒ½ç“¶é¢ˆ
slowest = max(durations.items(), key=lambda x: x[1])
print(f"æœ€æ…¢çš„èŠ‚ç‚¹: {slowest[0]}, è€—æ—¶: {slowest[1]}s")
```

---

## ğŸ¤” Tasks Mode ä¸ä¸‰æ®µå¼ Writer å¯¹æ¯”

### ç›¸ä¼¼ä¹‹å¤„

| åŠŸèƒ½ | Tasks Mode | ä¸‰æ®µå¼ Writer |
|------|-----------|---------------|
| **å¼€å§‹ä¿¡å·** | âœ… task_start | âœ… status="start" |
| **ç»“æŸä¿¡å·** | âœ… task_finish | âœ… status="end" |
| **æ‰§è¡ŒçŠ¶æ€** | âœ… start/finish | âœ… start/processing/end |

### å…³é”®å·®å¼‚

#### 1. **è¯­ä¹‰å±‚çº§**

**Tasks Mode**:
- å…³æ³¨**èŠ‚ç‚¹/ä»»åŠ¡çº§åˆ«**çš„æ‰§è¡Œ
- ç¼ºå°‘ä¸šåŠ¡è¯­ä¹‰ï¼ˆthinking/tool_call/plan ç­‰ï¼‰
- é€‚åˆç³»ç»Ÿçº§ç›‘æ§

**ä¸‰æ®µå¼ Writer**:
- å…³æ³¨**ä¸šåŠ¡æ¶ˆæ¯çº§åˆ«**çš„è¾“å‡º
- ä¸°å¯Œçš„æ¶ˆæ¯ç±»å‹åˆ†ç±»
- é€‚åˆç”¨æˆ·ç•Œé¢å±•ç¤º

#### 2. **ä¸­é—´çŠ¶æ€**

**Tasks Mode**:
```python
# åªæœ‰ start å’Œ finish
task_start â†’ task_finish
```

**ä¸‰æ®µå¼ Writer**:
```python
# æ”¯æŒå¤šæ¬¡ processing
start â†’ processing â†’ processing â†’ processing â†’ end
         (seq=1)      (seq=2)      (seq=3)
```

#### 3. **æ¶ˆæ¯ç±»å‹**

**Tasks Mode**:
```python
# ç»Ÿä¸€çš„äº‹ä»¶ç»“æ„
{
    'event': 'task_finish',
    'name': 'searching',
    'result': {...}  # åŸå§‹èŠ‚ç‚¹è¿”å›å€¼
}
```

**ä¸‰æ®µå¼ Writer**:
```python
# å¤šæ ·åŒ–çš„æ¶ˆæ¯ç±»å‹
{
    'message_type': 'search',  # è¯­ä¹‰åŒ–ç±»å‹
    'status': 'end',
    'data': {
        'query': [...],
        'results': {...},
        'results_count': 10
    }
}
```

---

## ğŸ’¡ Tasks Mode çš„æœ€ä½³ä½¿ç”¨åœºæ™¯

### âœ… é€‚åˆçš„åœºæ™¯

#### 1. ç³»ç»Ÿæ€§èƒ½ç›‘æ§

```python
# ç›‘æ§æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é•¿
async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_finish':
        # è®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
        monitor.record_duration(
            node=event['name'],
            duration=event['duration']
        )
```

#### 2. é”™è¯¯è¿½è¸ªä¸æŠ¥è­¦

```python
async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_finish' and event['error']:
        # å‘é€æŠ¥è­¦
        alert_system.send_alert(
            severity="error",
            node=event['name'],
            error_type=event['error']['type'],
            traceback=event['error']['traceback']
        )
```

#### 3. è¿›åº¦æ¡å®ç°ï¼ˆç®€å•åœºæ™¯ï¼‰

```python
total_tasks = 5  # planning, searching, analyzing, coding, writing
completed = 0

async for event in graph.astream(input, stream_mode="tasks"):
    if event['event'] == 'task_finish':
        completed += 1
        progress = int((completed / total_tasks) * 100)
        print(f"è¿›åº¦: {progress}%")
```

### âŒ ä¸é€‚åˆçš„åœºæ™¯

#### 1. å¤æ‚çš„ç”¨æˆ·ç•Œé¢åé¦ˆ

```python
# Tasks Mode ç¼ºå°‘ä¸šåŠ¡è¯­ä¹‰
{
    'event': 'task_finish',
    'name': 'analyzing',
    'result': {'analysis_data': {...}}
}

# å‰ç«¯éœ€è¦æ‰‹åŠ¨è§£æå’Œåˆ†ç±»
# è€Œ Writer ç›´æ¥æä¾›:
{
    'message_type': 'content',  # æ˜ç¡®çš„ç±»å‹
    'format': {'type': 'markdown'},
    'content': '## åˆ†æç»“æœ\n...'
}
```

#### 2. æµå¼ LLM è¾“å‡º

```python
# Tasks Mode åªåœ¨ä»»åŠ¡ç»“æŸæ—¶è¾“å‡ºå®Œæ•´ç»“æœ
# æ— æ³•å®ç°é€ token æµå¼æ˜¾ç¤º

# éœ€è¦ä½¿ç”¨ messages mode æˆ– custom mode (Writer)
```

#### 3. å·¥å…·è°ƒç”¨æµç¨‹å±•ç¤º

```python
# Tasks Mode æ— æ³•åŒºåˆ†å·¥å…·è°ƒç”¨å’Œå·¥å…·ç»“æœ
# Writer æä¾›ä¸“é—¨çš„ tool_call å’Œ tool_result ç±»å‹
```

---

## ğŸ”„ æ··åˆä½¿ç”¨ç­–ç•¥

### æ¨èç»„åˆï¼štasks + custom

```python
async for stream_mode, chunk in graph.astream(
    input,
    stream_mode=["tasks", "custom"]  # ç»„åˆä½¿ç”¨
):
    if stream_mode == "tasks":
        # ç”¨äºç³»ç»Ÿç›‘æ§
        if chunk['event'] == 'task_start':
            monitor.start_timer(chunk['task_id'])
        elif chunk['event'] == 'task_finish':
            monitor.end_timer(
                task_id=chunk['task_id'],
                duration=chunk['duration'],
                error=chunk['error']
            )
    
    elif stream_mode == "custom":
        # ç”¨äºç”¨æˆ·ç•Œé¢
        # Writer å‘å‡ºçš„ä¸šåŠ¡æ¶ˆæ¯
        yield chunk  # ç›´æ¥è½¬å‘ç»™å‰ç«¯
```

---

## ğŸ“ˆ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1: è‡ªåŠ¨è¿›åº¦è¿½è¸ªå¢å¼º

```python
# åœ¨ GraphWrapper ä¸­å¢å¼ºè¿›åº¦è¿½è¸ª

async def _execute_stream(self, input_data, thread_id, user_id):
    stream = app.astream(
        state,
        config=run_config,
        stream_mode=["custom", "tasks"]  # ç»„åˆä½¿ç”¨
    )
    
    task_registry = {}  # è¿½è¸ªä»»åŠ¡çŠ¶æ€
    
    async for mode, chunk in stream:
        if mode == "tasks":
            # è‡ªåŠ¨è®°å½•ä»»åŠ¡æ‰§è¡Œä¿¡æ¯
            if chunk['event'] == 'task_start':
                task_registry[chunk['task_id']] = {
                    'name': chunk['name'],
                    'start_time': chunk['timestamp'],
                    'status': 'running'
                }
            
            elif chunk['event'] == 'task_finish':
                task_info = task_registry.get(chunk['task_id'], {})
                task_info.update({
                    'status': 'completed' if not chunk['error'] else 'failed',
                    'end_time': chunk['timestamp'],
                    'duration': chunk['duration'],
                    'error': chunk['error']
                })
                
                # è‡ªåŠ¨æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€
                await self.repository.update_task_node_status(
                    task_id=thread_id,
                    node_name=chunk['name'],
                    status=task_info['status'],
                    duration=chunk['duration']
                )
        
        elif mode == "custom":
            # Writer çš„æ¶ˆæ¯ï¼Œæ­£å¸¸è½¬å‘
            yield chunk
```

### æ¡ˆä¾‹ 2: æ€§èƒ½åˆ†æä»ªè¡¨æ¿

```python
class PerformanceAnalyzer:
    def __init__(self):
        self.metrics = {
            'node_durations': {},
            'error_counts': {},
            'total_runs': 0
        }
    
    async def analyze_run(self, graph, input_data):
        """åˆ†æå•æ¬¡è¿è¡Œçš„æ€§èƒ½"""
        node_timings = []
        
        async for event in graph.astream(
            input_data,
            stream_mode="tasks"
        ):
            if event['event'] == 'task_finish':
                node_timings.append({
                    'node': event['name'],
                    'duration': event['duration'],
                    'error': bool(event['error'])
                })
        
        return self._generate_report(node_timings)
    
    def _generate_report(self, timings):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        total_time = sum(t['duration'] for t in timings)
        
        return {
            'total_duration': total_time,
            'node_breakdown': {
                t['node']: {
                    'duration': t['duration'],
                    'percentage': (t['duration'] / total_time) * 100
                }
                for t in timings
            },
            'bottleneck': max(timings, key=lambda x: x['duration'])['node']
        }
```

### æ¡ˆä¾‹ 3: æ™ºèƒ½é™çº§ç­–ç•¥

```python
async def execute_with_fallback(graph, input_data):
    """åŸºäº tasks æ¨¡å¼çš„æ™ºèƒ½é™çº§"""
    failed_nodes = set()
    
    async for event in graph.astream(
        input_data,
        stream_mode="tasks"
    ):
        if event['event'] == 'task_finish' and event['error']:
            failed_nodes.add(event['name'])
            
            # æ ¹æ®å¤±è´¥çš„èŠ‚ç‚¹åŠ¨æ€è°ƒæ•´ç­–ç•¥
            if event['name'] == 'searching':
                print("æœç´¢å¤±è´¥ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®")
                # è§¦å‘é™çº§é€»è¾‘
            
            elif event['name'] == 'analyzing':
                print("åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–åˆ†æ")
                # ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ³•
```

---

## ğŸ¯ ä¸é¡¹ç›®æ•´åˆå»ºè®®

### çŸ­æœŸå»ºè®®ï¼ˆä¸ç ´åç°æœ‰æ¶æ„ï¼‰

#### 1. åœ¨ GraphWrapper ä¸­æ·»åŠ  tasks æ¨¡å¼æ”¯æŒ

```python
# src/infrastructure/ai/graph/wrapper.py

async def _execute_stream(self, input_data, thread_id, user_id):
    # é»˜è®¤ä½¿ç”¨ custom + tasks ç»„åˆ
    stream = app.astream(
        state,
        config=run_config,
        stream_mode=["custom", "tasks"]  # æ–°å¢ tasks
    )
    
    async for mode, chunk in stream:
        if mode == "custom":
            # ç°æœ‰çš„ Writer æ¶ˆæ¯
            yield chunk
        
        elif mode == "tasks":
            # æ–°å¢ï¼šè‡ªåŠ¨è®°å½•æ€§èƒ½æ•°æ®
            await self._handle_task_event(chunk, thread_id)
```

#### 2. æ·»åŠ æ€§èƒ½ç›‘æ§

```python
async def _handle_task_event(self, event, task_id):
    """å¤„ç† tasks æ¨¡å¼äº‹ä»¶"""
    if event['event'] == 'task_finish':
        # è®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
        await self.monitor.record_node_execution(
            task_id=task_id,
            node_name=event['name'],
            duration=event['duration'],
            success=not event['error']
        )
```

### ä¸­æœŸå»ºè®®ï¼ˆå¢å¼ºåŠŸèƒ½ï¼‰

#### 1. è‡ªåŠ¨è¿›åº¦æ¨æ–­

```python
# Writer å¯ä»¥åˆ©ç”¨ tasks äº‹ä»¶è‡ªåŠ¨æ›´æ–°è¿›åº¦
class StreamWriter:
    def _auto_update_progress_from_tasks(self, task_event):
        """ä» tasks äº‹ä»¶è‡ªåŠ¨æ›´æ–°è¿›åº¦"""
        if task_event['event'] == 'task_finish':
            # è‡ªåŠ¨æ¨æ–­ä»»åŠ¡å®Œæˆï¼Œæ›´æ–° plan
            self.plan(
                tasks=self._infer_tasks_from_nodes(),
                current_task_id=task_event['name'],
                overall_progress=self._calculate_progress()
            )
```

#### 2. é”™è¯¯è‡ªåŠ¨æ¢å¤

```python
async def execute_with_retry(graph, input_data):
    """åŸºäº tasks æ¨¡å¼çš„è‡ªåŠ¨é‡è¯•"""
    max_retries = 3
    retry_count = {}
    
    async for event in graph.astream(
        input_data,
        stream_mode="tasks"
    ):
        if event['event'] == 'task_finish' and event['error']:
            node_name = event['name']
            retry_count[node_name] = retry_count.get(node_name, 0) + 1
            
            if retry_count[node_name] < max_retries:
                # è§¦å‘é‡è¯•
                print(f"èŠ‚ç‚¹ {node_name} å¤±è´¥ï¼Œç¬¬ {retry_count[node_name]} æ¬¡é‡è¯•")
```

### é•¿æœŸå»ºè®®ï¼ˆæ¶æ„ä¼˜åŒ–ï¼‰

#### 1. ç»Ÿä¸€äº‹ä»¶ç³»ç»Ÿ

```python
# åˆ›å»ºç»Ÿä¸€çš„äº‹ä»¶è½¬æ¢å±‚
class EventAdapter:
    """å°† tasks äº‹ä»¶è½¬æ¢ä¸º Writer æ ¼å¼"""
    
    def adapt_task_start(self, task_event):
        """task_start â†’ Writer start æ¶ˆæ¯"""
        return {
            'message_type': 'processing',
            'status': 'start',
            'node': task_event['name'],
            'timestamp': task_event['timestamp'],
            'data': {
                'task_id': task_event['task_id']
            }
        }
    
    def adapt_task_finish(self, task_event):
        """task_finish â†’ Writer end æ¶ˆæ¯"""
        return {
            'message_type': 'processing',
            'status': 'end',
            'node': task_event['name'],
            'timestamp': task_event['timestamp'],
            'data': {
                'duration': task_event['duration'],
                'error': task_event['error']
            }
        }
```

---

## ğŸ“Š æ€»ç»“ä¸å»ºè®®

### âœ… Tasks Mode çš„ä»·å€¼

1. **è‡ªåŠ¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª** - æ— éœ€æ‰‹åŠ¨å‘é€ start/end äº‹ä»¶
2. **å†…ç½®é”™è¯¯å¤„ç†** - è‡ªåŠ¨æ•è·å¹¶ç»“æ„åŒ–é”™è¯¯ä¿¡æ¯
3. **æ€§èƒ½ç›‘æ§** - è‡ªåŠ¨è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é•¿
4. **ç®€åŒ–è¿›åº¦è¿½è¸ª** - èŠ‚ç‚¹çº§åˆ«çš„è¿›åº¦åé¦ˆ

### âš ï¸ Tasks Mode çš„å±€é™

1. **ç¼ºå°‘ä¸šåŠ¡è¯­ä¹‰** - ä¸æ”¯æŒ thinking/tool_call/plan ç­‰åˆ†ç±»
2. **ç²’åº¦å›ºå®š** - åªèƒ½åœ¨èŠ‚ç‚¹çº§åˆ«ï¼Œæ— æ³•ç»†ç²’åº¦æ§åˆ¶
3. **ä¸æ”¯æŒæµå¼** - æ— æ³•å®ç° LLM é€ token è¾“å‡º
4. **å‰ç«¯é€‚é…æˆæœ¬** - éœ€è¦é¢å¤–è½¬æ¢ä¸ºä¸šåŠ¡æ¶ˆæ¯

### ğŸ¯ æœ€ç»ˆå»ºè®®

**æ¨èç­–ç•¥**: **ä¿ç•™ä¸‰æ®µå¼ Writer + è¡¥å…… tasks æ¨¡å¼ç”¨äºç›‘æ§**

```python
# æœ€ä½³å®è·µ
stream_mode=["custom", "tasks"]

# custom - ç”¨äºä¸šåŠ¡æ¶ˆæ¯ï¼ˆWriterï¼‰
# tasks  - ç”¨äºç³»ç»Ÿç›‘æ§å’Œæ€§èƒ½åˆ†æ
```

**ä¸æ¨è**: å®Œå…¨æ›¿æ¢ Writer ä¸º tasks æ¨¡å¼
- âŒ ä¼šä¸¢å¤±ä¸šåŠ¡è¯­ä¹‰
- âŒ å‰ç«¯éœ€è¦å¤§é‡é€‚é…
- âŒ æ— æ³•æ”¯æŒå¤æ‚çš„æµå¼åœºæ™¯

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LangGraph Stream Mode è¯¦è§£](./langgraph-stream-mode-guide.md)
- [LangGraph Agents å¼€å‘æŒ‡å—](./langgraph-agents-development-guide.md)
- [Writer æ¨¡å—æ¶æ„è¯´æ˜](../../src/infrastructure/ai/graph/writer/README.md)
- [ä¼˜åŒ–è®°å½•](./optimized.md)

---

## ğŸ”— å‚è€ƒèµ„æº

- [LangGraph Streaming Documentation](https://langchain-ai.github.io/langgraph/how-tos/streaming/)
- [LangGraph Graph Reference](https://langchain-ai.github.io/langgraph/reference/graphs/)
- [LangGraph Python SDK Reference](https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/)

---

**æœ€åæ›´æ–°**: 2025-10-13  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**ä½œè€…**: AutoAgents å›¢é˜Ÿ
