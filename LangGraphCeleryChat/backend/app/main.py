"""
FastAPI ä¸»åº”ç”¨
åŸºäº Celery + Redis çš„ LangGraph å†™ä½œåŠ©æ‰‹ API
"""

import json
import uuid
import logging
import asyncio
from typing import Dict, Any, Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager

# æŠ‘åˆ¶ asyncio çš„ socket.send() è­¦å‘Š
logging.getLogger('asyncio').setLevel(logging.ERROR)

from ..models.schemas import (
    CreateTaskRequest, CreateTaskResponse, TaskStatusResponse,
    InterruptResponseRequest, SessionInfo, ErrorResponse,
    WritingTaskConfig, WritingMode, WritingStyle, TaskStatus,
    ConversationSummary, ResumeValidationResponse, ConversationContext
)
from ..celery_app.tasks import execute_writing_task, resume_writing_task, cancel_writing_task
from ..utils.config import get_config
from ..utils.redis_client import get_redis_client
from ..utils.session_manager import get_session_manager
from ..utils.conversation_service import get_conversation_service
from ..utils.logger import get_logger, setup_logging

# è®¾ç½®æ—¥å¿—
setup_logging()
logger = get_logger(__name__)

# è·å–é…ç½®
config = get_config()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info("å¯åŠ¨ LangGraph Celery Chat API")
    
    # æµ‹è¯• Redis è¿æ¥
    redis_client = get_redis_client()
    if redis_client.ping():
        logger.info("âœ… Redis è¿æ¥æˆåŠŸ")
    else:
        logger.error("âŒ Redis è¿æ¥å¤±è´¥")
    
    yield
    
    # å…³é—­æ—¶
    logger.info("å…³é—­ LangGraph Celery Chat API")
    redis_client.close()


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title=config.app_name,
    version=config.version,
    description="åŸºäº Celery + Redis çš„ LangGraph å†™ä½œåŠ©æ‰‹ API",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=False,  # è®¾ç½®ä¸ºFalseä»¥æ”¯æŒé€šé…ç¬¦
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "LangGraph Celery Chat API",
        "version": config.version,
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    redis_client = get_redis_client()
    redis_status = "ok" if redis_client.ping() else "error"
    
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "redis": redis_status,
            "celery": "ok"  # ç®€åŒ–æ£€æŸ¥
        }
    }


# ============================================================================
# ä¼šè¯ç®¡ç† API
# ============================================================================

@app.post("/api/v1/sessions", response_model=SessionInfo)
async def create_session(user_id: str):
    """åˆ›å»ºæ–°ä¼šè¯"""
    try:
        session_manager = get_session_manager()
        session_id = await session_manager.create_session(user_id)
        
        return SessionInfo(
            session_id=session_id,
            user_id=user_id,
            created_at=datetime.now(),
            last_activity=datetime.now(),
            active_tasks=[]
        )
    except Exception as e:
        logger.error(f"åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/sessions/{session_id}", response_model=SessionInfo)
async def get_session(session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    try:
        session_manager = get_session_manager()
        session_data = await session_manager.get_session(session_id)
        
        if not session_data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        return SessionInfo(**session_data)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/v1/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    try:
        session_manager = get_session_manager()
        success = await session_manager.delete_session(session_id)

        if not success:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        return {"message": "ä¼šè¯å·²åˆ é™¤", "session_id": session_id}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/conversations/{conversation_id}/summary", response_model=ConversationSummary)
async def get_conversation_summary(conversation_id: str):
    """è·å–ä¼šè¯æ‘˜è¦"""
    try:
        conversation_service = get_conversation_service()
        summary = await conversation_service.get_conversation_summary(conversation_id)

        if not summary:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        return ConversationSummary(**summary)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if 'conversation_service' in locals():
            await conversation_service.close()


@app.post("/api/v1/conversations/{conversation_id}/validate-resume", response_model=ResumeValidationResponse)
async def validate_resume_request(conversation_id: str, task_id: Optional[str] = None):
    """éªŒè¯æ¢å¤è¯·æ±‚"""
    try:
        conversation_service = get_conversation_service()
        is_valid, message = await conversation_service.validate_resume_request(conversation_id, task_id)

        # è·å–é¢å¤–ä¿¡æ¯
        conversation_exists = await conversation_service.check_conversation_exists(conversation_id)

        response = ResumeValidationResponse(
            is_valid=is_valid,
            message=message,
            conversation_exists=conversation_exists,
            can_resume=is_valid and conversation_exists
        )

        if not is_valid:
            response.suggested_action = "create_new" if not conversation_exists else "check_task_status"

        return response
    except Exception as e:
        logger.error(f"éªŒè¯æ¢å¤è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if 'conversation_service' in locals():
            await conversation_service.close()


# ============================================================================
# ä»»åŠ¡ç®¡ç† API
# ============================================================================

@app.post("/api/v1/tasks", response_model=CreateTaskResponse)
async def create_task(request: CreateTaskRequest):
    """åˆ›å»ºå†™ä½œä»»åŠ¡ï¼ˆæ”¯æŒä¼šè¯æ¢å¤ï¼‰"""
    try:
        # ä½¿ç”¨ä¼šè¯æœåŠ¡åˆ¤æ–­æ˜¯æ¢å¤è¿˜æ˜¯åˆ›å»º
        conversation_service = get_conversation_service()
        session_id, is_resumed = await conversation_service.should_resume_or_create(
            request.conversation_id,
            request.user_id
        )

        # ç”Ÿæˆä»»åŠ¡ ID
        task_id = f"task_{uuid.uuid4().hex[:8]}"

        # å‡†å¤‡å“åº”æ•°æ®
        response_data = {
            "task_id": task_id,
            "session_id": session_id,
            "status": TaskStatus.PENDING,
            "is_resumed": is_resumed
        }

        # å¦‚æœæ˜¯æ¢å¤æ¨¡å¼ï¼Œè·å–ä¼šè¯ä¸Šä¸‹æ–‡
        if is_resumed:
            logger.info(f"ğŸ”„ æ¢å¤ä¼šè¯æ¨¡å¼: {session_id}")
            context = await conversation_service.prepare_resume_context(session_id)
            response_data["conversation_context"] = context
            response_data["message"] = f"æ¢å¤ä¼šè¯æˆåŠŸï¼Œä¼šè¯ID: {session_id}"
        else:
            logger.info(f"ğŸ“ åˆ›å»ºæ–°ä¼šè¯æ¨¡å¼: {session_id}")
            response_data["message"] = f"åˆ›å»ºæ–°ä»»åŠ¡æˆåŠŸï¼Œä¼šè¯ID: {session_id}"

        # åˆ›å»ºä»»åŠ¡çŠ¶æ€è®°å½•
        session_manager = get_session_manager()
        logger.info(f"æ­£åœ¨åˆ›å»ºä»»åŠ¡çŠ¶æ€è®°å½•: {task_id}")

        success = await session_manager.set_task_status(
            task_id=task_id,
            status="pending",
            user_id=request.user_id,
            session_id=session_id,
            metadata={
                "task_id": task_id,
                "session_id": session_id,
                "user_id": request.user_id,
                "config": request.config.model_dump(),
                "status": "pending",
                "current_step": "initializing",
                "progress": 0,
                "created_at": datetime.now().isoformat(),
                "is_resumed": is_resumed,
                "original_conversation_id": request.conversation_id
            }
        )

        if success:
            logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€è®°å½•åˆ›å»ºæˆåŠŸ: {task_id}")
        else:
            logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€è®°å½•åˆ›å»ºå¤±è´¥: {task_id}")

        # éªŒè¯ä»»åŠ¡çŠ¶æ€æ˜¯å¦çœŸçš„å†™å…¥äº†
        verify_task = await session_manager.get_task_status(task_id)
        if verify_task:
            logger.info(f"âœ… éªŒè¯æˆåŠŸï¼Œä»»åŠ¡çŠ¶æ€å·²å†™å…¥: {task_id}")
        else:
            logger.error(f"âŒ éªŒè¯å¤±è´¥ï¼Œä»»åŠ¡çŠ¶æ€æœªå†™å…¥: {task_id}")

        # å¯åŠ¨ Celery ä»»åŠ¡
        celery_task = execute_writing_task.delay(
            user_id=request.user_id,
            session_id=session_id,
            task_id=task_id,
            config_data=request.config.model_dump(),
            is_resumed=is_resumed,
            original_conversation_id=request.conversation_id
        )

        logger.info(f"åˆ›å»ºå†™ä½œä»»åŠ¡: {task_id}, Celeryä»»åŠ¡: {celery_task.id}")

        return CreateTaskResponse(**response_data)

    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # å…³é—­ä¼šè¯æœåŠ¡è¿æ¥
        if 'conversation_service' in locals():
            await conversation_service.close()


@app.get("/api/v1/tasks/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    try:
        logger.info(f"ğŸ” æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: {task_id}")
        session_manager = get_session_manager()
        task_data = await session_manager.get_task_status(task_id)

        logger.info(f"ğŸ“Š Redis æŸ¥è¯¢ç»“æœ: {task_data}")

        if not task_data:
            logger.warning(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        logger.info(f"âœ… æ‰¾åˆ°ä»»åŠ¡æ•°æ®: {task_id}")
        
        # è§£æä»»åŠ¡æ•°æ®
        metadata = task_data.get("metadata", {})
        result = task_data.get("result", {})

        # å¦‚æœ result æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ JSON
        if isinstance(result, str):
            try:
                import json
                result = json.loads(result)
                logger.info(f"âœ… è§£æ result JSON æˆåŠŸ: {task_id}")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ è§£æ result JSON å¤±è´¥: {task_id}, é”™è¯¯: {e}")
                result = {}

        # å¦‚æœ metadata æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ JSON
        if isinstance(metadata, str):
            try:
                import json
                metadata = json.loads(metadata)
                logger.info(f"âœ… è§£æ metadata JSON æˆåŠŸ: {task_id}")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ è§£æ metadata JSON å¤±è´¥: {task_id}, é”™è¯¯: {e}")
                metadata = {}
        
        return TaskStatusResponse(
            task_id=task_id,
            status=task_data.get("status", "unknown"),
            progress=metadata.get("progress", 0),
            current_step=metadata.get("current_step", "unknown"),
            outline=result.get("outline"),
            article=result.get("article"),
            search_results=result.get("search_results", []),
            created_at=datetime.fromisoformat(metadata.get("created_at", datetime.now().isoformat())),
            updated_at=datetime.fromisoformat(task_data.get("updated_at", datetime.now().isoformat())),
            completed_at=datetime.fromisoformat(result.get("completed_at")) if result.get("completed_at") and isinstance(result.get("completed_at"), str) else None,
            word_count=result.get("word_count", 0),
            generation_time=result.get("generation_time"),
            error_message=task_data.get("error")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/tasks/{task_id}/resume")
async def resume_task(task_id: str, request: InterruptResponseRequest):
    """æ¢å¤ä»»åŠ¡ï¼ˆå“åº”ç”¨æˆ·äº¤äº’ï¼‰"""
    conversation_service = None
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        session_manager = get_session_manager()
        task_data = await session_manager.get_task_status(task_id)

        if not task_data:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        user_id = task_data.get("user_id")
        session_id = task_data.get("session_id")

        if not user_id or not session_id:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡ä¿¡æ¯ä¸å®Œæ•´")

        # ä½¿ç”¨ä¼šè¯æœåŠ¡éªŒè¯æ¢å¤è¯·æ±‚
        conversation_service = get_conversation_service()
        is_valid, validation_message = await conversation_service.validate_resume_request(session_id, task_id)

        if not is_valid:
            raise HTTPException(status_code=400, detail=f"æ¢å¤è¯·æ±‚æ— æ•ˆ: {validation_message}")

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ˜¯å¦æ”¯æŒæ¢å¤
        task_status = task_data.get("status")
        if task_status not in ["paused", "failed"]:
            raise HTTPException(
                status_code=400,
                detail=f"ä»»åŠ¡çŠ¶æ€ä¸æ”¯æŒæ¢å¤: {task_status}ã€‚åªæœ‰æš‚åœæˆ–å¤±è´¥çš„ä»»åŠ¡å¯ä»¥æ¢å¤ã€‚"
            )

        logger.info(f"ğŸ”„ æ¢å¤ä»»åŠ¡éªŒè¯é€šè¿‡: {task_id}, çŠ¶æ€: {task_status}")

        # å¯åŠ¨æ¢å¤ä»»åŠ¡
        celery_task = resume_writing_task.delay(
            user_id=user_id,
            session_id=session_id,
            task_id=task_id,
            user_response=request.model_dump()
        )

        logger.info(f"æ¢å¤å†™ä½œä»»åŠ¡: {task_id}, Celeryä»»åŠ¡: {celery_task.id}")

        return {
            "message": "ä»»åŠ¡å·²æ¢å¤",
            "task_id": task_id,
            "celery_task_id": celery_task.id,
            "session_id": session_id,
            "previous_status": task_status
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if conversation_service:
            await conversation_service.close()


@app.delete("/api/v1/tasks/{task_id}")
async def cancel_task(task_id: str):
    """å–æ¶ˆä»»åŠ¡"""
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        session_manager = get_session_manager()
        task_data = await session_manager.get_task_status(task_id)
        
        if not task_data:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        user_id = task_data.get("user_id")
        session_id = task_data.get("session_id")
        
        # å¯åŠ¨å–æ¶ˆä»»åŠ¡
        celery_task = cancel_writing_task.delay(
            user_id=user_id or "unknown",
            session_id=session_id or "unknown",
            task_id=task_id
        )
        
        logger.info(f"å–æ¶ˆå†™ä½œä»»åŠ¡: {task_id}, Celeryä»»åŠ¡: {celery_task.id}")
        
        return {"message": "ä»»åŠ¡å·²å–æ¶ˆ", "task_id": task_id}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/users/{user_id}/tasks")
async def get_user_tasks(user_id: str):
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡"""
    try:
        logger.info(f"è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨: {user_id}")

        session_manager = get_session_manager()
        task_ids = await session_manager.get_user_tasks(user_id)

        # è·å–æ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
        tasks = []
        for task_id in task_ids:
            task_data = await session_manager.get_task_status(task_id)
            if task_data:
                tasks.append(task_data)

        return {"status": "success", "tasks": tasks, "count": len(tasks)}

    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# äº‹ä»¶æµ API (Server-Sent Events)
# ============================================================================

@app.get("/api/v1/events/{conversation_id}")
async def get_event_stream(conversation_id: str):
    """è·å–ä¼šè¯äº‹ä»¶æµ (Server-Sent Events) - æ”¯æŒæ–°çš„ WorkflowAdapter æ ¼å¼"""
    logger.info(f"ğŸ”— SSEè¿æ¥è¯·æ±‚: {conversation_id}")

    async def event_generator():
        """äº‹ä»¶ç”Ÿæˆå™¨ - æ”¹è¿›é”™è¯¯å¤„ç†"""
        redis_client = get_redis_client()
        # ä½¿ç”¨æ–°çš„æµåç§°æ ¼å¼
        stream_name = f"conversation_events:{conversation_id}"
        # å…ˆå‘é€ä¸€ä¸ªæµ‹è¯•äº‹ä»¶
        yield f"data: {json.dumps({'type': 'connection_test', 'message': 'SSEè¿æ¥æˆåŠŸ', 'timestamp': datetime.now().isoformat()})}\n\n"

        # ä½¿ç”¨ 0 è¯»å–æ‰€æœ‰å†å²æ¶ˆæ¯ï¼Œç„¶ååˆ‡æ¢åˆ°æ–°æ¶ˆæ¯
        last_id = "0"
        logger.info(f"ğŸ“¡ å¼€å§‹ç›‘å¬Redisæµ: {stream_name}")

        try:
            # å…ˆè¯»å–æ‰€æœ‰å†å²æ¶ˆæ¯
            try:
                events = redis_client.xread({stream_name: "0"}, count=100)
                if events:
                    logger.info(f"ğŸ“¨ å‘é€å†å²äº‹ä»¶: {len(events[0][1])} ä¸ª")
                    for stream, messages in events:
                        for message_id, fields in messages:
                            try:
                                # è§£ææ–°æ ¼å¼çš„æ•°æ®
                                event_type = fields.get("event_type", "unknown")
                                timestamp = fields.get("timestamp", "")
                                data_str = fields.get("data", "{}")

                                # è§£æ JSON æ•°æ®
                                data = json.loads(data_str) if isinstance(data_str, str) else data_str

                                # æ ¼å¼åŒ–ä¸º SSE æ ¼å¼
                                event_data = {
                                    "id": message_id,
                                    "event_type": event_type,
                                    "conversation_id": conversation_id,
                                    "timestamp": timestamp,
                                    "step": data.get("step", "unknown"),
                                    "status": data.get("status", ""),
                                    "progress": data.get("progress", 0),
                                    "data": data
                                }

                                logger.info(f"ğŸ“¤ å‘é€å†å²SSEäº‹ä»¶: {message_id}, ç±»å‹: {event_type}")
                                yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"
                                last_id = message_id

                            except Exception as e:
                                logger.error(f"è§£æå†å²äº‹ä»¶æ•°æ®å¤±è´¥: {e}, fields: {fields}")
                                continue
                else:
                    logger.info("ğŸ“­ æ²¡æœ‰å†å²äº‹ä»¶")
            except Exception as e:
                logger.error(f"è¯»å–å†å²äº‹ä»¶å¤±è´¥: {e}")

            # ç°åœ¨ç›‘å¬æ–°äº‹ä»¶
            while True:
                try:
                    # è¯»å–æ–°äº‹ä»¶
                    events = redis_client.xread({stream_name: last_id}, count=10, block=1000)

                    if events:
                        logger.info(f"ğŸ“¨ æ”¶åˆ° {len(events)} ä¸ªæµçš„äº‹ä»¶")
                        for stream, messages in events:
                            logger.info(f"ğŸ“‹ å¤„ç†æµ {stream}, æ¶ˆæ¯æ•°: {len(messages)}")
                            for message_id, fields in messages:
                                try:
                                    logger.debug(f"ğŸ” å¤„ç†æ¶ˆæ¯: {message_id}, å­—æ®µ: {list(fields.keys())}")
                                    # è§£ææ–°æ ¼å¼çš„æ•°æ®
                                    event_type = fields.get("event_type", "unknown")
                                    timestamp = fields.get("timestamp", "")
                                    data_str = fields.get("data", "{}")

                                    # è§£æ JSON æ•°æ®
                                    data = json.loads(data_str) if isinstance(data_str, str) else data_str

                                    # æ ¼å¼åŒ–ä¸º SSE æ ¼å¼
                                    event_data = {
                                        "id": message_id,
                                        "event_type": event_type,
                                        "conversation_id": conversation_id,
                                        "timestamp": timestamp,
                                        "step": data.get("step", "unknown"),
                                        "status": data.get("status", ""),
                                        "progress": data.get("progress", 0),
                                        "data": data
                                    }

                                    try:
                                        logger.info(f"ğŸ“¤ å‘é€SSEäº‹ä»¶: {message_id}, ç±»å‹: {event_type}")
                                        yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"
                                        last_id = message_id
                                        logger.debug(f"âœ… æ›´æ–°last_id: {last_id}")
                                    except (ConnectionResetError, BrokenPipeError, OSError) as e:
                                        # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                                        logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {conversation_id}")
                                        return

                                except Exception as e:
                                    logger.error(f"è§£æäº‹ä»¶æ•°æ®å¤±è´¥: {e}, fields: {fields}")
                                    continue
                    else:
                        logger.debug(f"â³ æ²¡æœ‰æ–°äº‹ä»¶ï¼Œç»§ç»­ç­‰å¾…...")
                        # å‘é€å¿ƒè·³
                        try:
                            yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': datetime.now().isoformat()})}\n\n"
                        except (ConnectionResetError, BrokenPipeError, OSError) as e:
                            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                            logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆå¿ƒè·³ï¼‰: {conversation_id}")
                            return

                except Exception as e:
                    logger.error(f"Redis è¯»å–é”™è¯¯: {e}")
                    # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    import asyncio
                    await asyncio.sleep(1)
                    continue

        except Exception as e:
            logger.error(f"äº‹ä»¶æµä¸¥é‡é”™è¯¯: {e}")
            try:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
            except:
                # å¦‚æœè¿æ¥å·²æ–­å¼€ï¼Œå¿½ç•¥å‘é€é”™è¯¯
                pass

    async def safe_event_generator():
        """å®‰å…¨çš„äº‹ä»¶ç”Ÿæˆå™¨åŒ…è£…å™¨"""
        try:
            async for chunk in event_generator():
                yield chunk
        except (ConnectionResetError, BrokenPipeError, OSError) as e:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œé™é»˜å¤„ç†
            logger.debug(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {conversation_id}")
            return
        except Exception as e:
            logger.error(f"äº‹ä»¶æµå¼‚å¸¸: {e}")
            return

    return StreamingResponse(
        safe_event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )


@app.get("/api/v1/tasks/{task_id}/stream")
async def stream_task_progress(task_id: str):
    """ä»»åŠ¡è¿›åº¦æµå¼æ¥å£ - å…¼å®¹æ–°çš„ conversation_events æ ¼å¼"""
    async def progress_generator():
        # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ç¡®å®š conversation_id
        session_manager = get_session_manager()
        task_data = await session_manager.get_task_status(task_id)

        if not task_data:
            yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡ä¸å­˜åœ¨'})}\n\n"
            return

        # ç¡®å®š conversation_id
        metadata = task_data.get("metadata", {})
        original_conversation_id = metadata.get("original_conversation_id")
        session_id = task_data.get("session_id")
        conversation_id = original_conversation_id or session_id

        redis_client = get_redis_client()
        stream_name = f"conversation_events:{conversation_id}"
        last_id = "0"

        try:
            while True:
                try:
                    # ä» Redis æµä¸­è¯»å–è¿›åº¦æ›´æ–°
                    events = redis_client.xread({stream_name: last_id}, count=10, block=1000)
                except Exception as e:
                    logger.error(f"Redis è¯»å–é”™è¯¯: {e}")
                    events = []

                if events:
                    for stream, messages in events:
                        for message_id, fields in messages:
                            try:
                                # è§£ææ–°æ ¼å¼çš„æ•°æ®
                                event_type = fields.get("event_type", "unknown")
                                timestamp = fields.get("timestamp", "")
                                data_str = fields.get("data", "{}")

                                # è§£æ JSON æ•°æ®
                                data = json.loads(data_str) if isinstance(data_str, str) else data_str

                                event_data = {
                                    "id": message_id,
                                    "event_type": event_type,
                                    "timestamp": timestamp,
                                    "task_id": task_id,
                                    "conversation_id": conversation_id,
                                    "step": data.get("step", "unknown"),
                                    "status": data.get("status", ""),
                                    "progress": data.get("progress", 0),
                                    "data": data
                                }

                                try:
                                    yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"
                                    last_id = message_id
                                except (ConnectionResetError, BrokenPipeError, OSError) as e:
                                    # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                                    logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆä»»åŠ¡æµï¼‰: {task_id}")
                                    return

                            except Exception as e:
                                logger.error(f"è§£æä»»åŠ¡è¿›åº¦æ•°æ®å¤±è´¥: {e}, fields: {fields}")
                                continue
                else:
                    # å‘é€å¿ƒè·³
                    try:
                        yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': datetime.now().isoformat()})}\n\n"
                    except (ConnectionResetError, BrokenPipeError, OSError) as e:
                        # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                        logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆä»»åŠ¡æµå¿ƒè·³ï¼‰: {task_id}")
                        return

        except Exception as e:
            logger.error(f"ä»»åŠ¡æµå¼ä¸¥é‡é”™è¯¯: {e}")
            try:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
            except:
                # å¦‚æœè¿æ¥å·²æ–­å¼€ï¼Œå¿½ç•¥å‘é€é”™è¯¯
                pass

    async def safe_progress_generator():
        """å®‰å…¨çš„è¿›åº¦ç”Ÿæˆå™¨åŒ…è£…å™¨"""
        try:
            async for chunk in progress_generator():
                yield chunk
        except (ConnectionResetError, BrokenPipeError, OSError) as e:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œé™é»˜å¤„ç†
            logger.debug(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆä»»åŠ¡æµï¼‰: {task_id}")
            return
        except Exception as e:
            logger.error(f"ä»»åŠ¡æµå¼‚å¸¸: {e}")
            return

    return StreamingResponse(
        safe_progress_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=config.debug)
