"""
å·¥ä½œæµé€‚é…å™¨
å°† Interative-Report-Workflow é›†æˆåˆ° Celery ç³»ç»Ÿä¸­ï¼Œä½¿ç”¨ Redis ä½œä¸º checkpoint å­˜å‚¨
"""

import json
import time
import uuid
import asyncio
import sys
import os
from typing import Dict, Any, Optional, cast
from datetime import datetime

from ..models.schemas import WritingTaskState, TaskStatus, MessageType, StreamEvent
from ..utils.redis_client import RedisClient
from ..utils.logger import get_logger
from ..utils.config import get_config

logger = get_logger(__name__)

# å¯¼å…¥æ‚¨çš„çœŸæ­£ Graph
from ..graph.graph import create_writing_assistant_graph
from langgraph.types import Command

class CeleryStreamWriter:
    """
    Celery æµå†™å…¥å™¨
    å°† LangGraph çš„æµå¼è¾“å‡ºé€‚é…åˆ° Redis Streams
    """
    
    def __init__(self, task_id: str, session_id: str, redis_client: RedisClient):
        self.task_id = task_id
        self.session_id = session_id
        self.redis_client = redis_client
        self.stream_name = f"task_events:{session_id}"
        
    def __call__(self, data: Dict[str, Any]) -> None:
        """å†™å…¥æµæ•°æ®åˆ° Redis Streams"""
        try:
            # åˆ›å»ºæµäº‹ä»¶
            event = StreamEvent(
                event_id=str(uuid.uuid4()),
                event_type=MessageType.PROGRESS_UPDATE,
                session_id=self.session_id,
                task_id=self.task_id,
                data=data
            )
            
            # å†™å…¥ Redis Streams
            self.redis_client.xadd(
                self.stream_name,
                {
                    "event_type": event.event_type.value,
                    "task_id": self.task_id,
                    "timestamp": event.timestamp.isoformat(),
                    "data": json.dumps(event.data, ensure_ascii=False, default=str)
                }
            )
            
            logger.debug(f"å†™å…¥æµäº‹ä»¶: {data.get('step', 'unknown')} - {data.get('status', '')}")
                
        except Exception as e:
            logger.error(f"å†™å…¥æµæ•°æ®å¤±è´¥: {e}")


class InterruptManager:
    """
    ä¸­æ–­ç®¡ç†å™¨
    å¤„ç† LangGraph çš„ interrupt äº‹ä»¶
    """

    def __init__(self, task_id: str, session_id: str, redis_client: RedisClient):
        self.task_id = task_id
        self.session_id = session_id
        self.redis_client = redis_client
        self.stream_name = f"task_events:{session_id}"
        self.interrupt_timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶
        
    async def send_interrupt_request(self, interrupt_data: Dict[str, Any]) -> str:
        """
        å‘é€ä¸­æ–­è¯·æ±‚
        
        Args:
            interrupt_data: ä¸­æ–­æ•°æ®
            
        Returns:
            interrupt_id: ä¸­æ–­è¯·æ±‚ID
        """
        interrupt_id = str(uuid.uuid4())
        
        try:
            # å‘é€ä¸­æ–­è¯·æ±‚äº‹ä»¶
            event = StreamEvent(
                event_id=interrupt_id,
                event_type=MessageType.INTERRUPT_REQUEST,
                session_id=self.session_id,
                task_id=self.task_id,
                data={
                    "interrupt_id": interrupt_id,
                    "interrupt_type": interrupt_data.get("type", "confirmation"),
                    "title": interrupt_data.get("title", "ç¡®è®¤è¯·æ±‚"),
                    "message": interrupt_data.get("message", "è¯·ç¡®è®¤æ˜¯å¦ç»§ç»­"),
                    "options": interrupt_data.get("options", ["ç¡®è®¤", "å–æ¶ˆ"]),
                    "default": interrupt_data.get("default", "ç¡®è®¤"),
                    "timeout": interrupt_data.get("timeout", self.interrupt_timeout),
                    "content": interrupt_data.get("content", {})
                }
            )
            
            # å†™å…¥äº‹ä»¶æµ
            self.redis_client.xadd(
                self.stream_name,
                {
                    "event_type": event.event_type.value,
                    "task_id": self.task_id,
                    "interrupt_id": interrupt_id,
                    "timestamp": event.timestamp.isoformat(),
                    "data": json.dumps(event.data, ensure_ascii=False, default=str)
                }
            )
            
            # å­˜å‚¨ä¸­æ–­çŠ¶æ€
            interrupt_key = f"interrupt:{interrupt_id}:state"
            self.redis_client.setex(
                interrupt_key,
                self.interrupt_timeout,
                json.dumps({
                    "status": "waiting",
                    "task_id": self.task_id,
                    "session_id": self.session_id,
                    "created_at": datetime.now().isoformat(),
                    "interrupt_data": interrupt_data
                })
            )
            
            logger.info(f"å‘é€ä¸­æ–­è¯·æ±‚: {interrupt_id}, ç±»å‹: {interrupt_data.get('type')}")
            return interrupt_id
            
        except Exception as e:
            logger.error(f"å‘é€ä¸­æ–­è¯·æ±‚å¤±è´¥: {e}")
            raise
    
    def get_user_response(self, interrupt_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·å“åº”
        
        Args:
            interrupt_id: ä¸­æ–­è¯·æ±‚ID
            
        Returns:
            ç”¨æˆ·å“åº”æ•°æ®
        """
        try:
            response_key = f"interrupt:{interrupt_id}:response"
            response_data = self.redis_client.get(response_key)
            
            if response_data:
                return json.loads(response_data)
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å“åº”å¤±è´¥: {e}")
            return None


class WorkflowAdapter:
    """
    å·¥ä½œæµé€‚é…å™¨ - é‡æ–°è®¾è®¡ç‰ˆæœ¬

    æ ¸å¿ƒèŒè´£ï¼š
    1. ç›´æ¥è°ƒç”¨å¤–éƒ¨ Interactive-Report-Workflow å›¾
    2. å¤„ç†æµå¼è¾“å‡ºé€‚é…åˆ° Redis Streams
    3. ç®¡ç†ä¸­æ–­æ£€æµ‹å’Œç”¨æˆ·äº¤äº’
    4. æä¾›ç»Ÿä¸€çš„æ‰§è¡Œå’Œæ¢å¤æ¥å£

    è®¾è®¡åŸåˆ™ï¼š
    - ä¸é‡æ–°æ„å»ºå›¾ç»“æ„
    - ä¸ä¿®æ”¹å¤–éƒ¨å›¾çš„ checkpoint
    - åªè´Ÿè´£è°ƒç”¨å’Œæ•°æ®è½¬æ¢
    """

    def __init__(self, conversation_id: str, redis_client: RedisClient):
        self.conversation_id = conversation_id  # ä½œä¸º LangGraph çš„ thread_id
        self.redis_client = redis_client
        self.stream_writer = CeleryStreamWriter(conversation_id, conversation_id, redis_client)
        self.interrupt_manager = InterruptManager(conversation_id, conversation_id, redis_client)

        # ç›´æ¥ä½¿ç”¨å¤–éƒ¨å›¾ï¼ˆå·²é…ç½® Redis checkpointï¼‰
        self.graph = create_writing_assistant_graph()

        logger.info(f"âœ… WorkflowAdapter åˆå§‹åŒ–å®Œæˆï¼Œconversation_id: {conversation_id}")
        logger.info(f"ğŸ“Š å›¾ç±»å‹: {type(self.graph)}")

    async def execute_workflow(
        self,
        initial_state: Optional[Dict[str, Any]] = None,
        resume_command: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„å·¥ä½œæµæ‰§è¡Œæ¥å£

        Args:
            initial_state: åˆå§‹çŠ¶æ€ï¼ˆç”¨äºæ–°ä»»åŠ¡ï¼‰
            resume_command: æ¢å¤å‘½ä»¤ï¼ˆç”¨äºæ¢å¤ä»»åŠ¡ï¼Œå¦‚ "yes", "no"ï¼‰

        Returns:
            æ‰§è¡Œç»“æœï¼ŒåŒ…å«æµå¼è¾“å‡ºã€ä¸­æ–­ä¿¡æ¯ç­‰
        """
        try:
            # é…ç½® LangGraph
            config = {
                "configurable": {"thread_id": self.conversation_id}
            }

            # ç¡®å®šè¾“å…¥å‚æ•°
            if initial_state is not None and resume_command is not None:
                # æ¢å¤è°ƒç”¨ï¼Œä½†éœ€è¦é‡å»ºçŠ¶æ€
                input_data = Command(resume=resume_command)
                logger.info(f"ğŸ”„ æ¢å¤å·¥ä½œæµæ‰§è¡Œ: {self.conversation_id}, command: {resume_command}")
                logger.info(f"ğŸ“ é‡å»ºçŠ¶æ€ï¼Œä¸»é¢˜: {initial_state.get('topic', 'unknown')}")

                # ç¡®ä¿ LangGraph çŠ¶æ€ä¸­åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
                # é€šè¿‡å…ˆæ›´æ–°çŠ¶æ€ï¼Œç„¶åå‘é€æ¢å¤å‘½ä»¤
                try:
                    # å…ˆå°è¯•è·å–å½“å‰çŠ¶æ€
                    current_state = await self.graph.aget_state(config)
                    if current_state and current_state.values:
                        # æ›´æ–°ç°æœ‰çŠ¶æ€
                        updated_state = {**current_state.values, **initial_state}
                        await self.graph.aupdate_state(config, updated_state)
                        logger.info(f"âœ… çŠ¶æ€æ›´æ–°æˆåŠŸï¼ŒåŒ…å«å­—æ®µ: {list(updated_state.keys())}")
                    else:
                        # å¦‚æœæ²¡æœ‰ç°æœ‰çŠ¶æ€ï¼Œå…ˆåˆå§‹åŒ–çŠ¶æ€
                        await self.graph.aupdate_state(config, initial_state)
                        logger.info(f"âœ… çŠ¶æ€åˆå§‹åŒ–æˆåŠŸï¼ŒåŒ…å«å­—æ®µ: {list(initial_state.keys())}")
                except Exception as e:
                    logger.warning(f"âš ï¸ çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ: {e}")

            elif initial_state is not None:
                # åˆå§‹è°ƒç”¨
                input_data = initial_state
                logger.info(f"ğŸš€ å¼€å§‹æ–°çš„å·¥ä½œæµæ‰§è¡Œ: {self.conversation_id}")
                logger.info(f"ğŸ“ åˆå§‹çŠ¶æ€: {initial_state.get('topic', 'unknown')}")
            elif resume_command is not None:
                # çº¯æ¢å¤è°ƒç”¨ï¼ˆä¸é‡å»ºçŠ¶æ€ï¼‰
                input_data = Command(resume=resume_command)
                logger.info(f"ğŸ”„ æ¢å¤å·¥ä½œæµæ‰§è¡Œ: {self.conversation_id}, command: {resume_command}")
            else:
                raise ValueError("å¿…é¡»æä¾› initial_state æˆ– resume_command ä¹‹ä¸€")

            # æ‰§è¡Œå›¾å¹¶å¤„ç†æµå¼è¾“å‡º
            return await self._execute_with_streaming(input_data, config)

        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def _execute_with_streaming(
        self,
        input_data: Any,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå›¾å¹¶å¤„ç†æµå¼è¾“å‡º

        æ­£ç¡®å¤„ç† LangGraph çš„æµå¼è¾“å‡ºæ ¼å¼ï¼š
        - ('custom', {...}): è‡ªå®šä¹‰æµå¼æ•°æ®
        - ('updates', {...}): çŠ¶æ€æ›´æ–°
        - ('updates', {'__interrupt__': ...}): ä¸­æ–­ä¿¡å·
        """
        try:
            final_result = None
            interrupted = False
            interrupt_info = None

            # ä½¿ç”¨æ­£ç¡®çš„æµå¼è°ƒç”¨æ–¹å¼
            async for chunk in self.graph.astream(
                input_data,
                cast(Any, config),
                stream_mode=["custom", "updates"]
            ):
                logger.info(f"ğŸ“Š æµå¼è¾“å‡º: {chunk}")

                # å¤„ç†ä¸åŒç±»å‹çš„æµå¼è¾“å‡º
                if isinstance(chunk, tuple) and len(chunk) == 2:
                    stream_type, data = chunk

                    if stream_type == "custom":
                        # å¤„ç†è‡ªå®šä¹‰æµå¼æ•°æ®ï¼ˆè¿›åº¦ã€çŠ¶æ€ç­‰ï¼‰
                        await self._handle_custom_stream(data)

                    elif stream_type == "updates":
                        # å¤„ç†çŠ¶æ€æ›´æ–°
                        if "__interrupt__" in data:
                            # æ£€æµ‹åˆ°ä¸­æ–­
                            interrupted = True
                            interrupt_info = data["__interrupt__"]
                            logger.info(f"ğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­: {interrupt_info}")
                            break
                        else:
                            # æ­£å¸¸çŠ¶æ€æ›´æ–°
                            await self._handle_state_update(data)
                            final_result = data

                # ä¿å­˜æœ€ç»ˆç»“æœ
                if chunk and not interrupted:
                    final_result = chunk

            # è¿”å›æ‰§è¡Œç»“æœ
            if interrupted:
                return await self._handle_interrupt(interrupt_info)
            else:
                return self._format_completion_result(final_result)

        except Exception as e:
            logger.error(f"âŒ æµå¼æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def _handle_custom_stream(self, data: Dict[str, Any]):
        """å¤„ç†è‡ªå®šä¹‰æµå¼æ•°æ® - ç›´æ¥ä½¿ç”¨å¤–éƒ¨å›¾çš„æ ¼å¼"""
        try:
            logger.info(f"ğŸ“¥ å¼€å§‹å¤„ç†æµå¼æ•°æ®: {data}")

            # å¤–éƒ¨å›¾å·²ç»æä¾›äº†æ­£ç¡®çš„æ ¼å¼ï¼Œç›´æ¥å†™å…¥ Redis Streams
            stream_name = f"conversation_events:{self.conversation_id}"
            logger.info(f"ğŸ“ å†™å…¥æµåç§°: {stream_name}")

            # æ·»åŠ  conversation_id åˆ°æ•°æ®ä¸­
            enhanced_data = {
                **data,
                "conversation_id": self.conversation_id
            }

            # å‡†å¤‡å†™å…¥ Redis çš„æ•°æ®
            redis_data = {
                "event_type": enhanced_data.get("event_type", "progress_update"),
                "timestamp": str(enhanced_data.get("timestamp", datetime.now().timestamp())),
                "data": json.dumps(enhanced_data, ensure_ascii=False, default=str)
            }
            logger.info(f"ğŸ“‹ Redis æ•°æ®: {redis_data}")

            # ç›´æ¥å†™å…¥ Redis Streams
            result = self.redis_client.xadd(stream_name, redis_data)
            logger.info(f"ğŸ“¤ æµå¼æ•°æ®å·²å†™å…¥: {result}, step: {data.get('step', 'unknown')}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æµå¼æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    async def _handle_state_update(self, data: Dict[str, Any]):
        """å¤„ç†çŠ¶æ€æ›´æ–° - ç›´æ¥å†™å…¥"""
        try:
            stream_name = f"conversation_events:{self.conversation_id}"

            # æ·»åŠ å…ƒæ•°æ®
            enhanced_data = {
                **data,
                "conversation_id": self.conversation_id,
                "event_type": "state_update"
            }

            # ç›´æ¥å†™å…¥ Redis Streams
            self.redis_client.xadd(
                stream_name,
                {
                    "event_type": "state_update",
                    "timestamp": datetime.now().timestamp(),
                    "data": json.dumps(enhanced_data, ensure_ascii=False, default=str)
                }
            )

            logger.debug(f"ğŸ“¤ çŠ¶æ€æ›´æ–°å·²å†™å…¥: {list(data.keys())}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†çŠ¶æ€æ›´æ–°å¤±è´¥: {e}")

    async def _handle_interrupt(self, interrupt_info: Any) -> Dict[str, Any]:
        """å¤„ç†ä¸­æ–­ä¿¡å·"""
        try:
            # è§£æä¸­æ–­ä¿¡æ¯
            if hasattr(interrupt_info, '__iter__') and len(interrupt_info) > 0:
                interrupt_data = interrupt_info[0]
                if hasattr(interrupt_data, 'value'):
                    interrupt_value = interrupt_data.value
                else:
                    interrupt_value = interrupt_data
            else:
                interrupt_value = interrupt_info

            # åˆ›å»ºä¸­æ–­äº‹ä»¶ - ä¿®å¤æ ¼å¼ä»¥åŒ¹é…å‰ç«¯æœŸæœ›
            interrupt_id = str(uuid.uuid4())
            interrupt_event = {
                "event_type": "interrupt_request",
                "conversation_id": self.conversation_id,
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "interrupt_id": interrupt_id,
                    "interrupt_type": interrupt_value.get("type", "confirmation"),  # å‰ç«¯æœŸæœ› interrupt_type
                    "title": interrupt_value.get("message", "éœ€è¦ç”¨æˆ·ç¡®è®¤"),      # å‰ç«¯æœŸæœ› title
                    "message": interrupt_value.get("instructions", "è¯·å›å¤ yes æˆ– no"),  # è¯¦ç»†æ¶ˆæ¯
                    "timeout": 300
                }
            }

            # å†™å…¥ Redis Streams
            stream_name = f"conversation_events:{self.conversation_id}"
            self.redis_client.xadd(
                stream_name,
                {
                    "event_type": interrupt_event["event_type"],
                    "timestamp": interrupt_event["timestamp"],
                    "data": json.dumps(interrupt_event["data"], ensure_ascii=False, default=str)
                }
            )

            logger.info(f"ğŸ›‘ ä¸­æ–­äº‹ä»¶å·²å‘é€: {interrupt_event['data']['interrupt_type']}")

            return {
                "completed": False,
                "interrupted": True,
                "interrupt_id": interrupt_event["data"]["interrupt_id"],
                "interrupt_type": interrupt_event["data"]["interrupt_type"],
                "title": interrupt_event["data"]["title"],
                "message": interrupt_event["data"]["message"]
            }

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä¸­æ–­å¤±è´¥: {e}")
            return {
                "completed": False,
                "interrupted": True,
                "error": f"å¤„ç†ä¸­æ–­å¤±è´¥: {e}"
            }

    def _format_completion_result(self, final_result: Any) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å®Œæˆç»“æœ"""
        try:
            if isinstance(final_result, tuple) and len(final_result) == 2:
                _, data = final_result
            else:
                data = final_result

            # æå–å…³é”®ä¿¡æ¯
            result = {
                "completed": True,
                "interrupted": False,
                "conversation_id": self.conversation_id
            }

            if isinstance(data, dict):
                # æå–å¸¸è§å­—æ®µ
                if "article_generation" in data:
                    article_data = data["article_generation"]
                    result.update({
                        "outline": article_data.get("outline"),
                        "article": article_data.get("article"),
                        "topic": article_data.get("topic"),
                        "search_results": article_data.get("search_results", [])
                    })
                else:
                    # ç›´æ¥ä½¿ç”¨æ•°æ®
                    result.update({
                        "outline": data.get("outline"),
                        "article": data.get("article"),
                        "topic": data.get("topic"),
                        "search_results": data.get("search_results", [])
                    })

            logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {self.conversation_id}")
            return result

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–å®Œæˆç»“æœå¤±è´¥: {e}")
            return {
                "completed": True,
                "interrupted": False,
                "conversation_id": self.conversation_id,
                "error": f"æ ¼å¼åŒ–ç»“æœå¤±è´¥: {e}"
            }

    async def execute_writing_workflow(
        self,
        initial_state: Dict[str, Any],
        task_state: WritingTaskState,
        is_resumed: bool = False
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå†™ä½œå·¥ä½œæµï¼ˆæ”¯æŒ interrupt å’Œ streamingï¼‰

        Args:
            initial_state: åˆå§‹çŠ¶æ€
            task_state: ä»»åŠ¡çŠ¶æ€

        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # è®¾ç½®é…ç½®
            config = {
                "configurable": {"thread_id": self.session_id}
            }

            # æ³¨å…¥æµå†™å…¥å™¨
            self._inject_stream_writer()

            # æ‰§è¡Œå·¥ä½œæµ
            logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {self.task_id}")

            # ä½¿ç”¨ astream æ‰§è¡Œå›¾ï¼Œæ”¯æŒä¸­æ–­å’Œæµå¼è¾“å‡º
            final_result = None
            interrupted = False

            try:
                # ä½¿ç”¨æ‚¨çš„çœŸæ­£ Graph çš„è°ƒç”¨æ–¹å¼
                async for chunk in self.graph.astream(initial_state, cast(Any, config), stream_mode=["custom", "updates"]):
                    logger.info(f"å·¥ä½œæµæ­¥éª¤: {chunk}")

                    # å¤„ç†æµå¼è¾“å‡º
                    await self._handle_streaming_output(chunk)

                    # æ›´æ–°æœ€ç»ˆç»“æœ
                    if chunk:
                        final_result = chunk

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­æ–­å¼‚å¸¸
                if "interrupt" in str(e).lower():
                    logger.info(f"å·¥ä½œæµè¢«ä¸­æ–­ï¼Œç­‰å¾…ç”¨æˆ·å“åº”: {e}")
                    interrupted = True

                    # è·å–å½“å‰çŠ¶æ€
                    current_state = self.graph.get_state(config)

                    # åˆ›å»ºä¸­æ–­æ•°æ®
                    interrupt_data = self._create_interrupt_data_from_state(current_state)
                    interrupt_id = await self.interrupt_manager.send_interrupt_request(interrupt_data)

                    return {
                        "completed": False,
                        "paused": True,
                        "interrupted": True,
                        "interrupt_id": interrupt_id,
                        "current_step": "awaiting_user_response",
                        "progress": 50,
                        "state": current_state.values if current_state else {}
                    }
                else:
                    raise e

            # å·¥ä½œæµå®Œæˆ
            if not interrupted:
                logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {self.task_id}")
                return {
                    "completed": True,
                    "outline": final_result.get("outline") if final_result else None,
                    "article": final_result.get("article") if final_result else None,
                    "search_results": final_result.get("search_results", []) if final_result else [],
                    "state": final_result or {}
                }

        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {e}")
            raise
    
    async def resume_writing_workflow(
        self,
        task_state: WritingTaskState,
        user_response: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ¢å¤å†™ä½œå·¥ä½œæµï¼ˆä½¿ç”¨ LangGraph checkpointï¼‰

        Args:
            task_state: ä»»åŠ¡çŠ¶æ€
            user_response: ç”¨æˆ·å“åº”

        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"æ¢å¤å·¥ä½œæµ: {self.task_id}, ç”¨æˆ·å“åº”: {user_response}")

            # è®¾ç½®é…ç½®
            config = {
                "configurable": {"thread_id": self.session_id}
            }

            # å¤„ç†ç”¨æˆ·å“åº”
            response_type = user_response.get("response", "")
            approved = user_response.get("approved", False)

            # æ ¹æ®ç”¨æˆ·å“åº”å†³å®š resume å‚æ•°
            if response_type == "ç¡®è®¤ç»§ç»­" or approved or "yes" in response_type.lower():
                resume_value = "yes"
            else:
                resume_value = "no"

            logger.info(f"ğŸ”„ ä½¿ç”¨ Command æ¢å¤å·¥ä½œæµ: resume={resume_value}")

            # ä½¿ç”¨æ‚¨çš„ Graph çš„ Command æ–¹å¼æ¢å¤
            if REAL_GRAPH_AVAILABLE and Command:
                # ä½¿ç”¨ Command(resume="yes") çš„æ–¹å¼
                final_result = None
                async for chunk in self.graph.astream(Command(resume=resume_value), cast(Any, config), stream_mode=["custom", "updates"]):
                    logger.info(f"æ¢å¤å·¥ä½œæµæ­¥éª¤: {chunk}")
                    if chunk:
                        final_result = chunk

                result = final_result
            else:
                # å›é€€åˆ°ä¼ ç»Ÿæ–¹å¼
                updated_state = {"user_confirmation": resume_value}
                self.graph.update_state(config, updated_state)
                result = await self.graph.ainvoke(None, config=config)

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if result and result.get("current_step") == "completed":
                logger.info(f"å·¥ä½œæµæ¢å¤æ‰§è¡Œå®Œæˆ: {self.task_id}")
                return {
                    "completed": True,
                    "outline": result.get("outline"),
                    "article": result.get("article"),
                    "search_results": result.get("search_results", []),
                    "state": result
                }
            else:
                # å¯èƒ½è¿˜æœ‰å…¶ä»–ä¸­æ–­
                logger.info(f"å·¥ä½œæµä»åœ¨ç­‰å¾…: {result.get('current_step') if result else 'unknown'}")
                return {
                    "completed": False,
                    "paused": True,
                    "current_step": result.get("current_step", "waiting") if result else "waiting",
                    "progress": 75,
                    "state": result or {}
                }

        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµå¤±è´¥: {e}")
            raise

    def _rebuild_state_from_task(self, task_state: WritingTaskState, user_response: Dict[str, Any]) -> Dict[str, Any]:
        """ä»ä»»åŠ¡çŠ¶æ€é‡å»ºå·¥ä½œæµçŠ¶æ€"""
        state = {
            "topic": task_state.config.topic,
            "user_id": task_state.user_id,
            "max_words": task_state.config.max_words,
            "style": task_state.config.style.value,
            "language": task_state.config.language,
            "mode": task_state.config.mode.value,
            "outline": task_state.outline.model_dump() if task_state.outline else None,
            "article": task_state.article,
            "search_results": [sr.model_dump() for sr in task_state.search_results],
            "messages": []
        }

        # æ ¹æ®ç”¨æˆ·å“åº”æ›´æ–°çŠ¶æ€
        response_type = user_response.get("response", "")
        approved = user_response.get("approved", False)

        if response_type == "ç¡®è®¤ç»§ç»­" or approved:
            state["user_confirmation"] = "yes"
        else:
            state["user_confirmation"] = "no"

        return state
    
    def _inject_stream_writer(self):
        """æ³¨å…¥æµå†™å…¥å™¨åˆ°å…¨å±€ä¸Šä¸‹æ–‡"""
        # è¿™é‡Œéœ€è¦æ¨¡æ‹Ÿ LangGraph çš„æµä¸Šä¸‹æ–‡
        # å®é™…å®ç°å¯èƒ½éœ€è¦æ ¹æ®å…·ä½“ç‰ˆæœ¬è°ƒæ•´
        import contextvars
        
        # åˆ›å»ºä¸Šä¸‹æ–‡å˜é‡
        if not hasattr(self, '_stream_writer_var'):
            self._stream_writer_var = contextvars.ContextVar('stream_writer')
        
        self._stream_writer_var.set(self.stream_writer)
    
    def _needs_user_interaction(self, node_output: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·äº¤äº’"""
        current_step = node_output.get("current_step", "")
        return current_step in [
            "awaiting_confirmation",
            "awaiting_search_permission", 
            "awaiting_rag_permission"
        ]
    
    def _create_interrupt_data(self, node_output: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºä¸­æ–­æ•°æ®"""
        current_step = node_output.get("current_step", "")
        
        if current_step == "awaiting_confirmation":
            return {
                "type": "outline_confirmation",
                "title": "å¤§çº²ç¡®è®¤",
                "message": self._format_outline_message(node_output.get("outline", {})),
                "options": ["ç¡®è®¤ç»§ç»­", "é‡æ–°ç”Ÿæˆ"],
                "default": "ç¡®è®¤ç»§ç»­",
                "content": {"outline": node_output.get("outline", {})}
            }
        elif current_step == "awaiting_search_permission":
            return {
                "type": "search_permission",
                "title": "æœç´¢æƒé™ç¡®è®¤",
                "message": f"æ˜¯å¦å…è®¸ä¸ºä¸»é¢˜ã€Œ{node_output.get('topic', '')}ã€è¿›è¡Œè”ç½‘æœç´¢ï¼Ÿ",
                "options": ["å…è®¸", "è·³è¿‡"],
                "default": "å…è®¸"
            }
        elif current_step == "awaiting_rag_permission":
            return {
                "type": "rag_permission", 
                "title": "RAGå¢å¼ºç¡®è®¤",
                "message": f"æ˜¯å¦éœ€è¦ä¸ºä¸»é¢˜ã€Œ{node_output.get('topic', '')}ã€è¿›è¡ŒRAGçŸ¥è¯†åº“å¢å¼ºï¼Ÿ",
                "options": ["å¯ç”¨", "è·³è¿‡"],
                "default": "å¯ç”¨"
            }
        
        return {
            "type": "generic_confirmation",
            "title": "ç¡®è®¤è¯·æ±‚",
            "message": "è¯·ç¡®è®¤æ˜¯å¦ç»§ç»­",
            "options": ["ç¡®è®¤", "å–æ¶ˆ"],
            "default": "ç¡®è®¤"
        }
    
    def _format_outline_message(self, outline: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å¤§çº²æ¶ˆæ¯"""
        if not outline:
            return "æ— å¤§çº²æ•°æ®"
        
        title = outline.get("title", "æœªçŸ¥æ ‡é¢˜")
        sections = outline.get("sections", [])
        
        message = f"è¯·ç¡®è®¤ä»¥ä¸‹å¤§çº²ï¼š\n\næ ‡é¢˜ï¼š{title}\n\nç« èŠ‚ï¼š\n"
        for i, section in enumerate(sections, 1):
            message += f"{i}. {section.get('title', 'æœªçŸ¥ç« èŠ‚')}\n"
            message += f"   æè¿°ï¼š{section.get('description', 'æ— æè¿°')}\n\n"
        
        return message
    
    def _calculate_progress(self, node_name: str) -> int:
        """è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”"""
        progress_map = {
            "generate_outline": 20,
            "outline_confirmation": 30,
            "search_confirmation": 40,
            "search_execution": 60,
            "article_generation": 90
        }
        return progress_map.get(node_name, 0)
    
    def _update_state_with_response(
        self, 
        task_state: WritingTaskState, 
        user_response: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ ¹æ®ç”¨æˆ·å“åº”æ›´æ–°çŠ¶æ€"""
        # é‡å»ºåŸºç¡€çŠ¶æ€
        state = {
            "topic": task_state.config.topic,
            "user_id": task_state.user_id,
            "max_words": task_state.config.max_words,
            "style": task_state.config.style.value,
            "language": task_state.config.language,
            "mode": task_state.config.mode.value,
            "outline": task_state.outline.model_dump() if task_state.outline else None,
            "article": task_state.article,
            "search_results": [sr.model_dump() for sr in task_state.search_results],
            "messages": []
        }
        
        # æ ¹æ®å“åº”ç±»å‹æ›´æ–°çŠ¶æ€
        response_type = user_response.get("type", "")
        approved = user_response.get("approved", False)
        
        if response_type == "outline_confirmation":
            state["user_confirmation"] = "yes" if approved else "no"
        elif response_type == "search_permission":
            state["search_permission"] = "yes" if approved else "no"
        elif response_type == "rag_permission":
            state["rag_permission"] = "yes" if approved else "no"

        return state

    async def _handle_streaming_output(self, chunk: Dict[str, Any]):
        """å¤„ç†æµå¼è¾“å‡ºï¼Œå­˜å‚¨åˆ° Redis"""
        try:
            # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥å­˜å‚¨åˆ° Redis hash
            stream_key = f"stream:{self.task_id}"

            # åºåˆ—åŒ–æ•°æ®
            import json
            chunk_data = {
                "data": json.dumps(chunk),
                "timestamp": datetime.now().isoformat(),
                "task_id": self.task_id
            }

            # å­˜å‚¨åˆ° Redis hashï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            self.redis_client.hset(
                stream_key,
                datetime.now().isoformat(),
                json.dumps(chunk_data)
            )

            # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ1å°æ—¶ï¼‰
            self.redis_client.expire(stream_key, 3600)

            logger.debug(f"æµå¼è¾“å‡ºå·²å­˜å‚¨: {stream_key}")

        except Exception as e:
            logger.error(f"å¤„ç†æµå¼è¾“å‡ºå¤±è´¥: {e}")

    def _create_interrupt_data_from_state(self, state) -> Dict[str, Any]:
        """ä»çŠ¶æ€åˆ›å»ºä¸­æ–­æ•°æ®"""
        try:
            state_values = state.values if hasattr(state, 'values') else state

            return {
                "type": "user_confirmation_required",
                "message": "éœ€è¦ç”¨æˆ·ç¡®è®¤ä»¥ç»§ç»­æ‰§è¡Œ",
                "data": state_values,
                "task_id": self.task_id,
                "session_id": self.session_id,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"åˆ›å»ºä¸­æ–­æ•°æ®å¤±è´¥: {e}")
            return {
                "type": "error",
                "message": f"åˆ›å»ºä¸­æ–­æ•°æ®å¤±è´¥: {e}",
                "task_id": self.task_id
            }
