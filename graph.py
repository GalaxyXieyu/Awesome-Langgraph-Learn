"""
LangGraphæ™ºèƒ½å†™ä½œåŠ©æ‰‹ - å›¾ç»“æ„æ¨¡å—
å®ç°åŸºäºçŠ¶æ€å›¾çš„æ™ºèƒ½å†™ä½œå·¥ä½œæµ
"""

import os
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import interrupt, Command
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.memory import InMemorySaver
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from tools import (tavily_search, validate_outline, format_article,
                   get_available_knowledge_bases, search_knowledge_base,
                   keyword_knowledge_search, hybrid_search, content_analyzer,
                   topic_expander, writing_style_advisor)
import logging
import time
import json
import re
from langgraph.config import get_stream_writer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --#DEBUG#--
DEBUG_MODE = os.getenv("DEBUG_MODE", "false").lower() == "true"
# --#DEBUG#--


def try_parse_partial_outline(partial_response: str) -> dict:
    """
    å°è¯•è§£æéƒ¨åˆ†ç”Ÿæˆçš„å¤§çº²å†…å®¹
    æ”¯æŒä¸å®Œæ•´çš„JSONç»“æ„ï¼Œæå–å·²å®Œæˆçš„ç« èŠ‚ä¿¡æ¯
    """
    try:
        # æ–¹æ³•1ï¼šç›´æ¥å°è¯•JSONè§£æ
        return json.loads(partial_response)
    except json.JSONDecodeError:
        pass
    
    try:
        # æ–¹æ³•2ï¼šå°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
        # æ·»åŠ ç¼ºå¤±çš„ç»“æŸæ‹¬å·
        fixed_json = partial_response.rstrip()
        if not fixed_json.endswith('}'):
            # è®¡ç®—éœ€è¦çš„ç»“æŸæ‹¬å·æ•°é‡
            open_braces = fixed_json.count('{') - fixed_json.count('}')
            open_brackets = fixed_json.count('[') - fixed_json.count(']')
            
            # æ·»åŠ ç¼ºå¤±çš„ç»“æŸç¬¦
            fixed_json += ']' * open_brackets + '}' * open_braces
        
        return json.loads(fixed_json)
    except (json.JSONDecodeError, ValueError):
        pass
    
    try:
        # æ–¹æ³•3ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç»“æ„åŒ–ä¿¡æ¯
        outline = {"title": "", "sections": []}
        
        # æå–æ ‡é¢˜
        title_match = re.search(r'"title":\s*"([^"]*)"', partial_response)
        if title_match:
            outline["title"] = title_match.group(1)
        
        # æå–ç« èŠ‚ä¿¡æ¯
        sections_text = re.search(r'"sections":\s*\[(.*)', partial_response, re.DOTALL)
        if sections_text:
            sections_content = sections_text.group(1)
            
            # æŸ¥æ‰¾å®Œæ•´çš„ç« èŠ‚å¯¹è±¡
            section_pattern = r'\{\s*"title":\s*"([^"]*)"[^}]*"description":\s*"([^"]*)"[^}]*"key_points":\s*\[([^\]]*)\]\s*\}'
            section_matches = re.finditer(section_pattern, sections_content)
            
            for match in section_matches:
                title = match.group(1)
                description = match.group(2)
                key_points_str = match.group(3)
                
                # è§£ækey_points
                key_points = []
                if key_points_str:
                    key_point_matches = re.findall(r'"([^"]*)"', key_points_str)
                    key_points = list(key_point_matches)
                
                outline["sections"].append({
                    "title": title,
                    "description": description,
                    "key_points": key_points
                })
        
        # åªæœ‰å½“è‡³å°‘æœ‰æ ‡é¢˜æˆ–ç« èŠ‚æ—¶æ‰è¿”å›
        if outline["title"] or outline["sections"]:
            return outline
            
    except Exception:
        pass
    
    return None


# å®šä¹‰å¤§çº²æ•°æ®æ¨¡å‹
class OutlineSection(BaseModel):
    """å¤§çº²ç« èŠ‚æ¨¡å‹"""
    title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    description: str = Field(description="ç« èŠ‚æè¿°")
    key_points: List[str] = Field(description="ç« èŠ‚è¦ç‚¹åˆ—è¡¨")


class ArticleOutline(BaseModel):
    """æ–‡ç« å¤§çº²æ¨¡å‹"""
    title: str = Field(description="æ–‡ç« æ ‡é¢˜")
    sections: List[OutlineSection] = Field(description="ç« èŠ‚åˆ—è¡¨")


class WritingState(TypedDict):
    """å†™ä½œåŠ©æ‰‹çš„çŠ¶æ€å®šä¹‰"""
    # åŸºæœ¬ä¿¡æ¯
    topic: str  # æ–‡ç« ä¸»é¢˜
    user_id: str  # ç”¨æˆ·ID

    # é…ç½®å‚æ•°
    max_words: int  # æœ€å¤§å­—æ•°
    style: str  # å†™ä½œé£æ ¼
    language: str  # è¯­è¨€
    enable_search: bool  # æ˜¯å¦å¯ç”¨æœç´¢

    # å·¥ä½œæµçŠ¶æ€
    current_step: str  # å½“å‰æ­¥éª¤
    outline: Optional[Dict[str, Any]]  # æ–‡ç« å¤§çº²
    article: Optional[str]  # ç”Ÿæˆçš„æ–‡ç« 
    search_results: List[Dict[str, Any]]  # æœç´¢ç»“æœ

    # ç”¨æˆ·äº¤äº’
    user_confirmation: Optional[str]  # ç”¨æˆ·ç¡®è®¤ä¿¡æ¯
    search_permission: Optional[str]  # æœç´¢æƒé™ç¡®è®¤

    # RAGå¢å¼ºåŠŸèƒ½
    rag_enhancement: Optional[str]  # RAGå¢å¼ºçŠ¶æ€
    enhancement_suggestions: Optional[List[Dict[str, Any]]]  # å¢å¼ºå»ºè®®
    selected_knowledge_bases: Optional[List[str]]  # é€‰æ‹©çš„çŸ¥è¯†åº“IDåˆ—è¡¨

    # æœ€ç»ˆæŠ¥å‘ŠåŠŸèƒ½
    final_report: Optional[str]  # æœ€ç»ˆç”Ÿæˆçš„æŠ¥å‘Š
    quality_score: Optional[float]  # å†…å®¹è´¨é‡åˆ†æ•°
    style_score: Optional[float]  # é£æ ¼åŒ¹é…åˆ†æ•°

    # ğŸ† æ–°å¢ï¼šæµå¼ç”ŸæˆçŠ¶æ€å­—æ®µ
    current_word_count: Optional[int]  # å½“å‰å­—æ•°
    generation_progress: Optional[int]  # ç”Ÿæˆè¿›åº¦ç™¾åˆ†æ¯”
    chunk_count: Optional[int]  # chunkè®¡æ•°
    latest_chunk: Optional[str]  # æœ€æ–°ç”Ÿæˆçš„chunkå†…å®¹

    # æ¶ˆæ¯å†å²
    messages: Annotated[List, add_messages]  # å¯¹è¯æ¶ˆæ¯

    # å…ƒæ•°æ®
    generation_time: float  # ç”Ÿæˆæ—¶é—´
    word_count: int  # å­—æ•°ç»Ÿè®¡
    status: str  # çŠ¶æ€ (processing/completed/error)
    error_message: Optional[str]  # é”™è¯¯ä¿¡æ¯


def create_llm() -> ChatOpenAI:
    """åˆ›å»ºLLMå®ä¾‹ - å¼ºåˆ¶å¯ç”¨æµå¼è¾“å‡º"""
    return ChatOpenAI(
        model="qwen2.5-72b-instruct-awq",
        temperature=0.7,
        base_url="https://llm.3qiao.vip:23436/v1",
        api_key="sk-0rnrrSH0OsiaWCiv6b37C1E4E60c4b9394325001Ec19A197",
    )


async def generate_outline_node(state: WritingState, config=None) -> WritingState:
    """
    å¤§çº²ç”ŸæˆèŠ‚ç‚¹ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨å¼‚æ­¥éæµå¼è°ƒç”¨
    æ ¹æ®æ•™ç¨‹æœ€ä½³å®è·µï¼šå¤§çº²ç”Ÿæˆä¸éœ€è¦å®æ—¶åé¦ˆï¼Œä½¿ç”¨ async def + ainvoke
    """
    # å®‰å…¨è·å–æµå¼å†™å…¥å™¨
    try:
        writer = get_stream_writer()
    except Exception:
        # å¦‚æœæ— æ³•è·å–writerï¼Œä½¿ç”¨ç©ºå‡½æ•°
        writer = lambda x: None

    try:
        # custom æµå¼è¾“å‡º - è¿›åº¦åé¦ˆ
        writer({"step": "outline_generation", "status": "å¼€å§‹ç”Ÿæˆå¤§çº²", "progress": 0})

        # åˆ›å»ºJSONè¾“å‡ºè§£æå™¨
        parser = JsonOutputParser(pydantic_object=ArticleOutline)

        # æ„å»ºæç¤ºæ¨¡æ¿
        outline_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚
            è¦æ±‚ï¼š
            1. å¤§çº²åº”è¯¥åŒ…å«æ ‡é¢˜å’Œ3-6ä¸ªä¸»è¦ç« èŠ‚
            2. æ¯ä¸ªç« èŠ‚åº”è¯¥æœ‰æ¸…æ™°çš„ä¸»é¢˜å’Œç®€è¦è¯´æ˜
            3. æ•´ä½“ç»“æ„è¦é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
            4. é€‚åˆ{style}é£æ ¼çš„å†™ä½œ
            5. ä½¿ç”¨{language}è¯­è¨€

            {format_instructions}"""),
            ("human", "è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆæ–‡ç« å¤§çº²ï¼š{topic}")
        ])

        # åˆ›å»ºLLMå’Œé“¾
        llm = create_llm()
        chain = outline_prompt | llm | parser

        writer({"step": "outline_generation", "status": "æ­£åœ¨ç”Ÿæˆå¤§çº²", "progress": 50})

        # ğŸ”¥ çœŸæ­£çš„æµå¼å¤§çº²ç”Ÿæˆï¼šå®æ—¶æ›´æ–°çŠ¶æ€å’Œè¿›åº¦
        full_response = ""
        chunk_count = 0
        
        async for chunk in llm.astream([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚
            è¦æ±‚ï¼š
            1. å¤§çº²åº”è¯¥åŒ…å«æ ‡é¢˜å’Œ3-6ä¸ªä¸»è¦ç« èŠ‚
            2. æ¯ä¸ªç« èŠ‚åº”è¯¥æœ‰æ¸…æ™°çš„ä¸»é¢˜å’Œç®€è¦è¯´æ˜
            3. æ•´ä½“ç»“æ„è¦é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
            4. é€‚åˆ{style}é£æ ¼çš„å†™ä½œ
            5. ä½¿ç”¨{language}è¯­è¨€

            {format_instructions}""".format(
                style=state.get("style", "formal"),
                language=state.get("language", "zh"),
                format_instructions=parser.get_format_instructions()
            )),
            ("human", f"è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆæ–‡ç« å¤§çº²ï¼š{state['topic']}")
        ], config=config):
            if chunk.content and isinstance(chunk.content, str):
                full_response += chunk.content
                chunk_count += 1
                # print(chunk.content)
                # ğŸ”¥ å…³é”®ï¼šå®æ—¶æ›´æ–°çŠ¶æ€ï¼Œè®©LangGraphæµå¼ä¼ é€’æ›´æ–°
                progress = min(90, len(full_response) // 5)  # æ ¹æ®é•¿åº¦è®¡ç®—è¿›åº¦
                
                # æ›´æ–°çŠ¶æ€ä¸­çš„æµå¼å­—æ®µ
                state.update({
                    "latest_chunk": chunk.content,
                    "current_step": "generating_outline",
                    "generation_progress": progress,
                    "chunk_count": chunk_count,
                    "current_word_count": len(full_response.split())
                })
                
                # ğŸŒŠ å®æ—¶å‘é€æµå¼è¿›åº¦æ›´æ–°
                writer({
                    "step": "outline_generation", 
                    "status": "æ­£åœ¨ç”Ÿæˆå¤§çº²...",
                    "progress": progress,
                    "current_content": chunk.content,
                    "total_chars": len(full_response),
                    "chunk_count": chunk_count
                })
                
                # ğŸ§  å°è¯•æ™ºèƒ½éƒ¨åˆ†è§£æï¼ˆæå–å·²å®Œæˆçš„ç« èŠ‚ï¼‰
                try:
                    # ç®€å•çš„éƒ¨åˆ†è§£æï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´çš„JSONç»“æ„ç‰‡æ®µ
                    if '"title"' in full_response and '"sections"' in full_response:
                        # å°è¯•è§£æå½“å‰å·²ç”Ÿæˆçš„å†…å®¹
                        temp_outline = try_parse_partial_outline(full_response)
                        if temp_outline:
                            # å¦‚æœè§£ææˆåŠŸï¼Œæ›´æ–°å¤§çº²çŠ¶æ€
                            state["outline"] = temp_outline
                            writer({
                                "step": "outline_generation",
                                "status": f"å·²è§£æåˆ° {len(temp_outline.get('sections', []))} ä¸ªç« èŠ‚",
                                "progress": progress,
                                "parsed_sections": len(temp_outline.get('sections', []))
                            })
                except Exception:
                    pass  # éƒ¨åˆ†è§£æå¤±è´¥æ—¶ç»§ç»­ç”Ÿæˆ

        # æœ€ç»ˆå®Œæ•´è§£æ
        writer({"step": "outline_generation", "status": "å®Œæˆç”Ÿæˆï¼Œæ­£åœ¨è§£æ...", "progress": 95})
        
        try:
            outline_data = parser.parse(full_response)
        except Exception as parse_error:
            logger.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨å“åº”: {parse_error}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„å¤§çº²ç»“æ„
            outline_data = {
                "title": f"{state['topic']}",
                "sections": [
                    {"title": "å¼•è¨€", "description": "ä»‹ç»ä¸»é¢˜èƒŒæ™¯", "key_points": ["èƒŒæ™¯ä»‹ç»", "é‡è¦æ€§"]},
                    {"title": "ä¸»è¦å†…å®¹", "description": "è¯¦ç»†é˜è¿°ä¸»é¢˜", "key_points": ["æ ¸å¿ƒè§‚ç‚¹", "å…·ä½“åˆ†æ"]},
                    {"title": "ç»“è®º", "description": "æ€»ç»“è¦ç‚¹", "key_points": ["æ€»ç»“", "å±•æœ›"]}
                ]
            }

        # JsonOutputParserè¿”å›çš„æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
        if isinstance(outline_data, dict):
            outline = outline_data
        else:
            # å¦‚æœæ˜¯Pydanticå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            outline = {
                "title": outline_data.title,
                "sections": [
                    {
                        "title": section.title,
                        "description": section.description,
                        "key_points": section.key_points
                    }
                    for section in outline_data.sections
                ]
            }

        writer({"step": "outline_generation", "status": "éªŒè¯å¤§çº²è´¨é‡", "progress": 80})

        # éªŒè¯å¤§çº²
        validation_result = validate_outline.invoke({"outline": outline})

        # custom æµå¼è¾“å‡º - å®ŒæˆçŠ¶æ€
        writer({
            "step": "outline_generation",
            "status": "å¤§çº²ç”Ÿæˆå®Œæˆ",
            "progress": 100,
            "outline": outline,
            "validation_score": validation_result.get('score', 0)
        })

        # æ›´æ–°çŠ¶æ€ - è¿™ä¼šè§¦å‘ updates æµå¼è¾“å‡º
        state["outline"] = outline
        state["current_step"] = "outline_generated"
        state["status"] = "completed"
        state["messages"] = state.get("messages", []) + [
            AIMessage(content=f"å·²ç”Ÿæˆæ–‡ç« å¤§çº²ï¼š\næ ‡é¢˜ï¼š{outline['title']}\nç« èŠ‚æ•°ï¼š{len(outline['sections'])}\néªŒè¯åˆ†æ•°ï¼š{validation_result.get('score', 0)}")
        ]

        # --#DEBUG#--
        if DEBUG_MODE:
            print(f"[DEBUG] å¤§çº²ç”Ÿæˆå®Œæˆï¼Œç« èŠ‚æ•°: {len(outline['sections'])}")
        # --#DEBUG#--

        return state

    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")

        # custom æµå¼è¾“å‡º - é”™è¯¯çŠ¶æ€
        writer({"step": "outline_generation", "status": f"ç”Ÿæˆå¤±è´¥: {str(e)}", "progress": -1})

        # åˆ›å»ºå¤‡ç”¨å¤§çº²
        fallback_outline = {
            "title": f"å…³äº{state['topic']}çš„æ–‡ç« ",
            "sections": [
                {"title": "å¼•è¨€", "description": "ä»‹ç»ä¸»é¢˜èƒŒæ™¯", "key_points": ["èƒŒæ™¯ä»‹ç»", "é‡è¦æ€§"]},
                {"title": "ä¸»è¦å†…å®¹", "description": "è¯¦ç»†é˜è¿°ä¸»é¢˜", "key_points": ["æ ¸å¿ƒè§‚ç‚¹", "å…·ä½“åˆ†æ"]},
                {"title": "ç»“è®º", "description": "æ€»ç»“è¦ç‚¹", "key_points": ["æ€»ç»“", "å±•æœ›"]}
            ]
        }

        # æ›´æ–°çŠ¶æ€ - è¿™ä¹Ÿä¼šè§¦å‘ updates æµå¼è¾“å‡º
        state["outline"] = fallback_outline
        state["current_step"] = "outline_generated"
        state["status"] = "fallback"
        state["error_message"] = str(e)
        state["messages"] = state.get("messages", []) + [
            AIMessage(content=f"ä½¿ç”¨å¤‡ç”¨å¤§çº²ï¼š{fallback_outline['title']}")
        ]
        return state


def human_confirmation_node(state: WritingState) -> WritingState:
    """
    äººå·¥ç¡®è®¤èŠ‚ç‚¹ - åŠ¨æ€ä¸­æ–­ç‰ˆæœ¬
    æ ¹æ®ç”¨æˆ·è®¾ç½®å’Œå¤§çº²è´¨é‡åŠ¨æ€å†³å®šæ˜¯å¦éœ€è¦ç¡®è®¤
    """
    from langgraph.types import interrupt

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤ - åŠ¨æ€åˆ¤æ–­é€»è¾‘
    outline = state.get("outline") or {}
    
    # è·å–å¤§çº²è´¨é‡åˆ†æ•°ï¼ˆå‡è®¾ä»éªŒè¯ç»“æœä¸­è·å–ï¼‰
    outline_quality = 100  # é»˜è®¤é«˜è´¨é‡
    
    # åŠ¨æ€ä¸­æ–­æ¡ä»¶ï¼š
    # 1. ç”¨æˆ·æ˜ç¡®è¦æ±‚ç¡®è®¤ï¼ˆå¯é€šè¿‡çŠ¶æ€ä¼ é€’ï¼‰
    # 2. å¤§çº²è´¨é‡è¾ƒä½éœ€è¦ç¡®è®¤  
    # 3. é¦–æ¬¡ä½¿ç”¨ç³»ç»Ÿéœ€è¦ç¡®è®¤
    require_confirmation = state.get("require_confirmation", True)  # ç”¨æˆ·è®¾ç½®
    low_quality = outline_quality < 80  # ä½è´¨é‡å¤§çº²
    new_user = state.get("user_id", "").endswith("_new")  # æ–°ç”¨æˆ·
    
    # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®ä¸éœ€è¦ç¡®è®¤ï¼Œåˆ™è·³è¿‡å…¶ä»–æ¡ä»¶
    if require_confirmation is False:
        need_confirmation = False
    else:
        # å¦åˆ™æ ¹æ®è´¨é‡å’Œç”¨æˆ·ç±»å‹åˆ¤æ–­
        need_confirmation = require_confirmation or low_quality or new_user
    
    if not need_confirmation:
        # è·³è¿‡ç¡®è®¤ï¼Œè‡ªåŠ¨é€šè¿‡
        state.update({
            "user_confirmation": "auto_yes",
            "current_step": "confirmation_processed",
            "messages": state.get("messages", []) + [
                AIMessage(content="å¤§çº²è´¨é‡è‰¯å¥½ï¼Œè‡ªåŠ¨ç¡®è®¤é€šè¿‡")
            ]
        })
        return state

    # éœ€è¦ç¡®è®¤æ—¶æ‰æ‰§è¡Œä¸­æ–­
    outline_text = f"æ–‡ç« æ ‡é¢˜ï¼š{outline.get('title', 'æœªçŸ¥')}\n\n"
    sections = outline.get("sections") or []
    for i, section in enumerate(sections, 1):
        outline_text += f"{i}. {section.get('title', 'æœªçŸ¥ç« èŠ‚')}\n"
        outline_text += f"   æè¿°ï¼š{section.get('description', 'æ— æè¿°')}\n"
        if section.get('key_points'):
            outline_text += f"   è¦ç‚¹ï¼š{', '.join(section['key_points'])}\n"
        outline_text += "\n"

    user_confirmation = interrupt({
        "type": "outline_confirmation",
        "message": "è¯·ç¡®è®¤ä»¥ä¸‹å¤§çº²æ˜¯å¦æ»¡æ„",
        "outline": outline,
        "formatted_outline": outline_text,
        "instructions": "è¯·å›å¤ 'yes' ç¡®è®¤ç»§ç»­ï¼Œæˆ– 'no' é‡æ–°ç”Ÿæˆå¤§çº²",
        "quality_score": outline_quality
    })

    # å¤„ç†ç”¨æˆ·ç¡®è®¤ç»“æœ
    if isinstance(user_confirmation, str):
        confirmation = user_confirmation.lower().strip()
    else:
        confirmation = str(user_confirmation).lower().strip()

    # æ›´æ–°çŠ¶æ€
    state.update({
        "user_confirmation": confirmation,
        "current_step": "confirmation_processed",
        "messages": state.get("messages", []) + [
            AIMessage(content=f"ç”¨æˆ·ç¡®è®¤ç»“æœ: {confirmation}")
        ]
    })

    return state


async def article_generation_node(state: WritingState, config=None) -> WritingState:
    """
    æ–‡ç« ç”ŸæˆèŠ‚ç‚¹ - ä½¿ç”¨æ­£ç¡®çš„LangGraphæµå¼æ–¹æ³•
    å…³é”®ï¼šåœ¨èŠ‚ç‚¹å†…ä½¿ç”¨LLMé“¾ï¼Œè®©LangGraphè‡ªåŠ¨æ•è·æµå¼è¾“å‡º
    """
    try:
        start_time = time.time()

        # åˆ›å»ºLLMé“¾ - å…³é”®æ˜¯è®©LangGraphèƒ½ç›´æ¥è°ƒç”¨è¿™ä¸ªé“¾
        llm = create_llm()

        # æ„å»ºæ–‡ç« ç”Ÿæˆæç¤º
        outline = state.get("outline") or {}
        outline_text = f"æ ‡é¢˜ï¼š{outline.get('title', '')}\n"

        sections = outline.get("sections") or []
        for i, section in enumerate(sections, 1):
            outline_text += f"{i}. {section.get('title', '')}\n"
            outline_text += f"   {section.get('description', '')}\n"
            if section.get('key_points'):
                outline_text += f"   è¦ç‚¹ï¼š{', '.join(section['key_points'])}\n"

        # æ·»åŠ æœç´¢ç»“æœåˆ°æç¤ºä¸­
        search_results = state.get("search_results", [])
        search_context = ""
        if search_results:
            search_context = "\n\nå‚è€ƒèµ„æ–™ï¼š\n"
            for i, result in enumerate(search_results[:5], 1):  # é™åˆ¶ä½¿ç”¨å‰5ä¸ªç»“æœ
                search_context += f"{i}. {result.get('title', '')}: {result.get('snippet', '')}\n"

        # æ·»åŠ RAGå¢å¼ºå†…å®¹
        enhancement_suggestions = state.get("enhancement_suggestions", [])
        rag_context = ""
        if enhancement_suggestions:
            rag_context = "\n\nçŸ¥è¯†åº“å¢å¼ºå†…å®¹ï¼š\n"
            for i, suggestion in enumerate(enhancement_suggestions[:3], 1):
                rag_context += f"{i}. {suggestion.get('content', '')}\n"

        # æ„å»ºç”ŸæˆæŒ‡ä»¤
        generation_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¤§çº²ç”Ÿæˆä¸€ç¯‡å®Œæ•´çš„æ–‡ç« ï¼š

{outline_text}

{search_context}

{rag_context}

è¦æ±‚ï¼š
1. æ–‡ç« é£æ ¼ï¼š{state.get('style', 'formal')}
2. è¯­è¨€ï¼š{state.get('language', 'zh')}
3. ç›®æ ‡å­—æ•°ï¼šçº¦{state.get('max_words', 1000)}å­—
4. å†…å®¹è¦æ±‚ï¼šé€»è¾‘æ¸…æ™°ã€è®ºè¯å……åˆ†ã€è¯­è¨€æµç•…
5. å¦‚æœæœ‰å‚è€ƒèµ„æ–™ï¼Œè¯·åˆç†å¼•ç”¨å’Œæ•´åˆ

è¯·ç”Ÿæˆå®Œæ•´çš„æ–‡ç« å†…å®¹ã€‚"""

        # ğŸ”¥ æ­£ç¡®çš„LangGraphæµå¼æ–¹æ³•ï¼šä½¿ç”¨astreamå®ç°çœŸæ­£çš„tokençº§æµå¼è¾“å‡º
        from langchain_core.runnables import RunnableLambda
        
        # åˆ›å»ºæ¶ˆæ¯
        messages = [HumanMessage(content=generation_prompt)]
        
        # ä½¿ç”¨æµå¼è°ƒç”¨æ”¶é›†æ‰€æœ‰tokenï¼Œå®ç°çœŸæ­£çš„æµå¼è¾“å‡º
        full_article = ""
        async for chunk in llm.astream(messages, config=config):
            if chunk.content and isinstance(chunk.content, str):
                full_article += chunk.content

        # æ ¼å¼åŒ–æ–‡ç« 
        formatted_result = format_article.invoke({
            "content": full_article,
            "style": state.get("style", "formal")
        })

        # è®¡ç®—ç”Ÿæˆæ—¶é—´
        generation_time = time.time() - start_time

        # æ›´æ–°çŠ¶æ€
        state.update({
            "article": formatted_result.get("formatted_content", full_article),
            "word_count": formatted_result.get("word_count", len(full_article)),
            "generation_time": generation_time,
            "current_step": "article_generated",
            "status": "completed",
            "messages": state.get("messages", []) + [
                AIMessage(content=f"æ–‡ç« ç”Ÿæˆå®Œæˆï¼\nå­—æ•°ï¼š{formatted_result.get('word_count', len(full_article))}\nç”Ÿæˆæ—¶é—´ï¼š{generation_time:.1f}ç§’")
            ]
        })

        # --#DEBUG#--
        if DEBUG_MODE:
            print(f"[DEBUG] æ–‡ç« ç”Ÿæˆå®Œæˆï¼Œå­—æ•°: {formatted_result.get('word_count', len(full_article))}")
        # --#DEBUG#--

        return state

    except Exception as e:
        logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}")
        state.update({
            "status": "error",
            "error_message": f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}",
            "current_step": "error"
        })
        return state


def generate_final_report_node(state: WritingState) -> WritingState:
    """
    ç”Ÿæˆæœ€ç»ˆæŠ¥å‘ŠèŠ‚ç‚¹ - ç›´æ¥ç”Ÿæˆå®Œæ•´çš„å†™ä½œæŠ¥å‘Š
    åŒ…å«æ–‡ç« å†…å®¹ã€ç»Ÿè®¡ä¿¡æ¯å’Œè´¨é‡è¯„ä¼°
    """
    # --#DEBUG#--
    if DEBUG_MODE:
        print("[DEBUG] å¼€å§‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    # --#DEBUG#--

    # ç®€åŒ–çš„è¿›åº¦è®°å½•å‡½æ•°
    def log_progress(step: str, status: str, progress: int):
        if DEBUG_MODE:
            print(f"[DEBUG] {step}: {status} ({progress}%)")

    log_progress("final_report", "å¼€å§‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", 0)

    try:
        article = state.get("article", "")
        topic = state.get("topic", "")
        outline = state.get("outline", {})
        search_results = state.get("search_results", [])
        word_count = state.get("word_count", 0)
        generation_time = state.get("generation_time", 0.0)

        if not article:
            state.update({
                "current_step": "report_error",
                "error_message": "æ²¡æœ‰æ–‡ç« å†…å®¹ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š",
                "messages": state.get("messages", []) + [
                    AIMessage(content="æ²¡æœ‰æ–‡ç« å†…å®¹ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                ]
            })
            return state

        log_progress("final_report", "åˆ†ææ–‡ç« è´¨é‡", 20)

        # æ‰§è¡Œå†…å®¹åˆ†æ
        try:
            content_analysis = content_analyzer.invoke({"text": article})
        except Exception as e:
            logger.warning(f"å†…å®¹åˆ†æå¤±è´¥: {e}")
            content_analysis = {"quality_score": 0, "word_count": word_count}

        log_progress("final_report", "ç”Ÿæˆå†™ä½œé£æ ¼è¯„ä¼°", 40)

        # æ‰§è¡Œå†™ä½œé£æ ¼åˆ†æ
        try:
            style_analysis = writing_style_advisor.invoke({
                "content": article,
                "target_style": state.get("style", "formal")
            })
        except Exception as e:
            logger.warning(f"é£æ ¼åˆ†æå¤±è´¥: {e}")
            style_analysis = {"style_match_score": 0}

        log_progress("final_report", "æ•´ç†æŠ¥å‘Šå†…å®¹", 60)

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report_sections = []

        # 1. åŸºæœ¬ä¿¡æ¯
        report_sections.append("# ğŸ“ æ™ºèƒ½å†™ä½œåŠ©æ‰‹ - å®ŒæˆæŠ¥å‘Š\n")
        report_sections.append(f"**ä¸»é¢˜**: {topic}")
        report_sections.append(f"**ç”Ÿæˆæ—¶é—´**: {generation_time:.1f}ç§’")
        report_sections.append(f"**å­—æ•°ç»Ÿè®¡**: {word_count}å­—")
        report_sections.append(f"**å†™ä½œé£æ ¼**: {state.get('style', 'formal')}")
        report_sections.append("")

        # 2. æ–‡ç« å¤§çº²
        if outline:
            report_sections.append("## ğŸ“‹ æ–‡ç« å¤§çº²")
            report_sections.append(f"**æ ‡é¢˜**: {outline.get('title', 'æœªçŸ¥')}")
            sections = outline.get("sections", [])
            for i, section in enumerate(sections, 1):
                report_sections.append(f"{i}. {section.get('title', 'æœªçŸ¥ç« èŠ‚')}")
                if section.get('description'):
                    report_sections.append(f"   - {section.get('description')}")
            report_sections.append("")

        # 3. è´¨é‡è¯„ä¼°
        report_sections.append("## ğŸ“Š è´¨é‡è¯„ä¼°")
        quality_score = content_analysis.get('quality_score', 0) if isinstance(content_analysis, dict) else 0
        style_score = style_analysis.get('style_match_score', 0) if isinstance(style_analysis, dict) else 0

        report_sections.append(f"- **å†…å®¹è´¨é‡åˆ†æ•°**: {quality_score}/100")
        report_sections.append(f"- **é£æ ¼åŒ¹é…åˆ†æ•°**: {style_score}/100")
        report_sections.append(f"- **ç»¼åˆè¯„åˆ†**: {(quality_score + style_score) / 2:.1f}/100")
        report_sections.append("")

        # 4. æœç´¢èµ„æºä½¿ç”¨æƒ…å†µ
        if search_results:
            report_sections.append("## ğŸ” å‚è€ƒèµ„æº")
            report_sections.append(f"ä½¿ç”¨äº† {len(search_results)} ä¸ªæœç´¢ç»“æœä½œä¸ºå‚è€ƒï¼š")
            for i, result in enumerate(search_results[:5], 1):
                title = result.get('title', 'æœªçŸ¥æ ‡é¢˜')
                url = result.get('url', '')
                report_sections.append(f"{i}. [{title}]({url})")
            report_sections.append("")

        # 5. ç”Ÿæˆçš„æ–‡ç« å†…å®¹
        report_sections.append("## ğŸ“„ ç”Ÿæˆçš„æ–‡ç« ")
        report_sections.append("```")
        report_sections.append(article)
        report_sections.append("```")
        report_sections.append("")

        # 6. æŠ€æœ¯ç»Ÿè®¡
        report_sections.append("## ğŸ”§ æŠ€æœ¯ç»Ÿè®¡")
        report_sections.append(f"- **å¤„ç†èŠ‚ç‚¹**: å¤§çº²ç”Ÿæˆ â†’ ç¡®è®¤ â†’ RAGå¢å¼º â†’ æœç´¢ â†’ æ–‡ç« ç”Ÿæˆ")
        report_sections.append(f"- **ä½¿ç”¨å·¥å…·**: å†…å®¹åˆ†æå™¨ã€å†™ä½œé£æ ¼é¡¾é—®")
        selected_kbs = state.get("selected_knowledge_bases")
        if selected_kbs:
            kb_count = len(selected_kbs)
            report_sections.append(f"- **çŸ¥è¯†åº“**: ä½¿ç”¨äº† {kb_count} ä¸ªçŸ¥è¯†åº“")
        report_sections.append(f"- **ç”Ÿæˆæ¨¡å¼**: æµå¼è¾“å‡º")
        report_sections.append("")

        log_progress("final_report", "å®ŒæˆæŠ¥å‘Šç”Ÿæˆ", 80)

        # åˆå¹¶æŠ¥å‘Šå†…å®¹
        final_report = "\n".join(report_sections)

        log_progress("final_report", f"æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(final_report)}, è´¨é‡: {quality_score})", 100)

        # æ›´æ–°çŠ¶æ€
        state.update({
            "current_step": "completed",
            "status": "completed",
            "messages": state.get("messages", []) + [
                AIMessage(content=f"âœ… å†™ä½œä»»åŠ¡å®Œæˆï¼\nğŸ“Š è´¨é‡è¯„åˆ†: {(quality_score + style_score) / 2:.1f}/100\nğŸ“ å­—æ•°: {word_count}å­—\nâ±ï¸ ç”¨æ—¶: {generation_time:.1f}ç§’\n\n{final_report}")
            ]
        })

        # --#DEBUG#--
        if DEBUG_MODE:
            print(f"[DEBUG] æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè´¨é‡åˆ†æ•°: {quality_score}")
        # --#DEBUG#--

        return state

    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        log_progress("final_report", f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", -1)
        state.update({
            "status": "error",
            "error_message": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
            "current_step": "error"
        })
        return state


def search_confirmation_node(state: WritingState) -> WritingState:
    """
    æœç´¢ç¡®è®¤èŠ‚ç‚¹ - åŠ¨æ€ä¸­æ–­ç‰ˆæœ¬
    æ ¹æ®ä¸»é¢˜æ•æ„Ÿåº¦ã€ç”¨æˆ·åå¥½ã€æˆæœ¬è€ƒè™‘ç­‰åŠ¨æ€å†³å®šæ˜¯å¦éœ€è¦æœç´¢ç¡®è®¤
    """
    from langgraph.types import interrupt
    
    # --#DEBUG#--
    if DEBUG_MODE:
        print("[DEBUG] åŠ¨æ€æœç´¢æƒé™æ£€æŸ¥")
    # --#DEBUG#--

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨æœç´¢åŠŸèƒ½
    if not state.get("enable_search", True):
        state.update({
            "current_step": "search_skipped",
            "search_permission": "no",
            "messages": state.get("messages", []) + [
                AIMessage(content="æœç´¢åŠŸèƒ½å·²ç¦ç”¨")
            ]
        })
        return state

    # åŠ¨æ€åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ç¡®è®¤
    topic = state.get("topic", "").lower()
    
    # 1. æ•æ„Ÿä¸»é¢˜åˆ¤æ–­
    sensitive_keywords = ["private", "secret", "confidential", "å†…éƒ¨", "æœºå¯†", "ä¸ªäºº"]
    is_sensitive = any(keyword in topic for keyword in sensitive_keywords)
    
    # 2. ä¸»é¢˜ç±»å‹åˆ¤æ–­ï¼ˆæŠ€æœ¯ç±»ä¸»é¢˜é€šå¸¸éœ€è¦æœ€æ–°ä¿¡æ¯ï¼‰
    technical_keywords = ["ç¼–ç¨‹", "æŠ€æœ¯", "å¼€å‘", "python", "javascript", "ai", "machine learning"]
    is_technical = any(keyword in topic for keyword in technical_keywords)
    
    # 3. ç”¨æˆ·å†å²åå¥½ï¼ˆå¯ä»¥ä»ç”¨æˆ·IDæˆ–çŠ¶æ€ä¸­è·å–ï¼‰
    user_prefers_search = state.get("user_prefers_search", True)
    
    # 4. ç°æœ‰å†…å®¹å……è¶³æ€§åˆ¤æ–­
    outline = state.get("outline", {})
    sections_count = len(outline.get("sections", []))
    content_sufficient = sections_count >= 4  # 4ä¸ªä»¥ä¸Šç« èŠ‚è®¤ä¸ºå†…å®¹æ¯”è¾ƒå……è¶³
    
    # åŠ¨æ€å†³ç­–é€»è¾‘
    if is_sensitive:
        # æ•æ„Ÿä¸»é¢˜ï¼šéœ€è¦ç”¨æˆ·æ˜ç¡®æˆæƒ
        need_confirmation = True
        auto_decision = None
    elif is_technical and user_prefers_search:
        # æŠ€æœ¯ä¸»é¢˜ä¸”ç”¨æˆ·åå¥½æœç´¢ï¼šè‡ªåŠ¨å…è®¸
        need_confirmation = False
        auto_decision = "yes"
    elif content_sufficient and not is_technical:
        # éæŠ€æœ¯ä¸»é¢˜ä¸”å†…å®¹å……è¶³ï¼šè‡ªåŠ¨è·³è¿‡
        need_confirmation = False  
        auto_decision = "no"
    else:
        # å…¶ä»–æƒ…å†µï¼šè¯¢é—®ç”¨æˆ·
        need_confirmation = True
        auto_decision = None
    
    if not need_confirmation:
        # è‡ªåŠ¨å†³ç­–ï¼Œæ— éœ€ç”¨æˆ·ç¡®è®¤
        state.update({
            "current_step": "search_auto_decided",
            "search_permission": auto_decision,
            "messages": state.get("messages", []) + [
                AIMessage(content=f"è‡ªåŠ¨å†³å®šæœç´¢æƒé™: {'å…è®¸æœç´¢' if auto_decision == 'yes' else 'è·³è¿‡æœç´¢'}")
            ]
        })
        return state

    # éœ€è¦ç”¨æˆ·ç¡®è®¤æ—¶æ‰§è¡Œä¸­æ–­
    search_info = {
        "estimated_queries": min(3, len(outline.get("sections", []))),
        "topic_sensitivity": "é«˜" if is_sensitive else "ä½", 
        "recommended_action": "å»ºè®®æœç´¢" if is_technical else "å¯é€‰æœç´¢"
    }
    
    user_search_permission = interrupt({
        "type": "search_permission",
        "message": "æ˜¯å¦å…è®¸è¿›è¡Œè”ç½‘æœç´¢ï¼Ÿ",
        "topic": state.get("topic"),
        "search_info": search_info,
        "instructions": "è¯·å›å¤ 'yes' å…è®¸æœç´¢ï¼Œ'no' è·³è¿‡æœç´¢",
        "sensitivity_level": "é«˜" if is_sensitive else "ä½"
    })

    # å¤„ç†ç”¨æˆ·é€‰æ‹©
    if isinstance(user_search_permission, str):
        permission = user_search_permission.lower().strip()
    else:
        permission = str(user_search_permission).lower().strip()

    state.update({
        "current_step": "search_permission_processed",
        "search_permission": permission,
        "messages": state.get("messages", []) + [
            AIMessage(content=f"æœç´¢æƒé™ç¡®è®¤ç»“æœ: {permission}")
        ]
    })

    return state


def search_execution_node(state: WritingState) -> WritingState:
    """
    æœç´¢æ‰§è¡ŒèŠ‚ç‚¹ - ä¿®å¤ç‰ˆæœ¬ï¼Œä¿æŒåŒæ­¥ä»¥æ”¯æŒå·¥å…·è°ƒç”¨
    æœç´¢èŠ‚ç‚¹ä¸»è¦è°ƒç”¨å·¥å…·ï¼Œä¿æŒåŒæ­¥å³å¯
    """
    from langgraph.config import get_stream_writer

    # --#DEBUG#--
    if DEBUG_MODE:
        print("[DEBUG] æ‰§è¡Œè”ç½‘æœç´¢")
    # --#DEBUG#--

    try:
        writer = get_stream_writer()

        # æ£€æŸ¥æœç´¢æƒé™
        if state.get("search_permission") != "yes":
            writer({"step": "search_execution", "status": "è·³è¿‡æœç´¢", "progress": 100})
            state.update({
                "search_results": [],
                "current_step": "search_completed"
            })
            return state

        writer({"step": "search_execution", "status": "å¼€å§‹æœç´¢", "progress": 0})

        # æ„å»ºæœç´¢æŸ¥è¯¢
        topic = state.get("topic", "")
        outline = state.get("outline") or {}

        # åŸºäºä¸»é¢˜å’Œå¤§çº²æ„å»ºæœç´¢å…³é”®è¯
        search_queries = [topic]

        # æ·»åŠ ç« èŠ‚ç›¸å…³çš„æœç´¢è¯
        sections = outline.get("sections") or []
        for section in sections[:3]:  # é™åˆ¶æœç´¢æ•°é‡
            section_title = section.get("title", "")
            if section_title and section_title not in search_queries:
                search_queries.append(f"{topic} {section_title}")

        writer({
            "step": "search_execution",
            "status": f"å‡†å¤‡æœç´¢ {len(search_queries)} ä¸ªæŸ¥è¯¢",
            "progress": 10,
            "queries": search_queries
        })

        # æ‰§è¡Œæœç´¢
        all_search_results = []
        for i, query in enumerate(search_queries):
            try:
                progress = 10 + (i / len(search_queries)) * 70
                writer({
                    "step": "search_execution",
                    "status": f"æœç´¢: {query}",
                    "progress": int(progress),
                    "current_query": query
                })

                results = tavily_search.invoke({"query": query, "max_results": 3})
                if isinstance(results, list):
                    all_search_results.extend(results)
                    writer({
                        "step": "search_execution",
                        "status": f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ",
                        "progress": int(progress + 5),
                        "query_results": len(results)
                    })

                # --#DEBUG#--
                if DEBUG_MODE:
                    print(f"[DEBUG] æœç´¢æŸ¥è¯¢ '{query}' è¿”å› {len(results) if isinstance(results, list) else 1} ä¸ªç»“æœ")
                # --#DEBUG#--

            except Exception as search_error:
                logger.warning(f"æœç´¢æŸ¥è¯¢ '{query}' å¤±è´¥: {search_error}")
                writer({
                    "step": "search_execution",
                    "status": f"æœç´¢å¤±è´¥: {query}",
                    "progress": int(progress),
                    "error": str(search_error)
                })
                continue

        writer({"step": "search_execution", "status": "å¤„ç†æœç´¢ç»“æœ", "progress": 85})

        # å»é‡å’Œé™åˆ¶ç»“æœæ•°é‡
        unique_results = []
        seen_urls = set()
        for result in all_search_results:
            url = result.get("url", "")
            if url and url not in seen_urls and len(unique_results) < 10:
                seen_urls.add(url)
                unique_results.append(result)

        writer({
            "step": "search_execution",
            "status": "æœç´¢å®Œæˆ",
            "progress": 100,
            "total_results": len(unique_results),
            "results_preview": [r.get("title", "") for r in unique_results[:3]]
        })

        # æ›´æ–°çŠ¶æ€
        state.update({
            "search_results": unique_results,
            "current_step": "search_completed",
            "messages": state.get("messages", []) + [
                AIMessage(content=f"æœç´¢å®Œæˆï¼Œè·å¾— {len(unique_results)} ä¸ªç›¸å…³èµ„æ–™ã€‚")
            ]
        })

        # --#DEBUG#--
        if DEBUG_MODE:
            print(f"[DEBUG] æœç´¢å®Œæˆï¼Œå…±è·å¾— {len(unique_results)} ä¸ªç»“æœ")
        # --#DEBUG#--

        return state

    except Exception as e:
        logger.error(f"æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        writer({"step": "search_execution", "status": f"æœç´¢å¤±è´¥: {str(e)}", "progress": -1})
        state.update({
            "status": "error",
            "error_message": f"æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}",
            "current_step": "error"
        })
        return state


def rag_enhancement_node(state: WritingState) -> WritingState:
    """
    RAGå¢å¼ºèŠ‚ç‚¹ - åŠ¨æ€ä¸­æ–­ç‰ˆæœ¬
    æ ¹æ®ä¸»é¢˜ç±»å‹ã€ç”¨æˆ·å†å²ã€çŸ¥è¯†åº“åŒ¹é…åº¦ç­‰åŠ¨æ€å†³å®šæ˜¯å¦éœ€è¦RAGå¢å¼º
    """
    from langgraph.types import interrupt

    # --#DEBUG#--
    if DEBUG_MODE:
        print("[DEBUG] åŠ¨æ€RAGå¢å¼ºæ£€æŸ¥")
    # --#DEBUG#--

    # è·å–æµå¼å†™å…¥å™¨
    try:
        from langgraph.config import get_stream_writer
        writer = get_stream_writer()
        writer({"step": "rag_enhancement", "status": "æ£€æŸ¥RAGå¢å¼ºéœ€æ±‚", "progress": 0})
    except Exception:
        writer = lambda _: None

    # è·å–å¯ç”¨çŸ¥è¯†åº“
    try:
        available_kbs = get_available_knowledge_bases.invoke({})
        if not available_kbs or (len(available_kbs) == 1 and "error" in available_kbs[0]):
            state.update({
                "rag_enhancement": "no_knowledge_bases", 
                "current_step": "rag_skipped",
                "messages": state.get("messages", []) + [
                    AIMessage(content="æ²¡æœ‰å¯ç”¨çš„çŸ¥è¯†åº“ï¼Œè·³è¿‡RAGå¢å¼º")
                ]
            })
            return state
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
        state.update({
            "rag_enhancement": "error",
            "current_step": "rag_error"
        })
        return state

    # åŠ¨æ€åˆ¤æ–­æ˜¯å¦éœ€è¦RAGå¢å¼º
    topic = state.get("topic", "").lower()
    
    # 1. ä¸»é¢˜åŒ¹é…åº¦åˆ†æ
    kb_matches = []
    for kb in available_kbs:
        kb_category = kb.get("category", "").lower()
        kb_keywords = kb.get("keywords", "").lower()
        
        # ç®€å•çš„åŒ¹é…ç®—æ³•
        topic_words = topic.split()
        match_score = 0
        for word in topic_words:
            if word in kb_category or word in kb_keywords:
                match_score += 1
        
        if match_score > 0:
            kb_matches.append({
                "kb": kb,
                "score": match_score
            })
    
    # 2. ç”¨æˆ·å†å²å’Œåå¥½
    user_prefers_rag = state.get("user_prefers_rag", True)
    user_expertise = state.get("user_expertise", "intermediate")  # beginner/intermediate/expert
    
    # 3. å†…å®¹å¤æ‚åº¦åˆ¤æ–­
    outline = state.get("outline", {})
    sections_count = len(outline.get("sections", []))
    complex_topic = sections_count >= 5  # 5ä¸ªä»¥ä¸Šç« èŠ‚è®¤ä¸ºæ˜¯å¤æ‚ä¸»é¢˜
    
    # åŠ¨æ€å†³ç­–é€»è¾‘
    if not kb_matches:
        # æ²¡æœ‰åŒ¹é…çš„çŸ¥è¯†åº“ï¼šè‡ªåŠ¨è·³è¿‡
        need_rag = False
        auto_decision = "skip"
        reason = "æ²¡æœ‰åŒ¹é…çš„çŸ¥è¯†åº“"
    elif user_expertise == "expert" and not complex_topic:
        # ä¸“å®¶ç”¨æˆ·ä¸”ä¸»é¢˜ä¸å¤æ‚ï¼šè‡ªåŠ¨è·³è¿‡
        need_rag = False
        auto_decision = "skip"
        reason = "ä¸“å®¶ç”¨æˆ·ï¼Œä¸»é¢˜ç›¸å¯¹ç®€å•"
    elif len(kb_matches) == 1 and kb_matches[0]["score"] >= 2:
        # å•ä¸ªé«˜åŒ¹é…åº¦çŸ¥è¯†åº“ï¼šè‡ªåŠ¨é€‰æ‹©
        need_rag = False
        auto_decision = "auto_select"
        auto_kb = kb_matches[0]["kb"]["id"]
        reason = f"è‡ªåŠ¨é€‰æ‹©é«˜åŒ¹é…åº¦çŸ¥è¯†åº“: {kb_matches[0]['kb']['name']}"
    elif user_prefers_rag and kb_matches:
        # ç”¨æˆ·åå¥½RAGä¸”æœ‰åŒ¹é…ï¼šè¯¢é—®ç”¨æˆ·
        need_rag = True
        auto_decision = None
        reason = "å¤šä¸ªåŒ¹é…çš„çŸ¥è¯†åº“ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©"
    else:
        # å…¶ä»–æƒ…å†µï¼šè‡ªåŠ¨è·³è¿‡
        need_rag = False
        auto_decision = "skip"
        reason = "ç”¨æˆ·åå¥½æˆ–åŒ¹é…åº¦ä¸è¶³"

    writer({"step": "rag_enhancement", "status": f"å†³ç­–ç»“æœ: {reason}", "progress": 50})

    if not need_rag:
        # è‡ªåŠ¨å†³ç­–ï¼Œæ— éœ€ç”¨æˆ·é€‰æ‹©
        if auto_decision == "auto_select":
            # è‡ªåŠ¨é€‰æ‹©çŸ¥è¯†åº“å¹¶è¿›è¡Œç®€å•æ£€ç´¢
            try:
                results = search_knowledge_base.invoke({
                    "query": topic,
                    "knowledge_base_ids": [auto_kb],
                    "top_k": 2
                })
                enhancement_suggestions = []
                if isinstance(results, list):
                    for result in results[:3]:
                        if isinstance(result, dict) and "content" in result:
                            enhancement_suggestions.append({
                                "content": result.get("content", ""),
                                "title": result.get("title", ""),
                                "knowledge_base": result.get("knowledge_base_name", ""),
                                "relevance": result.get("relevance_score", 0)
                            })
                
                state.update({
                    "rag_enhancement": "auto_applied",
                    "selected_knowledge_bases": [auto_kb],
                    "enhancement_suggestions": enhancement_suggestions,
                    "current_step": "rag_enhanced",
                    "messages": state.get("messages", []) + [
                        AIMessage(content=f"è‡ªåŠ¨åº”ç”¨RAGå¢å¼ºï¼Œæ‰¾åˆ° {len(enhancement_suggestions)} ä¸ªå»ºè®®")
                    ]
                })
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨RAGå¢å¼ºå¤±è´¥: {e}")
                state.update({
                    "rag_enhancement": "auto_failed",
                    "current_step": "rag_skipped"
                })
        else:
            # è·³è¿‡RAGå¢å¼º
            state.update({
                "rag_enhancement": "skipped",
                "current_step": "rag_skipped",
                "messages": state.get("messages", []) + [
                    AIMessage(content=f"è·³è¿‡RAGå¢å¼ºï¼š{reason}")
                ]
            })
        
        writer({"step": "rag_enhancement", "status": "RAGå¢å¼ºå†³ç­–å®Œæˆ", "progress": 100})
        return state

    # éœ€è¦ç”¨æˆ·é€‰æ‹©æ—¶æ‰§è¡Œä¸­æ–­
    kb_options = []
    for match in sorted(kb_matches, key=lambda x: x["score"], reverse=True):
        kb = match["kb"]
        kb_options.append({
            "id": kb["id"],
            "name": kb["name"],
            "description": kb["description"],
            "match_score": match["score"],
            "document_count": kb.get("document_count", 0)
        })

    kb_list_text = "\n".join([
        f"â€¢ [{kb['id']}] {kb['name']} (åŒ¹é…åº¦: {kb['match_score']}, {kb['document_count']}æ–‡æ¡£)\n  {kb['description']}"
        for kb in kb_options[:5]  # æœ€å¤šæ˜¾ç¤º5ä¸ªé€‰é¡¹
    ])

    user_kb_choice = interrupt({
        "type": "knowledge_base_selection",
        "message": f"å‘ç° {len(kb_matches)} ä¸ªåŒ¹é…çš„çŸ¥è¯†åº“ï¼Œæ˜¯å¦è¿›è¡ŒRAGå¢å¼ºï¼Ÿ",
        "available_options": kb_options,
        "formatted_options": kb_list_text,
        "instructions": "è¯·è¾“å…¥çŸ¥è¯†åº“IDï¼ˆå¦‚'python_advanced'ï¼‰æˆ– 'skip' è·³è¿‡RAGå¢å¼º",
        "recommendation": f"æ¨èä½¿ç”¨: {kb_options[0]['id']}" if kb_options else "æ— æ¨è"
    })

    # å¤„ç†ç”¨æˆ·é€‰æ‹©
    if isinstance(user_kb_choice, str):
        choice = user_kb_choice.strip()
    else:
        choice = str(user_kb_choice).strip()

    if choice.lower() in ["skip", "no", "none"]:
        state.update({
            "rag_enhancement": "user_skipped",
            "current_step": "rag_skipped",
            "messages": state.get("messages", []) + [
                AIMessage(content="ç”¨æˆ·é€‰æ‹©è·³è¿‡RAGå¢å¼º")
            ]
        })
    else:
        # éªŒè¯é€‰æ‹©çš„çŸ¥è¯†åº“ID
        valid_kb_ids = [kb["id"] for kb in kb_options]
        if choice in valid_kb_ids:
            selected_kb_id = choice
        else:
            # æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æ¨èçš„ç¬¬ä¸€ä¸ª
            selected_kb_id = kb_options[0]["id"] if kb_options else None

        if selected_kb_id:
            # æ‰§è¡ŒRAGæ£€ç´¢
            try:
                results = search_knowledge_base.invoke({
                    "query": topic,
                    "knowledge_base_ids": [selected_kb_id],
                    "top_k": 3
                })
                enhancement_suggestions = []
                if isinstance(results, list):
                    for result in results:
                        if isinstance(result, dict) and "content" in result:
                            enhancement_suggestions.append({
                                "content": result.get("content", ""),
                                "title": result.get("title", ""),
                                "knowledge_base": result.get("knowledge_base_name", ""),
                                "relevance": result.get("relevance_score", 0)
                            })
                
                state.update({
                    "rag_enhancement": "applied",
                    "selected_knowledge_bases": [selected_kb_id],
                    "enhancement_suggestions": enhancement_suggestions,
                    "current_step": "rag_enhanced",
                    "messages": state.get("messages", []) + [
                        AIMessage(content=f"åº”ç”¨RAGå¢å¼ºï¼Œä½¿ç”¨çŸ¥è¯†åº“ {selected_kb_id}ï¼Œæ‰¾åˆ° {len(enhancement_suggestions)} ä¸ªå»ºè®®")
                    ]
                })
            except Exception as e:
                logger.error(f"RAGæ£€ç´¢å¤±è´¥: {e}")
                state.update({
                    "rag_enhancement": "failed",
                    "current_step": "rag_error"
                })
        else:
            state.update({
                "rag_enhancement": "no_valid_selection",
                "current_step": "rag_skipped"
            })

    writer({"step": "rag_enhancement", "status": "RAGå¢å¼ºå®Œæˆ", "progress": 100})
    return state


def route_after_confirmation(state: WritingState) -> str:
    """
    ç¡®è®¤åçš„è·¯ç”±é€»è¾‘ - æ ¹æ®ç”¨æˆ·ç¡®è®¤ç»“æœå†³å®šä¸‹ä¸€æ­¥
    """
    user_confirmation = (state.get("user_confirmation") or "").lower().strip()

    # --#DEBUG#--
    if DEBUG_MODE:
        print(f"[DEBUG] ç”¨æˆ·ç¡®è®¤ç»“æœ: {user_confirmation}")
    # --#DEBUG#--

    if user_confirmation == "yes" or user_confirmation == "auto_yes":
        return "rag_enhancement"  # å…ˆè¿›è¡ŒRAGå¢å¼º
    elif user_confirmation == "no":
        return "generate_outline"  # é‡æ–°ç”Ÿæˆå¤§çº²
    else:
        # è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºinterrupt()ä¼šç­‰å¾…æœ‰æ•ˆè¾“å…¥
        return "rag_enhancement"


def route_after_rag_enhancement(state: WritingState) -> str:
    """
    RAGå¢å¼ºåçš„è·¯ç”±é€»è¾‘
    """
    rag_status = state.get("rag_enhancement", "")

    # --#DEBUG#--
    if DEBUG_MODE:
        print(f"[DEBUG] RAGå¢å¼ºçŠ¶æ€: {rag_status}")
    # --#DEBUG#--

    # æ— è®ºRAGå¢å¼ºç»“æœå¦‚ä½•ï¼Œéƒ½ç»§ç»­åˆ°æœç´¢ç¡®è®¤
    return "search_confirmation"


def route_after_search_confirmation(state: WritingState) -> str:
    """
    æœç´¢ç¡®è®¤åçš„è·¯ç”±é€»è¾‘ - æ ¹æ®æœç´¢æƒé™å†³å®šæ˜¯å¦æ‰§è¡Œæœç´¢
    """
    search_permission = (state.get("search_permission") or "").lower().strip()

    # --#DEBUG#--
    if DEBUG_MODE:
        print(f"[DEBUG] æœç´¢æƒé™: {search_permission}")
    # --#DEBUG#--

    if search_permission == "yes":
        return "search_execution"
    else:
        return "article_generation"  # ç›´æ¥ç”Ÿæˆæ–‡ç« 


def should_continue_after_search(state: WritingState) -> str:
    """
    æœç´¢å®Œæˆåçš„è·¯ç”±é€»è¾‘ - æœç´¢å®Œæˆåç›´æ¥è¿›å…¥æ–‡ç« ç”Ÿæˆ
    """
    # å¿½ç•¥stateå‚æ•°ï¼Œç›´æ¥è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    return "article_generation"


def create_writing_assistant_graph():
    """
    åˆ›å»ºæ™ºèƒ½å†™ä½œåŠ©æ‰‹çš„çŠ¶æ€å›¾ - åŠ¨æ€ä¸­æ–­ç‰ˆæœ¬
    ä¸ä½¿ç”¨å›ºå®šçš„interrupt_beforeï¼Œè€Œæ˜¯åœ¨èŠ‚ç‚¹å†…éƒ¨åŠ¨æ€å†³å®šä¸­æ–­

    Returns:
        ç¼–è¯‘åçš„çŠ¶æ€å›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(WritingState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("generate_outline", generate_outline_node)
    workflow.add_node("human_confirmation", human_confirmation_node)
    workflow.add_node("rag_enhancement", rag_enhancement_node)
    workflow.add_node("search_confirmation", search_confirmation_node)
    workflow.add_node("search_execution", search_execution_node)
    workflow.add_node("article_generation", article_generation_node)
    workflow.add_node("generate_final_report", generate_final_report_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("generate_outline")

    # æ·»åŠ è¾¹å’Œæ¡ä»¶è·¯ç”±
    workflow.add_edge("generate_outline", "human_confirmation")

    # äººå·¥ç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "human_confirmation",
        route_after_confirmation,
        {
            "rag_enhancement": "rag_enhancement",
            "generate_outline": "generate_outline"
        }
    )

    # RAGå¢å¼ºåçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "rag_enhancement",
        route_after_rag_enhancement,
        {
            "search_confirmation": "search_confirmation"
        }
    )

    # æœç´¢ç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "search_confirmation",
        route_after_search_confirmation,
        {
            "search_execution": "search_execution",
            "article_generation": "article_generation"
        }
    )

    # æœç´¢å®Œæˆåçš„è·¯ç”±
    workflow.add_conditional_edges(
        "search_execution",
        should_continue_after_search,
        {
            "article_generation": "article_generation"
        }
    )

    # æ–‡ç« ç”Ÿæˆå®Œæˆåè¿›å…¥æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ
    workflow.add_edge("article_generation", "generate_final_report")

    # æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆåç»“æŸ
    workflow.add_edge("generate_final_report", END)

    # é…ç½®checkpointerä»¥æ”¯æŒçŠ¶æ€æŒä¹…åŒ–
    memory = InMemorySaver()

    # ğŸ”¥ åŠ¨æ€ä¸­æ–­æ¨¡å¼ï¼šä¸ä½¿ç”¨interrupt_beforeï¼Œè€Œæ˜¯åœ¨èŠ‚ç‚¹å†…éƒ¨åŠ¨æ€å†³å®šä¸­æ–­
    # è¿™æ ·å¯ä»¥æ ¹æ®å®é™…çŠ¶æ€å’Œç”¨æˆ·è®¾ç½®æ™ºèƒ½å†³å®šæ˜¯å¦éœ€è¦ä¸­æ–­
    app = workflow.compile(
        checkpointer=memory
        # ç§»é™¤å›ºå®šçš„interrupt_beforeé…ç½®ï¼Œæ”¹ä¸ºèŠ‚ç‚¹å†…éƒ¨åŠ¨æ€ä¸­æ–­
    )

    return app


def should_interrupt_for_node(node_name: str, state: WritingState) -> bool:
    """
    å®¢æˆ·ç«¯æ™ºèƒ½åˆ¤æ–­å‡½æ•° - å†³å®šæ˜¯å¦éœ€è¦åœ¨ç‰¹å®šèŠ‚ç‚¹å‰ä¸­æ–­
    
    Args:
        node_name: èŠ‚ç‚¹åç§°
        state: å½“å‰çŠ¶æ€
    
    Returns:
        bool: æ˜¯å¦éœ€è¦ä¸­æ–­
    """
    # æœç´¢æ‰§è¡ŒèŠ‚ç‚¹çš„åˆ¤æ–­é€»è¾‘
    if node_name == "search_execution":
        # å¦‚æœæœç´¢è¢«ç¦ç”¨ï¼Œä¸éœ€è¦ä¸­æ–­
        if not state.get("enable_search", True):
            return False
        
        # å¦‚æœç”¨æˆ·å·²ç»æ˜ç¡®æ‹’ç»æœç´¢ï¼Œä¸éœ€è¦ä¸­æ–­
        if state.get("search_permission") == "no":
            return False
            
        # å¦‚æœæœç´¢æƒé™å¾…å¤„ç†ï¼Œéœ€è¦ä¸­æ–­è¯¢é—®ç”¨æˆ·
        if state.get("search_permission") == "pending":
            return True
            
        # é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœå¯ç”¨æœç´¢ä¸”æœªè®¾ç½®æƒé™ï¼Œéœ€è¦ä¸­æ–­
        return state.get("search_permission") is None
    
    # å·¥å…·èŠ‚ç‚¹çš„åˆ¤æ–­é€»è¾‘ï¼ˆæœªæ¥æ‰©å±•ï¼‰
    if "tool" in node_name.lower():
        # å¯ä»¥æ ¹æ®å…·ä½“å·¥å…·ç±»å‹å’Œæ•æ„Ÿåº¦åˆ¤æ–­
        return False
        
    # é»˜è®¤ä¸ä¸­æ–­
    return False


def get_interrupt_message_for_node(node_name: str, state: WritingState) -> dict:
    """
    ä¸ºç‰¹å®šèŠ‚ç‚¹ç”Ÿæˆä¸­æ–­æ¶ˆæ¯
    
    Args:
        node_name: èŠ‚ç‚¹åç§°
        state: å½“å‰çŠ¶æ€
        
    Returns:
        dict: ä¸­æ–­æ¶ˆæ¯å­—å…¸
    """
    if node_name == "search_execution":
        return {
            "type": "search_permission",
            "message": "æ˜¯å¦å…è®¸è¿›è¡Œè”ç½‘æœç´¢ï¼Ÿ",
            "description": "ä¸ºäº†ç”Ÿæˆæ›´å‡†ç¡®å’Œæœ€æ–°çš„å†…å®¹ï¼Œç³»ç»Ÿå¯ä»¥è¿›è¡Œè”ç½‘æœç´¢è·å–ç›¸å…³èµ„æ–™",
            "instructions": "è¯·å›å¤ 'yes' å…è®¸æœç´¢ï¼Œæˆ– 'no' è·³è¿‡æœç´¢",
            "current_topic": state.get("topic", ""),
            "estimated_queries": 3  # é¢„ä¼°æœç´¢æŸ¥è¯¢æ•°é‡
        }
    

    
    return {
        "type": "unknown",
        "message": f"èŠ‚ç‚¹ {node_name} éœ€è¦ç”¨æˆ·ç¡®è®¤",
        "instructions": "è¯·å›å¤ 'yes' ç»§ç»­ï¼Œæˆ– 'no' è·³è¿‡"
    }


def get_node_type(node_name: str) -> str:
    """
    è·å–èŠ‚ç‚¹ç±»å‹ç”¨äºæ™ºèƒ½è·¯ç”±
    
    Args:
        node_name: èŠ‚ç‚¹åç§°
        
    Returns:
        str: èŠ‚ç‚¹ç±»å‹
    """
    node_types = {
        "generate_outline": "generation",
        "human_confirmation": "interaction", 
        "rag_enhancement": "enhancement",
        "search_confirmation": "interaction",
        "search_execution": "tool",
        "article_generation": "generation",
        "multi_tool_analysis": "analysis"
    }
    
    return node_types.get(node_name, "unknown")


def is_sensitive_operation(node_name: str, state: WritingState) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºæ•æ„Ÿæ“ä½œï¼Œéœ€è¦é¢å¤–ç¡®è®¤
    
    Args:
        node_name: èŠ‚ç‚¹åç§°
        state: å½“å‰çŠ¶æ€
        
    Returns:
        bool: æ˜¯å¦ä¸ºæ•æ„Ÿæ“ä½œ
    """
    # æœç´¢æ“ä½œï¼šæ ¹æ®ä¸»é¢˜æ•æ„Ÿåº¦å’Œç”¨æˆ·è®¾ç½®åˆ¤æ–­
    if node_name == "search_execution":
        topic = state.get("topic", "").lower()
        sensitive_keywords = ["private", "secret", "confidential", "å†…éƒ¨", "æœºå¯†"]
        return any(keyword in topic for keyword in sensitive_keywords)
    
    # æŠ¥å‘Šç”Ÿæˆï¼šé€šå¸¸ä¸æ•æ„Ÿ
    if node_name == "generate_final_report":
        return False  # æŠ¥å‘Šç”Ÿæˆé€šå¸¸ä¸æ•æ„Ÿ
    
    return False


def initialize_writing_state(
    topic: str,
    user_id: str,
    max_words: int = 1000,
    style: str = "formal",
    language: str = "zh",
    enable_search: bool = True
) -> WritingState:
    """
    åˆå§‹åŒ–å†™ä½œçŠ¶æ€

    Args:
        topic: æ–‡ç« ä¸»é¢˜
        user_id: ç”¨æˆ·ID
        max_words: æœ€å¤§å­—æ•°
        style: å†™ä½œé£æ ¼
        language: è¯­è¨€
        enable_search: æ˜¯å¦å¯ç”¨æœç´¢

    Returns:
        åˆå§‹åŒ–çš„çŠ¶æ€å­—å…¸
    """
    return WritingState(
        topic=topic,
        user_id=user_id,
        max_words=max_words,
        style=style,
        language=language,
        enable_search=enable_search,
        current_step="initialized",
        outline=None,
        article=None,
        search_results=[],
        user_confirmation=None,
        search_permission=None,
        rag_enhancement=None,
        enhancement_suggestions=None,
        selected_knowledge_bases=None,
        final_report=None,
        quality_score=None,
        style_score=None,
        # ğŸ† æ–°å¢ï¼šæµå¼ç”ŸæˆçŠ¶æ€å­—æ®µåˆå§‹åŒ–
        current_word_count=None,
        generation_progress=None,
        chunk_count=None,
        latest_chunk=None,
        messages=[],
        generation_time=0.0,
        word_count=0,
        status="processing",
        error_message=None
    )


def clean_debug_tags(module_name: str) -> None:
    """
    æ¸…ç†è°ƒè¯•æ ‡è®°ï¼ˆç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼‰

    Args:
        module_name: æ¨¡å—åç§°
    """
    # --#DEBUG#--
    if DEBUG_MODE:
        print(f"[DEBUG] æ¸…ç†æ¨¡å— {module_name} çš„è°ƒè¯•æ ‡è®°")
    # --#DEBUG#--

    logger.info(f"å·²æ¸…ç†æ¨¡å— {module_name} çš„è°ƒè¯•ä»£ç ")