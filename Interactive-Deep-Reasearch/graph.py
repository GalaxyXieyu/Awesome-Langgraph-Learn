"""
æ ¸å¿ƒå›¾æ¨¡å—
é«˜çº§äº¤äº’å¼æ·±åº¦ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿçš„ä¸»è¦å·¥ä½œæµå›¾
é›†æˆMulti-Agentåä½œã€Human-in-loopäº¤äº’å’Œæµå¼è¾“å‡º
"""

import json
import time
import asyncio
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime

from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.config import get_stream_writer
from langgraph.types import interrupt
import logging

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from state import (
    DeepResearchState, ReportMode, AgentType, InteractionType, TaskStatus,
    ReportOutline, ReportSection, ResearchResult, AnalysisInsight,
    update_performance_metrics, add_research_result,
    add_analysis_insight, update_task_status, add_user_interaction
)
from tools import (
    get_research_tools, get_analysis_tools, get_writing_tools, get_validation_tools,
    advanced_web_search, multi_source_research, content_analyzer, trend_analyzer,
    section_content_generator, report_formatter, quality_validator
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# LLMé…ç½®
# ============================================================================

def create_llm() -> ChatOpenAI:
    """åˆ›å»ºLLMå®ä¾‹"""
    return ChatOpenAI(
        model="qwen2.5-72b-instruct-awq",
        temperature=0.7,
        base_url="https://llm.3qiao.vip:23436/v1",
        api_key="sk-0rnrrSH0OsiaWCiv6b37C1E4E60c4b9394325001Ec19A197",
    )

def create_specialized_agents():
    """åˆ›å»ºä¸“ä¸šåŒ–Agent"""
    llm = create_llm()
    
    # ç ”ç©¶ä¸“å®¶Agent
    researcher_agent = create_react_agent(
        llm,
        tools=get_research_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶ä¸“å®¶ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
        1. æ·±åº¦æœç´¢å’Œæ”¶é›†ç›¸å…³ä¿¡æ¯
        2. è¯„ä¼°ä¿¡æ¯æ¥æºçš„å¯ä¿¡åº¦å’Œç›¸å…³æ€§
        3. è¯†åˆ«å…³é”®è¶‹åŠ¿å’Œå‘å±•æ¨¡å¼
        4. æä¾›å…¨é¢ä¸”å‡†ç¡®çš„ç ”ç©¶æ•°æ®
        
        å·¥ä½œåŸåˆ™ï¼š
        - ä½¿ç”¨å¤šä¸ªå¯ä¿¡æ¥æºéªŒè¯ä¿¡æ¯
        - å…³æ³¨æœ€æ–°å‘å±•å’Œè¶‹åŠ¿
        - ä¿æŒå®¢è§‚å’Œæ‰¹åˆ¤æ€§æ€ç»´
        - æä¾›è¯¦ç»†çš„æ•°æ®æ”¯æ’‘
        
        è¯·ç¡®ä¿ç ”ç©¶çš„æ·±åº¦å’Œå¹¿åº¦ï¼Œä¸ºåç»­åˆ†ææä¾›å……åˆ†çš„æ•°æ®åŸºç¡€ã€‚"""
    )
    
    # åˆ†æä¸“å®¶Agent
    analyst_agent = create_react_agent(
        llm,
        tools=get_analysis_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†æä¸“å®¶ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
        1. æ·±åº¦åˆ†æç ”ç©¶æ•°æ®å’Œä¿¡æ¯
        2. è¯†åˆ«å…³é”®æ´å¯Ÿã€æ¨¡å¼å’Œè¶‹åŠ¿
        3. è¿›è¡Œé¢„æµ‹æ€§åˆ†æå’Œé£é™©è¯„ä¼°
        4. æä¾›æ•°æ®é©±åŠ¨çš„ç»“è®ºå’Œå»ºè®®
        
        åˆ†æé‡ç‚¹ï¼š
        - è¶‹åŠ¿è¯†åˆ«å’Œæ¨¡å¼å‘ç°
        - å› æœå…³ç³»åˆ†æ
        - å½±å“å› ç´ è¯„ä¼°
        - é¢„æµ‹æ€§æ´å¯Ÿç”Ÿæˆ
        
        è¯·è¿ç”¨ä¸¥æ ¼çš„åˆ†ææ–¹æ³•ï¼Œç¡®ä¿ç»“è®ºçš„ç§‘å­¦æ€§å’Œå¯é æ€§ã€‚"""
    )
    
    # å†™ä½œä¸“å®¶Agent
    writer_agent = create_react_agent(
        llm,
        tools=get_writing_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯å†™ä½œä¸“å®¶ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
        1. å°†å¤æ‚ç ”ç©¶å’Œåˆ†æè½¬åŒ–ä¸ºæ¸…æ™°çš„å†…å®¹
        2. ç¡®ä¿å†…å®¹ç»“æ„åˆç†ã€é€»è¾‘æ¸…æ™°
        3. é€‚åº”ä¸åŒè¯»è€…ç¾¤ä½“çš„éœ€æ±‚
        4. ä¿æŒä¸€è‡´çš„ä¸“ä¸šå†™ä½œé£æ ¼
        
        å†™ä½œæ ‡å‡†ï¼š
        - ç»“æ„æ¸…æ™°ã€å±‚æ¬¡åˆ†æ˜
        - è¯­è¨€å‡†ç¡®ã€è¡¨è¾¾æµç•…
        - é€»è¾‘ä¸¥å¯†ã€è®ºè¯å……åˆ†
        - é‡ç‚¹çªå‡ºã€æ˜“äºç†è§£
        
        è¯·ç¡®ä¿ç”Ÿæˆçš„å†…å®¹å…·æœ‰ä¸“ä¸šæ€§ã€å¯è¯»æ€§å’Œå®ç”¨æ€§ã€‚"""
    )
    
    # éªŒè¯ä¸“å®¶Agent
    validator_agent = create_react_agent(
        llm,
        tools=get_validation_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´¨é‡éªŒè¯ä¸“å®¶ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
        1. éªŒè¯æŠ¥å‘Šå†…å®¹çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
        2. æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§å’Œè®ºè¯ä¸¥å¯†æ€§
        3. è¯„ä¼°å†…å®¹è´¨é‡å’Œå¯è¯»æ€§
        4. è¯†åˆ«é—®é¢˜å¹¶æä¾›æ”¹è¿›å»ºè®®
        
        éªŒè¯æ ‡å‡†ï¼š
        - å†…å®¹å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
        - é€»è¾‘ä¸€è‡´æ€§å’Œè¿è´¯æ€§
        - ç»“æ„åˆç†æ€§å’Œå¯è¯»æ€§
        - ä¸“ä¸šæ€§å’Œæƒå¨æ€§
        
        è¯·ä¸¥æ ¼æŒ‰ç…§è´¨é‡æ ‡å‡†è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æŠ¥å‘Šçš„ä¸“ä¸šæ°´å‡†ã€‚"""
    )
    
    return {
        AgentType.RESEARCHER: researcher_agent,
        AgentType.ANALYST: analyst_agent,
        AgentType.WRITER: writer_agent,
        AgentType.VALIDATOR: validator_agent
    }

# ============================================================================
# æ™ºèƒ½åè°ƒèŠ‚ç‚¹
# ============================================================================

async def intelligent_supervisor_node(state: DeepResearchState, config=None) -> DeepResearchState:
    """
    æ™ºèƒ½ç›‘ç£åè°ƒèŠ‚ç‚¹
    è´Ÿè´£æ•´ä½“ä»»åŠ¡è§„åˆ’ã€Agentè°ƒåº¦å’Œæµç¨‹æ§åˆ¶
    """
    writer = get_stream_writer()
    writer({
        "step": "supervision",
        "status": "å¼€å§‹æ™ºèƒ½ä»»åŠ¡åè°ƒ",
        "progress": 0,
        "session_id": state["session_id"]
    })
    
    try:
        start_time = time.time()
        llm = create_llm()
        
        # æ„å»ºåè°ƒåˆ†ææç¤º
        supervision_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„æŠ¥å‘Šç”Ÿæˆç›‘ç£åè°ƒå™¨ã€‚åˆ†æå½“å‰çŠ¶æ€å¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
            
            å¯ç”¨çš„Agentç±»å‹ï¼š
            - researcher: æ·±åº¦ç ”ç©¶å’Œä¿¡æ¯æ”¶é›†
            - analyst: æ•°æ®åˆ†æå’Œæ´å¯Ÿç”Ÿæˆ
            - writer: å†…å®¹å†™ä½œå’ŒæŠ¥å‘Šç”Ÿæˆ
            - validator: è´¨é‡éªŒè¯å’Œæ”¹è¿›
            
            å¯ç”¨çš„è¡ŒåŠ¨ï¼š
            - outline_generation: ç”ŸæˆæŠ¥å‘Šå¤§çº²
            - research_execution: æ‰§è¡Œæ·±åº¦ç ”ç©¶
            - analysis_generation: ç”Ÿæˆåˆ†ææ´å¯Ÿ
            - content_creation: åˆ›å»ºæŠ¥å‘Šå†…å®¹
            - quality_validation: è´¨é‡éªŒè¯
            - finish: å®ŒæˆæŠ¥å‘Šç”Ÿæˆ
            
            è¯·åˆ†æå½“å‰çŠ¶æ€å¹¶è¿”å›æ¨èçš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼ˆåªè¿”å›è¡ŒåŠ¨åç§°ï¼‰ã€‚
            """),
            ("human", """
            å½“å‰çŠ¶æ€åˆ†æï¼š
            - ä¸»é¢˜ï¼š{topic}
            - å½“å‰æ­¥éª¤ï¼š{current_step}
            - æ‰§è¡Œè·¯å¾„ï¼š{execution_path}
            - å·²æœ‰å¤§çº²ï¼š{has_outline}
            - ç ”ç©¶ç»“æœæ•°ï¼š{research_count}
            - åˆ†ææ´å¯Ÿæ•°ï¼š{insights_count}
            - å·²æœ‰æœ€ç»ˆæŠ¥å‘Šï¼š{has_final_report}
            - è¿è¡Œæ¨¡å¼ï¼š{mode}
            
            è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æ¨èä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
            """)
        ])
        
        # å‡†å¤‡çŠ¶æ€åˆ†ææ•°æ®
        analysis_data = {
            "topic": state["topic"],
            "current_step": state["current_step"],
            "execution_path": " â†’ ".join(state["execution_path"]) if state["execution_path"] else "æ— ",
            "has_outline": "æ˜¯" if state["outline"] else "å¦",
            "research_count": len(state["research_results"]),
            "insights_count": len(state["analysis_insights"]),
            "has_final_report": "æ˜¯" if state["final_report"] else "å¦",
            "mode": state["mode"]
        }
        
        writer({
            "step": "supervision",
            "status": "åˆ†æå½“å‰çŠ¶æ€...",
            "progress": 30,
            "analysis_data": analysis_data
        })
        
        # æµå¼ç”Ÿæˆåè°ƒå†³ç­–
        full_response = ""
        chunk_count = 0
        async for chunk in llm.astream(supervision_prompt.format_messages(**analysis_data), config=config):
            if chunk.content:
                full_response += chunk.content
                chunk_count += 1
                
                # å‡å°‘è¿›åº¦æ›´æ–°é¢‘ç‡ï¼Œåªåœ¨ç‰¹å®šçš„chunkæ•°æ—¶æ›´æ–°
                if chunk_count % 5 == 0:
                    writer({
                        "step": "supervision",
                        "status": "æ­£åœ¨åˆ¶å®šåè°ƒå†³ç­–...",
                        "progress": min(80, 60 + (chunk_count // 5) * 4),
                        "reasoning": full_response[:200] + "..." if len(full_response) > 200 else full_response
                    })
        
        # è§£æå†³ç­–
        decision_text = full_response.lower().strip()
        
        # æ™ºèƒ½å†³ç­–é€»è¾‘
        if not state["outline"]:
            next_action = "outline_generation"
            reasoning = "éœ€è¦é¦–å…ˆç”ŸæˆæŠ¥å‘Šå¤§çº²"
        elif len(state["research_results"]) < 5:  # éœ€è¦è¶³å¤Ÿçš„ç ”ç©¶æ•°æ®
            next_action = "research_execution"
            reasoning = "éœ€è¦è¿›è¡Œæ·±åº¦ç ”ç©¶æ”¶é›†æ•°æ®"
        elif len(state["analysis_insights"]) < 3:  # éœ€è¦åˆ†ææ´å¯Ÿ
            next_action = "analysis_generation"
            reasoning = "éœ€è¦ç”Ÿæˆåˆ†ææ´å¯Ÿ"
        elif not state["final_report"]:
            next_action = "content_creation"
            reasoning = "éœ€è¦åˆ›å»ºæœ€ç»ˆæŠ¥å‘Šå†…å®¹"
        elif state["final_report"] and not state.get("validated", False):
            next_action = "quality_validation"
            reasoning = "éœ€è¦è¿›è¡Œè´¨é‡éªŒè¯"
        else:
            next_action = "finish"
            reasoning = "æŠ¥å‘Šç”Ÿæˆæµç¨‹å®Œæˆ"
        
        # åŸºäºå“åº”å†…å®¹è¿›è¡Œå¾®è°ƒ
        if "outline" in decision_text and not state["outline"]:
            next_action = "outline_generation"
        elif "research" in decision_text:
            next_action = "research_execution"
        elif "analysis" in decision_text or "insight" in decision_text:
            next_action = "analysis_generation"
        elif "content" in decision_text or "write" in decision_text:
            next_action = "content_creation"
        elif "validation" in decision_text or "quality" in decision_text:
            next_action = "quality_validation"
        elif "finish" in decision_text or "complete" in decision_text:
            next_action = "finish"
        
        # æ›´æ–°çŠ¶æ€
        execution_time = time.time() - start_time
        update_performance_metrics(state, "supervisor", execution_time)
        
        state["current_step"] = f"supervised_{next_action}"
        state["execution_path"] = state["execution_path"] + ["supervisor"]
        state["agent_results"]["supervisor"] = {
            "next_action": next_action,
            "reasoning": reasoning,
            "execution_time": execution_time
        }
        
        # æ·»åŠ ç›‘ç£æ¶ˆæ¯
        supervision_message = f"""
        ğŸ§  æ™ºèƒ½ç›‘ç£åè°ƒå®Œæˆï¼š
        
        ğŸ“Š å½“å‰çŠ¶æ€åˆ†æï¼š
        - å¤§çº²çŠ¶æ€ï¼š{'å·²ç”Ÿæˆ' if state['outline'] else 'å¾…ç”Ÿæˆ'}
        - ç ”ç©¶æ•°æ®ï¼š{len(state['research_results'])}æ¡
        - åˆ†ææ´å¯Ÿï¼š{len(state['analysis_insights'])}ä¸ª
        - æŠ¥å‘ŠçŠ¶æ€ï¼š{'å·²ç”Ÿæˆ' if state['final_report'] else 'å¾…ç”Ÿæˆ'}
        
        ğŸ¯ å†³ç­–ç»“æœï¼š
        - ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š{next_action}
        - å†³ç­–ç†ç”±ï¼š{reasoning}
        - æ‰§è¡Œæ—¶é—´ï¼š{execution_time:.2f}ç§’
        """
        
        state["messages"] = state["messages"] + [AIMessage(content=supervision_message)]
        
        writer({
            "step": "supervision",
            "status": "ç›‘ç£åè°ƒå®Œæˆ",
            "progress": 100,
            "next_action": next_action,
            "reasoning": reasoning,
            "execution_time": execution_time
        })
        
        logger.info(f"ç›‘ç£åè°ƒå®Œæˆ: {next_action} - {reasoning}")
        return state
        
    except Exception as e:
        logger.error(f"ç›‘ç£åè°ƒå¤±è´¥: {str(e)}")
        writer({
            "step": "supervision",
            "status": f"ç›‘ç£åè°ƒå¤±è´¥: {str(e)}",
            "progress": -1
        })
        
        state["error_log"] = state["error_log"] + [f"ç›‘ç£åè°ƒé”™è¯¯: {str(e)}"]
        state["current_step"] = "supervision_failed"
        return state

# ============================================================================
# å¤§çº²ç”ŸæˆèŠ‚ç‚¹
# ============================================================================

async def outline_generation_node(state: DeepResearchState, config=None) -> DeepResearchState:
    """å¤§çº²ç”ŸæˆèŠ‚ç‚¹"""
    writer = get_stream_writer()
    writer({
        "step": "outline_generation",
        "status": "å¼€å§‹ç”Ÿæˆæ·±åº¦ç ”ç©¶å¤§çº²",
        "progress": 0
    })
    
    try:
        start_time = time.time()
        llm = create_llm()
        parser = JsonOutputParser(pydantic_object=ReportOutline)
        
        # æ„å»ºé«˜çº§å¤§çº²ç”Ÿæˆæç¤º
        outline_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸“ä¸šçš„æŠ¥å‘Šå¤§çº²è®¾è®¡ä¸“å®¶ã€‚è¯·ç”Ÿæˆè¯¦ç»†çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šå¤§çº²ã€‚
            
            è¦æ±‚ï¼š
            1. å¤§çº²ç¬¦åˆ{report_type}æŠ¥å‘Šçš„æ ‡å‡†ç»“æ„
            2. é’ˆå¯¹{target_audience}è¯»è€…ç¾¤ä½“è®¾è®¡
            3. ç ”ç©¶æ·±åº¦ä¸º{depth_level}çº§åˆ«
            4. ç›®æ ‡å­—æ•°çº¦{target_length}å­—
            5. æ¯ä¸ªç« èŠ‚åŒ…å«ç ”ç©¶æŸ¥è¯¢å…³é”®è¯
            6. ç« èŠ‚ä¼˜å…ˆçº§åˆç†åˆ†é…
            
            {format_instructions}"""),
            ("human", """
            è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆä¸“ä¸šçš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šå¤§çº²ï¼š
            
            ç ”ç©¶ä¸»é¢˜ï¼š{topic}
            æŠ¥å‘Šç±»å‹ï¼š{report_type}
            ç›®æ ‡è¯»è€…ï¼š{target_audience}
            æ·±åº¦çº§åˆ«ï¼š{depth_level}
            
            è¯·ç¡®ä¿å¤§çº²ç»“æ„å®Œæ•´ã€é€»è¾‘æ¸…æ™°ã€ä¾¿äºæ·±åº¦ç ”ç©¶ã€‚
            """)
        ])
        
        input_data = {
            "topic": state["topic"],
            "report_type": state["report_type"],
            "target_audience": state["target_audience"],
            "depth_level": state["depth_level"],
            "target_length": state["target_length"],
            "format_instructions": parser.get_format_instructions()
        }
        
        writer({
            "step": "outline_generation",
            "status": "æ­£åœ¨ç”Ÿæˆä¸“ä¸šå¤§çº²...",
            "progress": 30
        })
        
        # åˆ›å»ºLLMé“¾å¹¶æµå¼æ‰§è¡Œ
        llm_chain = outline_prompt | llm | parser
        
        outline_data = None
        chunk_count = 0
        current_outline_display = ""
        
        async for chunk in llm_chain.astream(input_data, config=config):
            outline_data = chunk
            chunk_count += 1
            # å®æ—¶æ˜¾ç¤ºå¤§çº²å†…å®¹ï¼ˆæ¯5ä¸ªchunkæ›´æ–°ä¸€æ¬¡ä»¥å‡å°‘é¢‘ç‡ï¼‰
            if chunk_count % 5 == 0:
                # æ„å»ºå½“å‰å¤§çº²çš„æ˜¾ç¤ºæ–‡æœ¬
                if hasattr(chunk, 'title'):
                    current_outline_display = f"ğŸ¯ æ ‡é¢˜ï¼š{chunk.title}\n"
                if hasattr(chunk, 'sections') and chunk.sections:
                    current_outline_display += f"ğŸ“š ç« èŠ‚({len(chunk.sections)}ä¸ª):\n"
                    for i, section in enumerate(chunk.sections[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ªç« èŠ‚
                        if hasattr(section, 'title'):
                            current_outline_display += f"  {i}. {section.title}\n"
                            if hasattr(section, 'description'):
                                current_outline_display += f"     {section.description}\n"
                    if len(chunk.sections) > 3:
                        current_outline_display += f"  ... è¿˜æœ‰{len(chunk.sections)-3}ä¸ªç« èŠ‚"
                
                writer({
                    "step": "outline_generation",
                    "status": "æ­£åœ¨æ„å»ºå¤§çº²ç»“æ„...",
                    "content": chunk,
                    "progress": min(90, 30 + (chunk_count // 5) * 10),
                    "current_outline": current_outline_display,
                    "chunk_count": chunk_count
                })
                
                # å¦‚æœå¤§çº²åŸºæœ¬å®Œæ•´ï¼Œæå‰æ˜¾ç¤º
                if hasattr(chunk, 'title') and hasattr(chunk, 'sections') and len(chunk.sections) >= 3:
                    writer({
                        "step": "outline_generation",
                        "status": "å¤§çº²ç»“æ„å·²ç”Ÿæˆï¼Œæ­£åœ¨å®Œå–„ç»†èŠ‚...",
                        "progress": 85,
                        "partial_outline": chunk,
                        "streaming_content": current_outline_display
                    })
        
        # å¤„ç†ç”Ÿæˆç»“æœ
        if not outline_data:
            # åˆ›å»ºé»˜è®¤å¤§çº²
            outline_data = ReportOutline(
                title=f"{state['topic']} - æ·±åº¦ç ”ç©¶æŠ¥å‘Š",
                executive_summary=f"æœ¬æŠ¥å‘Šå¯¹{state['topic']}è¿›è¡Œå…¨é¢æ·±å…¥çš„ç ”ç©¶åˆ†æï¼Œä¸º{state['target_audience']}æä¾›ä¸“ä¸šæ´å¯Ÿã€‚",
                sections=[
                    ReportSection(
                        id="background",
                        title="ç ”ç©¶èƒŒæ™¯ä¸ç°çŠ¶",
                        description="åˆ†æç ”ç©¶èƒŒæ™¯ã€å‘å±•å†ç¨‹å’Œå½“å‰çŠ¶æ€",
                        key_points=["å†å²å‘å±•", "ç°çŠ¶åˆ†æ", "å…³é”®ç‰¹å¾"],
                        research_queries=[f"{state['topic']} å‘å±•å†å²", f"{state['topic']} ç°çŠ¶åˆ†æ", f"{state['topic']} å¸‚åœºè§„æ¨¡"],
                        priority=5
                    ),
                    ReportSection(
                        id="deep_analysis",
                        title="æ·±åº¦åˆ†æä¸æ´å¯Ÿ",
                        description="è¿›è¡Œæ·±å…¥åˆ†æï¼Œè¯†åˆ«å…³é”®è¶‹åŠ¿å’Œæ¨¡å¼",
                        key_points=["æ ¸å¿ƒé©±åŠ¨å› ç´ ", "å‘å±•è¶‹åŠ¿", "å½±å“å› ç´ "],
                        research_queries=[f"{state['topic']} è¶‹åŠ¿åˆ†æ", f"{state['topic']} å½±å“å› ç´ ", f"{state['topic']} å‘å±•é¢„æµ‹"],
                        priority=5
                    ),
                    ReportSection(
                        id="case_studies",
                        title="æ¡ˆä¾‹ç ”ç©¶ä¸åº”ç”¨",
                        description="åˆ†æå…¸å‹æ¡ˆä¾‹å’Œå®é™…åº”ç”¨æƒ…å†µ",
                        key_points=["æˆåŠŸæ¡ˆä¾‹", "åº”ç”¨åœºæ™¯", "å®æ–½ç»éªŒ"],
                        research_queries=[f"{state['topic']} æ¡ˆä¾‹ç ”ç©¶", f"{state['topic']} åº”ç”¨å®ä¾‹", f"{state['topic']} æœ€ä½³å®è·µ"],
                        priority=4
                    ),
                    ReportSection(
                        id="challenges_opportunities",
                        title="æŒ‘æˆ˜ä¸æœºé‡åˆ†æ",
                        description="è¯†åˆ«é¢ä¸´çš„æŒ‘æˆ˜å’Œå‘å±•æœºé‡",
                        key_points=["ä¸»è¦æŒ‘æˆ˜", "å‘å±•æœºé‡", "é£é™©è¯„ä¼°"],
                        research_queries=[f"{state['topic']} æŒ‘æˆ˜åˆ†æ", f"{state['topic']} å‘å±•æœºä¼š", f"{state['topic']} é£é™©è¯„ä¼°"],
                        priority=4
                    ),
                    ReportSection(
                        id="future_outlook",
                        title="æœªæ¥å±•æœ›ä¸å»ºè®®",
                        description="é¢„æµ‹æœªæ¥å‘å±•å¹¶æå‡ºä¸“ä¸šå»ºè®®",
                        key_points=["å‘å±•é¢„æµ‹", "æˆ˜ç•¥å»ºè®®", "è¡ŒåŠ¨è®¡åˆ’"],
                        research_queries=[f"{state['topic']} æœªæ¥å‘å±•", f"{state['topic']} å‘å±•å»ºè®®", f"{state['topic']} æˆ˜ç•¥è§„åˆ’"],
                        priority=3
                    )
                ],
                methodology="é‡‡ç”¨æ–‡çŒ®ç ”ç©¶ã€æ¡ˆä¾‹åˆ†æã€è¶‹åŠ¿é¢„æµ‹å’Œä¸“å®¶æ´å¯Ÿç›¸ç»“åˆçš„ç»¼åˆç ”ç©¶æ–¹æ³•",
                target_audience=state["target_audience"],
                estimated_length=state["target_length"]
            )
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        if hasattr(outline_data, 'dict'):
            outline_dict = outline_data.dict()
        else:
            outline_dict = dict(outline_data) if outline_data else {}
        
        # æ›´æ–°çŠ¶æ€
        execution_time = time.time() - start_time
        update_performance_metrics(state, "outline_generator", execution_time)
        update_task_status(state, "outline_generation", TaskStatus.COMPLETED)
        
        state["outline"] = outline_dict
        state["current_step"] = "outline_generated"
        state["execution_path"] = state["execution_path"] + ["outline_generation"]
        
        # åˆ›å»ºå¤§çº²å±•ç¤ºæ¶ˆæ¯
        sections_text = "\n".join([
            f"  {i+1}. {section['title']}\n     {section['description']}\n     å…³é”®è¯: {', '.join(section['research_queries'][:3])}"
            for i, section in enumerate(outline_dict.get("sections", []))
        ])
        
        outline_message = f"""
        ğŸ“‹ æ·±åº¦ç ”ç©¶å¤§çº²ç”Ÿæˆå®Œæˆï¼š
        
        ğŸ¯ æŠ¥å‘Šæ ‡é¢˜ï¼š{outline_dict.get('title', 'æœªçŸ¥')}
        
        ğŸ“ æ‰§è¡Œæ‘˜è¦ï¼š
        {outline_dict.get('executive_summary', 'æ— æ‘˜è¦')}
        
        ğŸ“š ç ”ç©¶ç« èŠ‚ï¼š
        {sections_text}
        
        ğŸ” ç ”ç©¶æ–¹æ³•ï¼š{outline_dict.get('methodology', 'æœªæŒ‡å®š')}
        ğŸ“Š é¢„ä¼°å­—æ•°ï¼š{outline_dict.get('estimated_length', 0):,}å­—
        â±ï¸ ç”Ÿæˆæ—¶é—´ï¼š{execution_time:.2f}ç§’
        """
        
        state["messages"] = state["messages"] + [AIMessage(content=outline_message)]
        
        writer({
            "step": "outline_generation",
            "status": "æ·±åº¦ç ”ç©¶å¤§çº²ç”Ÿæˆå®Œæˆ",
            "progress": 100,
            "sections_count": len(outline_dict.get("sections", [])),
            "execution_time": execution_time,
            "content": {
                "type": "outline",
                "data": outline_dict,
                "display_text": outline_message
            }
        })
        
        logger.info(f"å¤§çº²ç”Ÿæˆå®Œæˆ: {len(outline_dict.get('sections', []))}ä¸ªç« èŠ‚")
        return state
        
    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        writer({
            "step": "outline_generation",
            "status": f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}",
            "progress": -1
        })
        
        state["error_log"] = state["error_log"] + [f"å¤§çº²ç”Ÿæˆé”™è¯¯: {str(e)}"]
        state["current_step"] = "outline_generation_failed"
        update_task_status(state, "outline_generation", TaskStatus.FAILED)
        return state

# ============================================================================
# äº¤äº’ç¡®è®¤èŠ‚ç‚¹
# ============================================================================

def create_interaction_node(interaction_type: InteractionType):
    """åˆ›å»ºäº¤äº’ç¡®è®¤èŠ‚ç‚¹çš„å·¥å‚å‡½æ•°"""
    
    def interaction_node(state: DeepResearchState) -> DeepResearchState:
        """é€šç”¨äº¤äº’ç¡®è®¤èŠ‚ç‚¹"""
        writer = get_stream_writer()
        
        interaction_config = get_interaction_config(interaction_type)
        mode = state["mode"]
        
        writer({
            "step": f"interaction_{interaction_type.value}",
            "status": f"å¤„ç†{interaction_config['title']}",
            "progress": 0,
            "interaction_type": interaction_type.value,
            "mode": mode.value
        })
        
        # Copilotæ¨¡å¼è‡ªåŠ¨é€šè¿‡
        if mode == ReportMode.COPILOT:
            state["approval_status"][interaction_type.value] = True
            state["user_feedback"][interaction_type.value] = {"approved": True, "auto": True}
            
            writer({
                "step": f"interaction_{interaction_type.value}",
                "status": "Copilotæ¨¡å¼è‡ªåŠ¨é€šè¿‡",
                "progress": 100,
                "auto_approved": True
            })
            
            state["messages"] = state["messages"] + [
                AIMessage(content=f"ğŸ¤– Copilotæ¨¡å¼ï¼š{interaction_config['copilot_message']}")
            ]
            
            return state
        
        # äº¤äº’æ¨¡å¼éœ€è¦ç”¨æˆ·ç¡®è®¤
        message_content = format_interaction_message(state, interaction_type, interaction_config)
        
        writer({
            "step": f"interaction_{interaction_type.value}",
            "status": "ç­‰å¾…ç”¨æˆ·ç¡®è®¤",
            "progress": 50,
            "awaiting_user_input": True
        })
        
        # ä½¿ç”¨interruptç­‰å¾…ç”¨æˆ·è¾“å…¥
        user_response = interrupt({
            "type": interaction_type.value,
            "title": interaction_config["title"],
            "message": message_content,
            "options": interaction_config["options"],
            "default": interaction_config.get("default", "continue")
        })
        
        # å¤„ç†ç”¨æˆ·å“åº”
        approved = user_response.get("approved", True) if isinstance(user_response, dict) else True
        state["approval_status"][interaction_type.value] = approved
        state["user_feedback"][interaction_type.value] = user_response
        
        # è®°å½•äº¤äº’å†å²
        add_user_interaction(state, interaction_type.value, user_response)
        
        writer({
            "step": f"interaction_{interaction_type.value}",
            "status": "ç”¨æˆ·ç¡®è®¤å®Œæˆ",
            "progress": 100,
            "user_response": user_response,
            "approved": approved
        })
        
        # æ·»åŠ ç¡®è®¤æ¶ˆæ¯
        status_emoji = "âœ…" if approved else "âŒ"
        confirmation_message = f"{status_emoji} {interaction_config['title']}ï¼š{'ç¡®è®¤é€šè¿‡' if approved else 'è¢«æ‹’ç»'}"
        
        state["messages"] = state["messages"] + [AIMessage(content=confirmation_message)]
        
        return state
    
    return interaction_node

def get_interaction_config(interaction_type: InteractionType) -> Dict[str, Any]:
    """è·å–äº¤äº’é…ç½®"""
    configs = {
        InteractionType.OUTLINE_CONFIRMATION: {
            "title": "å¤§çº²ç¡®è®¤",
            "copilot_message": "è‡ªåŠ¨ç¡®è®¤æŠ¥å‘Šå¤§çº²ï¼Œç»§ç»­æ‰§è¡Œç ”ç©¶",
            "options": ["ç¡®è®¤ç»§ç»­", "ä¿®æ”¹å¤§çº²", "é‡æ–°ç”Ÿæˆ"],
            "default": "ç¡®è®¤ç»§ç»­"
        },
        InteractionType.RESEARCH_PERMISSION: {
            "title": "ç ”ç©¶æƒé™ç¡®è®¤",
            "copilot_message": "è‡ªåŠ¨å…è®¸è¿›è¡Œæ·±åº¦ç ”ç©¶å’Œæ•°æ®æ”¶é›†",
            "options": ["å…è®¸ç ”ç©¶", "è·³è¿‡ç ”ç©¶", "é™åˆ¶èŒƒå›´"],
            "default": "å…è®¸ç ”ç©¶"
        },
        InteractionType.ANALYSIS_APPROVAL: {
            "title": "åˆ†æç»“æœå®¡æ‰¹",
            "copilot_message": "è‡ªåŠ¨ç¡®è®¤åˆ†æç»“æœï¼Œç»§ç»­å†…å®¹ç”Ÿæˆ",
            "options": ["ç¡®è®¤åˆ†æ", "é‡æ–°åˆ†æ", "è°ƒæ•´æ–¹å‘"],
            "default": "ç¡®è®¤åˆ†æ"
        },
        InteractionType.CONTENT_REVIEW: {
            "title": "å†…å®¹å®¡æŸ¥",
            "copilot_message": "è‡ªåŠ¨é€šè¿‡å†…å®¹å®¡æŸ¥ï¼Œå‡†å¤‡æœ€ç»ˆæŠ¥å‘Š",
            "options": ["é€šè¿‡å®¡æŸ¥", "ä¿®æ”¹å†…å®¹", "é‡å†™ç« èŠ‚"],
            "default": "é€šè¿‡å®¡æŸ¥"
        },
        InteractionType.FINAL_APPROVAL: {
            "title": "æœ€ç»ˆå®¡æ‰¹",
            "copilot_message": "è‡ªåŠ¨å®Œæˆæœ€ç»ˆå®¡æ‰¹ï¼ŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ",
            "options": ["æœ€ç»ˆç¡®è®¤", "å†æ¬¡ä¿®æ”¹", "ç”Ÿæˆæ–°ç‰ˆæœ¬"],
            "default": "æœ€ç»ˆç¡®è®¤"
        }
    }
    return configs.get(interaction_type, {})

def format_interaction_message(state: DeepResearchState, interaction_type: InteractionType, config: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–äº¤äº’æ¶ˆæ¯"""
    if interaction_type == InteractionType.OUTLINE_CONFIRMATION:
        outline = state.get("outline", {})
        sections_text = "\n".join([
            f"  {i+1}. {section.get('title', 'æœªçŸ¥ç« èŠ‚')}\n     {section.get('description', 'æ— æè¿°')}"
            for i, section in enumerate(outline.get("sections", []))
        ])
        return f"""
            è¯·ç¡®è®¤ä»¥ä¸‹æ·±åº¦ç ”ç©¶æŠ¥å‘Šå¤§çº²ï¼š

            ğŸ“‹ æ ‡é¢˜ï¼š{outline.get('title', 'æœªçŸ¥æ ‡é¢˜')}

            ğŸ“ æ‘˜è¦ï¼š{outline.get('executive_summary', 'æ— æ‘˜è¦')}

            ğŸ“š ç« èŠ‚ç»“æ„ï¼š
            {sections_text}

            ğŸ” ç ”ç©¶æ–¹æ³•ï¼š{outline.get('methodology', 'æœªæŒ‡å®š')}
            ğŸ“Š é¢„ä¼°å­—æ•°ï¼š{outline.get('estimated_length', 0):,}å­—
            ğŸ‘¥ ç›®æ ‡è¯»è€…ï¼š{outline.get('target_audience', 'æœªçŸ¥')}
        """
    elif interaction_type == InteractionType.RESEARCH_PERMISSION:
        return f"""
            æ˜¯å¦å…è®¸å¯¹ä¸»é¢˜ã€Œ{state['topic']}ã€è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼Ÿ

            ç ”ç©¶å°†åŒ…æ‹¬ï¼š
            - å¤šæºç½‘ç»œæœç´¢å’Œä¿¡æ¯æ”¶é›†
            - ç›¸å…³æ¡ˆä¾‹å’Œæ•°æ®åˆ†æ
            - è¶‹åŠ¿è¯†åˆ«å’Œæ¨¡å¼å‘ç°
            - ä¸“ä¸šæ´å¯Ÿç”Ÿæˆ

            é¢„è®¡ç ”ç©¶æ—¶é—´ï¼š5-10åˆ†é’Ÿ
        """
    else:
        return f"è¯·ç¡®è®¤{config['title']}ç›¸å…³è®¾ç½®"

# åˆ›å»ºäº¤äº’èŠ‚ç‚¹å®ä¾‹
outline_confirmation_node = create_interaction_node(InteractionType.OUTLINE_CONFIRMATION)
research_permission_node = create_interaction_node(InteractionType.RESEARCH_PERMISSION)
analysis_approval_node = create_interaction_node(InteractionType.ANALYSIS_APPROVAL)
content_review_node = create_interaction_node(InteractionType.CONTENT_REVIEW)
final_approval_node = create_interaction_node(InteractionType.FINAL_APPROVAL)

# ============================================================================
# Multi-Agentæ‰§è¡ŒèŠ‚ç‚¹
# ============================================================================

async def multi_agent_research_node(state: DeepResearchState, config=None) -> DeepResearchState:
    """ğŸš€ çœŸæ­£çš„Multi-Agentå¹¶è¡Œç ”ç©¶æ‰§è¡ŒèŠ‚ç‚¹"""
    writer = get_stream_writer()
    writer({
        "step": "multi_agent_research",
        "status": "ğŸ¤– å¯åŠ¨Multi-Agentå¹¶è¡Œç ”ç©¶ç³»ç»Ÿ",
        "progress": 0
    })
    
    try:
        start_time = time.time()
        agents = create_specialized_agents()
        
        outline = state.get("outline", {})
        sections = outline.get("sections", [])
        
        if not sections:
            writer({
                "step": "multi_agent_research",
                "status": "æ²¡æœ‰å¯ç ”ç©¶çš„ç« èŠ‚",
                "progress": 100
            })
            return state
        
        writer({
            "step": "multi_agent_research",
            "status": f"ğŸ”§ å¯åŠ¨3ä¸ªä¸“ä¸šAgentå¹¶è¡Œç ”ç©¶{len(sections)}ä¸ªç« èŠ‚",
            "progress": 10
        })
        
        # æ™ºèƒ½ç”Ÿæˆç ”ç©¶æŸ¥è¯¢
        def generate_smart_queries(topic, section):
            """åŸºäºä¸»é¢˜å’Œç« èŠ‚åŠ¨æ€ç”Ÿæˆç ”ç©¶æŸ¥è¯¢"""
            section_title = section.get('title', '')
            key_points = section.get('key_points', [])
            
            # åŸºç¡€æŸ¥è¯¢ç­–ç•¥
            base_queries = [
                f"{topic} {section_title}",  # æ ¸å¿ƒä¸»é¢˜æŸ¥è¯¢
                f"{section_title} 2024å¹´æœ€æ–°å‘å±•",  # æ—¶é—´ç»´åº¦
                f"{section_title} æˆåŠŸæ¡ˆä¾‹åˆ†æ"  # æ¡ˆä¾‹ç»´åº¦
            ]
            
            # åŸºäºå…³é”®ç‚¹çš„ç²¾ç¡®æŸ¥è¯¢
            for point in key_points[:2]:
                base_queries.append(f"{topic} {point} å®è·µåº”ç”¨")
            
            # æ ¹æ®ç« èŠ‚ç±»å‹æ·»åŠ ç‰¹å®šæŸ¥è¯¢
            if "èƒŒæ™¯" in section_title or "ç°çŠ¶" in section_title:
                base_queries.append(f"{topic} å‘å±•å†å² å¸‚åœºè§„æ¨¡")
            elif "åˆ†æ" in section_title or "è¶‹åŠ¿" in section_title:
                base_queries.append(f"{topic} å‘å±•è¶‹åŠ¿ é¢„æµ‹åˆ†æ")
            elif "æŒ‘æˆ˜" in section_title or "é—®é¢˜" in section_title:
                base_queries.append(f"{topic} é¢ä¸´æŒ‘æˆ˜ è§£å†³æ–¹æ¡ˆ")
            elif "å‰æ™¯" in section_title or "æœªæ¥" in section_title:
                base_queries.append(f"{topic} æœªæ¥å‘å±• æŠ•èµ„æœºä¼š")
            
            return base_queries[:5]  # æ¯ä¸ªç« èŠ‚æœ€å¤š5ä¸ªé«˜è´¨é‡æŸ¥è¯¢
        
        # Agentä»»åŠ¡åˆ†é…ç­–ç•¥
        def assign_agent_by_section(section):
            """æ ¹æ®ç« èŠ‚ç‰¹ç‚¹æ™ºèƒ½åˆ†é…Agent"""
            title = section.get('title', '').lower()
            
            if any(keyword in title for keyword in ['èƒŒæ™¯', 'ç°çŠ¶', 'å‘å±•', 'å†å²']):
                return AgentType.RESEARCHER  # ç ”ç©¶å‹ç« èŠ‚
            elif any(keyword in title for keyword in ['åˆ†æ', 'è¶‹åŠ¿', 'é¢„æµ‹', 'æ´å¯Ÿ']):
                return AgentType.ANALYST  # åˆ†æå‹ç« èŠ‚
            elif any(keyword in title for keyword in ['æ¡ˆä¾‹', 'åº”ç”¨', 'å®è·µ']):
                return [AgentType.RESEARCHER, AgentType.ANALYST]  # åä½œå‹ç« èŠ‚
            else:
                return AgentType.RESEARCHER  # é»˜è®¤ç ”ç©¶å‹
        
        # å‡†å¤‡å¹¶è¡Œä»»åŠ¡
        research_tasks = []
        for section in sections:
            smart_queries = generate_smart_queries(state["topic"], section)
            assigned_agent = assign_agent_by_section(section)
            
            research_tasks.append({
                "section": section,
                "queries": smart_queries,
                "agent_type": assigned_agent,
                "priority": section.get("priority", 3)
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡
        research_tasks.sort(key=lambda x: x["priority"], reverse=True)
        
        writer({
            "step": "multi_agent_research",
            "status": "âš¡ å¹¶è¡Œæ‰§è¡Œç ”ç©¶ä»»åŠ¡...",
            "progress": 20,
            "task_count": len(research_tasks),
            "agent_distribution": {
                "researcher_tasks": len([t for t in research_tasks if t["agent_type"] == AgentType.RESEARCHER]),
                "analyst_tasks": len([t for t in research_tasks if t["agent_type"] == AgentType.ANALYST]),
                "collaborative_tasks": len([t for t in research_tasks if isinstance(t["agent_type"], list)])
            }
        })
        
        # çœŸæ­£çš„Multi-Agentå¹¶è¡Œæ‰§è¡Œ
        async def research_section_with_agent(task):
            """ä½¿ç”¨æŒ‡å®šAgentæ‰§è¡Œç« èŠ‚ç ”ç©¶"""
            section = task["section"]
            queries = task["queries"]
            agent_type = task["agent_type"]
            
            section_results = []
            
            # å¹¶è¡Œæœç´¢æ‰€æœ‰æŸ¥è¯¢
            search_tasks = []
            for query in queries:
                search_tasks.append(
                    asyncio.create_task(
                        asyncio.to_thread(
                            multi_source_research.invoke,
                            {
                                "topic": state["topic"],
                                "research_queries": [query],
                                "max_results_per_query": 3,  # å¢åŠ ç»“æœæ•°é‡
                                "search_depth": "advanced"  # æ·±åº¦æœç´¢
                            }
                        )
                    )
                )
            
            # ç­‰å¾…æ‰€æœ‰æœç´¢å®Œæˆ
            search_results = await asyncio.gather(*search_tasks, return_exceptions=True)
            
            # å¤„ç†æœç´¢ç»“æœ
            for results in search_results:
                if isinstance(results, list):
                    for result in results:
                        if not result.get("error"):
                            # æ·»åŠ Agentä¿¡æ¯
                            result["section_id"] = section.get("id")
                            result["section_title"] = section.get("title")
                            result["assigned_agent"] = str(agent_type)
                            result["research_priority"] = task["priority"]
                            section_results.append(result)
            
            return section_results
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ç ”ç©¶ä»»åŠ¡
        section_tasks = [research_section_with_agent(task) for task in research_tasks]
        section_results_list = await asyncio.gather(*section_tasks, return_exceptions=True)
        
        # æ±‡æ€»ç»“æœå’Œè´¨é‡è¯„ä¼°
        all_research_results = []
        completed_tasks = 0
        
        for i, section_results in enumerate(section_results_list):
            if isinstance(section_results, list):
                for result in section_results:
                    # è®¡ç®—è´¨é‡è¯„åˆ†
                    result["research_quality_score"] = calculate_research_quality(result)
                    add_research_result(state, result)
                    all_research_results.append(result)
                
                completed_tasks += 1
                progress = 20 + (completed_tasks / len(research_tasks)) * 60
                
                writer({
                    "step": "multi_agent_research",
                    "status": f"âœ… ç« èŠ‚ç ”ç©¶å®Œæˆ: {research_tasks[i]['section'].get('title', 'æœªçŸ¥')} ({len(section_results)}ä¸ªç»“æœ)",
                    "progress": int(progress),
                    "completed_sections": completed_tasks,
                    "total_sections": len(sections),
                    "agent_used": research_tasks[i]["agent_type"]
                })
            else:
                logger.warning(f"ç« èŠ‚ {research_tasks[i]['section'].get('title')} ç ”ç©¶å¤±è´¥: {section_results}")
        
        # æ•°æ®æ¸…ç†å’Œä¼˜åŒ–
        writer({
            "step": "multi_agent_research",
            "status": "ğŸ” æ‰§è¡Œæ•°æ®è´¨é‡åˆ†æå’Œæ™ºèƒ½å»é‡...",
            "progress": 85
        })
        
        # æ™ºèƒ½å»é‡å’Œè´¨é‡ç­›é€‰
        unique_results = []
        seen_urls = set()
        content_hashes = set()
        
        for result in all_research_results:
            url = result.get("url", "")
            content = result.get("content", "")
            content_hash = hash(content[:200])  # åŸºäºå†…å®¹å‰200å­—ç¬¦å»é‡
            
            if url and url not in seen_urls and content_hash not in content_hashes:
                seen_urls.add(url)
                content_hashes.add(content_hash)
                unique_results.append(result)
        
        # æŒ‰è´¨é‡å’Œä¼˜å…ˆçº§æ’åº
        unique_results.sort(
            key=lambda x: (x.get("research_quality_score", 0), x.get("research_priority", 0)), 
            reverse=True
        )
        
        # é™åˆ¶æœ€ç»ˆç»“æœæ•°é‡ï¼ˆä¿ç•™æœ€é«˜è´¨é‡çš„ç»“æœï¼‰
        max_results = len(sections) * 8  # æ¯ç« èŠ‚å¹³å‡8ä¸ªé«˜è´¨é‡ç»“æœ
        unique_results = unique_results[:max_results]
        
        # æ›´æ–°çŠ¶æ€
        execution_time = time.time() - start_time
        update_performance_metrics(state, "multi_agent_researcher", execution_time)
        update_task_status(state, "research_execution", TaskStatus.COMPLETED)
        
        state["current_step"] = "research_completed"
        state["execution_path"] = state["execution_path"] + ["multi_agent_research"]
        
        # è®¡ç®—æ•ˆç‡ç»Ÿè®¡
        avg_quality = sum(r.get('research_quality_score', 0) for r in unique_results) / max(len(unique_results), 1)
        estimated_serial_time = len(sections) * 45  # ä¼°è®¡ä¸²è¡Œæ‰§è¡Œæ—¶é—´
        efficiency_gain = max(0, estimated_serial_time - execution_time)
        
        # ç”Ÿæˆè¯¦ç»†ç ”ç©¶æŠ¥å‘Š
        research_message = f"""
        ğŸ¤– Multi-Agentå¹¶è¡Œç ”ç©¶ç³»ç»Ÿæ‰§è¡Œå®Œæˆï¼
        
        ğŸ“Š æ‰§è¡Œç»Ÿè®¡ï¼š
        - å¹¶è¡Œç« èŠ‚ï¼š{len(research_tasks)}ä¸ªåŒæ—¶å¤„ç†
        - é«˜è´¨é‡æ•°æ®ï¼š{len(unique_results)}æ¡ï¼ˆæ™ºèƒ½å»é‡åï¼‰
        - å¹³å‡è´¨é‡è¯„åˆ†ï¼š{avg_quality:.3f}/1.0
        - å®é™…æ‰§è¡Œæ—¶é—´ï¼š{execution_time:.2f}ç§’
        
        ğŸš€ æ€§èƒ½æå‡ï¼š
        - é¢„è®¡ä¸²è¡Œæ—¶é—´ï¼š{estimated_serial_time}ç§’
        - å¹¶è¡Œæ•ˆç‡æå‡ï¼š{efficiency_gain:.1f}ç§’ ({efficiency_gain/max(estimated_serial_time, 1)*100:.1f}%)
        - å¹³å‡æ¯ç« èŠ‚ï¼š{execution_time/len(sections):.1f}ç§’
        
        ğŸ¯ å„ç« èŠ‚ç ”ç©¶è´¨é‡ï¼š
        {chr(10).join([f"  â€¢ {section.get('title', 'æœªçŸ¥ç« èŠ‚')}: {len([r for r in unique_results if r.get('section_id') == section.get('id')])}æ¡æ•°æ® (è´¨é‡: {sum(r.get('research_quality_score', 0) for r in unique_results if r.get('section_id') == section.get('id'))/max(len([r for r in unique_results if r.get('section_id') == section.get('id')]), 1):.2f})" for section in sections])}
        
        âš¡ ç³»ç»Ÿæ™ºèƒ½åŒ–ç‰¹æ€§ï¼š
        - åŠ¨æ€æŸ¥è¯¢ç”Ÿæˆï¼šåŸºäºç« èŠ‚å†…å®¹è‡ªåŠ¨ä¼˜åŒ–æœç´¢ç­–ç•¥
        - æ™ºèƒ½Agentåˆ†é…ï¼šæ ¹æ®ç« èŠ‚ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„ä¸“ä¸šAgent
        - è´¨é‡è¯„ä¼°ç³»ç»Ÿï¼šå¤šç»´åº¦è¯„åˆ†ç¡®ä¿æ•°æ®è´¨é‡
        """
        
        state["messages"] = state["messages"] + [AIMessage(content=research_message)]
        
        writer({
            "step": "multi_agent_research",
            "status": "ğŸ‰ Multi-Agentå¹¶è¡Œç ”ç©¶å®Œæˆï¼",
            "progress": 100,
            "total_results": len(unique_results),
            "execution_time": execution_time,
            "quality_score": avg_quality,
            "efficiency_gain": f"{efficiency_gain:.1f}s ({efficiency_gain/max(estimated_serial_time, 1)*100:.1f}%)",
            "content": {
                "type": "research_summary",
                "data": {
                    "total_results": len(unique_results),
                    "sections_covered": len(sections),
                    "avg_quality": avg_quality,
                    "execution_time": execution_time
                }
            }
        })
        
        logger.info(f"Multi-Agentå¹¶è¡Œç ”ç©¶å®Œæˆ: {len(unique_results)}ä¸ªé«˜è´¨é‡ç ”ç©¶ç»“æœï¼Œè´¨é‡è¯„åˆ†{avg_quality:.3f}")
        return state
        
    except Exception as e:
        logger.error(f"Multi-Agentç ”ç©¶å¤±è´¥: {str(e)}")
        writer({
            "step": "multi_agent_research",
            "status": f"âŒ ç ”ç©¶å¤±è´¥: {str(e)}",
            "progress": -1
        })
        
        state["error_log"] = state["error_log"] + [f"Multi-Agentç ”ç©¶é”™è¯¯: {str(e)}"]
        state["current_step"] = "research_failed"
        update_task_status(state, "research_execution", TaskStatus.FAILED)
        return state

def calculate_research_quality(result: Dict[str, Any]) -> float:
    """è®¡ç®—ç ”ç©¶ç»“æœçš„è´¨é‡è¯„åˆ† - å¤šç»´åº¦è¯„ä¼°"""
    score = 0.3  # åŸºç¡€åˆ†
    
    # 1. å†…å®¹è´¨é‡è¯„åˆ† (0-0.3)
    content = result.get("content", "")
    content_length = len(content)
    if content_length > 200:
        score += min(0.3, content_length / 2000)  # é•¿åº¦å¥–åŠ±
    
    # 2. æ ‡é¢˜è´¨é‡è¯„åˆ† (0-0.15)
    title = result.get("title", "")
    if title and len(title) > 10:
        score += 0.1
        if any(keyword in title.lower() for keyword in ['åˆ†æ', 'ç ”ç©¶', 'æŠ¥å‘Š', 'å‘å±•', 'è¶‹åŠ¿']):
            score += 0.05  # ä¸“ä¸šè¯æ±‡å¥–åŠ±
    
    # 3. æ¥æºå¯ä¿¡åº¦è¯„åˆ† (0-0.25)
    url = result.get("url", "")
    if url:
        trusted_domains = [".edu", ".gov", ".org", "wikipedia", "arxiv", "ieee", "acm"]
        if any(domain in url for domain in trusted_domains):
            score += 0.25  # é«˜å¯ä¿¡åº¦æ¥æº
        elif any(domain in url for domain in [".com", ".net", ".io"]):
            score += 0.1   # ä¸€èˆ¬å•†ä¸šæ¥æº
    
    # 4. ç›¸å…³æ€§è¯„åˆ† (0-0.2)
    topic_keywords = result.get("query", "").lower().split()
    content_lower = content.lower()
    relevance_count = sum(1 for keyword in topic_keywords if keyword in content_lower)
    if topic_keywords:
        relevance_ratio = relevance_count / len(topic_keywords)
        score += min(0.2, relevance_ratio * 0.2)
    
    return min(1.0, score)

# ============================================================================
# å…¶ä»–æ ¸å¿ƒèŠ‚ç‚¹ï¼ˆåˆ†æã€å†…å®¹ç”Ÿæˆã€éªŒè¯ï¼‰
# ============================================================================

async def content_creation_node(state: DeepResearchState) -> DeepResearchState:
    """å†…å®¹åˆ›å»ºèŠ‚ç‚¹ - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    writer = get_stream_writer()
    writer({
        "step": "content_creation",
        "status": "å¼€å§‹åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š",
        "progress": 0
    })
    
    try:
        start_time = time.time()
        
        outline = state.get("outline", {})
        research_results = state.get("research_results", [])
        
        if not outline:
            writer({
                "step": "content_creation",
                "status": "æ²¡æœ‰å¤§çº²ï¼Œæ— æ³•åˆ›å»ºæŠ¥å‘Š",
                "progress": 100
            })
            return state
        
        writer({
            "step": "content_creation",
            "status": "æ­£åœ¨ç”ŸæˆæŠ¥å‘Šå†…å®¹...",
            "progress": 20
        })
        
        # ä½¿ç”¨å†™ä½œå·¥å…·ç”Ÿæˆç« èŠ‚å†…å®¹
        sections = outline.get("sections", [])
        generated_sections = []
        
        for i, section in enumerate(sections):
            section_progress = 20 + (i / len(sections)) * 60
            
            writer({
                "step": "content_creation",
                "status": f"ç”Ÿæˆç« èŠ‚: {section.get('title', 'æœªçŸ¥')}",
                "progress": int(section_progress),
                "current_section": section.get('title', ''),
                "section_index": i + 1,
                "total_sections": len(sections)
            })
            
            # è·å–ç›¸å…³ç ”ç©¶æ•°æ®
            section_research = [r for r in research_results 
                              if r.get("section_id") == section.get("id")]
            
            if not section_research:
                # å¦‚æœæ²¡æœ‰ç‰¹å®šç« èŠ‚çš„ç ”ç©¶æ•°æ®ï¼Œä½¿ç”¨å‰å‡ ä¸ªé€šç”¨æ•°æ®
                section_research = research_results[:3]
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›ç ”ç©¶æ•°æ®ï¼Œå¦‚æœå®Œå…¨æ²¡æœ‰ï¼Œåˆ›å»ºé»˜è®¤æ•°æ®
            if not section_research:
                section_research = [{
                    "id": "default",
                    "query": section.get("title", ""),
                    "source_type": "default",
                    "title": f"{section.get('title', '')}ç›¸å…³å†…å®¹", 
                    "content": f"å…³äº{section.get('title', '')}çš„åŸºç¡€ä¿¡æ¯å’Œåˆ†æã€‚",
                    "url": "",
                    "credibility_score": 0.7,
                    "relevance_score": 0.8,
                    "timestamp": time.time()
                }]
            
            try:
                # ç”Ÿæˆç« èŠ‚å†…å®¹
                section_content = section_content_generator.invoke({
                    "section_title": section.get("title", ""),
                    "section_description": section.get("description", ""),
                    "research_data": section_research,
                    "target_words": max(200, state.get("target_length", 2000) // len(sections)),
                    "style": state.get("style", "professional")
                })
                
                if not section_content.get("error"):
                    generated_sections.append(section_content)
                else:
                    logger.warning(f"ç« èŠ‚å†…å®¹ç”Ÿæˆå¤±è´¥: {section.get('title')} - {section_content.get('error')}")
                    
            except Exception as section_error:
                logger.error(f"ç« èŠ‚å†…å®¹ç”Ÿæˆå¼‚å¸¸: {section.get('title')} - {str(section_error)}")
                # åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç« èŠ‚å†…å®¹ä½œä¸ºåå¤‡
                basic_section = {
                    "id": f"basic_{i}",
                    "section_title": section.get("title", ""),
                    "content": f"## {section.get('title', '')}\n\n{section.get('description', '')}\n\næœ¬ç« èŠ‚çš„è¯¦ç»†å†…å®¹æ­£åœ¨å®Œå–„ä¸­ã€‚",
                    "word_count": 50,
                    "target_words": state.get("target_length", 2000) // len(sections),
                    "style": state.get("style", "professional"),
                    "sources_used": len(section_research),
                    "generated_at": time.time(),
                    "quality_score": 60
                }
                generated_sections.append(basic_section)
        
        writer({
            "step": "content_creation",
            "status": "æ­£åœ¨æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š...",
            "progress": 85
        })
        
        # æ ¼å¼åŒ–å®Œæ•´æŠ¥å‘Š
        try:
            if generated_sections:
                final_report_data = report_formatter.invoke({
                    "title": outline.get("title", "ç ”ç©¶æŠ¥å‘Š"),
                    "sections": generated_sections,
                    "executive_summary": outline.get("executive_summary", ""),
                    "metadata": {
                        "generated_at": time.time(),
                        "report_type": state.get("report_type", "research"),
                        "target_audience": state.get("target_audience", "ä¸“ä¸šäººå£«"),
                        "depth_level": state.get("depth_level", "medium")
                    }
                })
                
                if not final_report_data.get("error"):
                    state["final_report"] = final_report_data.get("content", "")
                else:
                    # åˆ›å»ºåŸºæœ¬æŠ¥å‘Šä½œä¸ºåå¤‡
                    basic_report = f"""# {outline.get('title', 'ç ”ç©¶æŠ¥å‘Š')}

                    ## æ‰§è¡Œæ‘˜è¦
                    {outline.get('executive_summary', 'æœ¬æŠ¥å‘Šæ­£åœ¨ç”Ÿæˆä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹ã€‚')}

                    """
                    for section in generated_sections:
                        basic_report += section.get("content", "") + "\n\n"
                    
                    state["final_report"] = basic_report
            else:
                # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•ç« èŠ‚ï¼Œåˆ›å»ºåŸºæœ¬æŠ¥å‘Š
                state["final_report"] = f"""# {outline.get('title', 'ç ”ç©¶æŠ¥å‘Š')}

                ## æ‰§è¡Œæ‘˜è¦
                {outline.get('executive_summary', 'æŠ±æ­‰ï¼ŒæŠ¥å‘Šç”Ÿæˆé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚')}

                ## çŠ¶æ€è¯´æ˜
                æŠ¥å‘Šæ­£åœ¨å¤„ç†ä¸­ï¼Œéƒ¨åˆ†å†…å®¹å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´ç”Ÿæˆã€‚
                """
                final_report_data = {"total_words": len(state["final_report"]), "content": state["final_report"]}
                
        except Exception as format_error:
            logger.error(f"æŠ¥å‘Šæ ¼å¼åŒ–å¼‚å¸¸: {str(format_error)}")
            # åˆ›å»ºç®€å•çš„åå¤‡æŠ¥å‘Š
            state["final_report"] = f"""# {outline.get('title', 'ç ”ç©¶æŠ¥å‘Š')}

            ## æ‰§è¡Œæ‘˜è¦
            {outline.get('executive_summary', 'æŠ¥å‘Šç”Ÿæˆé‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œæ­£åœ¨å¤„ç†ä¸­ã€‚')}

            ## ç”ŸæˆçŠ¶æ€
            ç³»ç»Ÿæ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åé‡è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚
            """
            final_report_data = {"total_words": len(state["final_report"]), "content": state["final_report"]}
        
        # æ›´æ–°çŠ¶æ€
        execution_time = time.time() - start_time
        update_performance_metrics(state, "writer", execution_time)
        update_task_status(state, "content_creation", TaskStatus.COMPLETED)
        
        state["current_step"] = "content_created"
        state["execution_path"] = state["execution_path"] + ["content_creation"]
        
        # æ·»åŠ å†…å®¹åˆ›å»ºå®Œæˆæ¶ˆæ¯
        content_message = f"""
        ğŸ“ æœ€ç»ˆæŠ¥å‘Šåˆ›å»ºå®Œæˆï¼š
        
        ğŸ“Š å†…å®¹ç»Ÿè®¡ï¼š
        - æŠ¥å‘Šæ ‡é¢˜ï¼š{outline.get('title', 'æœªçŸ¥')}
        - ç”Ÿæˆç« èŠ‚ï¼š{len(generated_sections)}ä¸ª
        - æ€»å­—æ•°ï¼š{final_report_data.get('total_words', 0):,}å­—
        - æ‰§è¡Œæ—¶é—´ï¼š{execution_time:.2f}ç§’
        
        âœ… æŠ¥å‘Šå·²å®Œæˆï¼Œå¯ä¾›æŸ¥çœ‹å’Œä½¿ç”¨
        """
        
        state["messages"] = state["messages"] + [AIMessage(content=content_message)]
        
        writer({
            "step": "content_creation",
            "status": "æœ€ç»ˆæŠ¥å‘Šåˆ›å»ºå®Œæˆ",
            "progress": 100,
            "sections_generated": len(generated_sections),
            "total_words": final_report_data.get("total_words", 0),
            "execution_time": execution_time,
            "content": {
                "type": "final_report",
                "data": final_report_data,
                "display_text": content_message,
                "full_report": final_report_data.get("formatted_report", "")
            }
        })
        
        logger.info(f"å†…å®¹åˆ›å»ºå®Œæˆ: {len(generated_sections)}ä¸ªç« èŠ‚, {final_report_data.get('total_words', 0)}å­—")
        return state
        
    except Exception as e:
        logger.error(f"å†…å®¹åˆ›å»ºå¤±è´¥: {str(e)}")
        writer({
            "step": "content_creation",
            "status": f"å†…å®¹åˆ›å»ºå¤±è´¥: {str(e)}",
            "progress": -1
        })
        
        state["error_log"] = state["error_log"] + [f"å†…å®¹åˆ›å»ºé”™è¯¯: {str(e)}"]
        state["current_step"] = "content_creation_failed"
        update_task_status(state, "content_creation", TaskStatus.FAILED)
        return state

async def analysis_generation_node(state: DeepResearchState) -> DeepResearchState:
    """åˆ†ææ´å¯Ÿç”ŸæˆèŠ‚ç‚¹"""
    writer = get_stream_writer()
    writer({
        "step": "analysis_generation",
        "status": "å¼€å§‹ç”Ÿæˆåˆ†ææ´å¯Ÿ",
        "progress": 0
    })
    
    try:
        start_time = time.time()
        
        research_results = state.get("research_results", [])
        if not research_results:
            writer({
                "step": "analysis_generation",
                "status": "æ²¡æœ‰ç ”ç©¶æ•°æ®å¯ä¾›åˆ†æ",
                "progress": 100
            })
            return state
        
        writer({
            "step": "analysis_generation", 
            "status": "æ­£åœ¨è¿›è¡Œè¶‹åŠ¿åˆ†æ...",
            "progress": 30
        })
        
        # ä½¿ç”¨è¶‹åŠ¿åˆ†æå·¥å…·
        insights = trend_analyzer.invoke({
            "research_results": research_results,
            "analysis_focus": state.get("report_type", "general")
        })
        
        writer({
            "step": "analysis_generation",
            "status": "æ­£åœ¨ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š...",
            "progress": 70
        })
        
        # æ·»åŠ æ´å¯Ÿåˆ°çŠ¶æ€
        for insight in insights:
            if not insight.get("error"):
                add_analysis_insight(state, insight)
        
        # æ›´æ–°çŠ¶æ€
        execution_time = time.time() - start_time
        update_performance_metrics(state, "analyst", execution_time)
        update_task_status(state, "analysis_generation", TaskStatus.COMPLETED)
        
        state["current_step"] = "analysis_completed"
        state["execution_path"] = state["execution_path"] + ["analysis_generation"]
        
        # æ·»åŠ åˆ†æå®Œæˆæ¶ˆæ¯
        analysis_message = f"""
        ğŸ“ˆ åˆ†ææ´å¯Ÿç”Ÿæˆå®Œæˆï¼š
        
        ğŸ” æ´å¯Ÿç»Ÿè®¡ï¼š
        - ç”Ÿæˆæ´å¯Ÿï¼š{len([i for i in insights if not i.get('error')])}ä¸ª
        - æ•°æ®æ¥æºï¼š{len(research_results)}æ¡ç ”ç©¶ç»“æœ
        - æ‰§è¡Œæ—¶é—´ï¼š{execution_time:.2f}ç§’
        
        ğŸ’¡ ä¸»è¦æ´å¯Ÿç±»å‹ï¼š
        {chr(10).join([f"  â€¢ {insight.get('type', 'æœªçŸ¥')}: {insight.get('title', 'æœªçŸ¥æ ‡é¢˜')}" for insight in insights[:3] if not insight.get('error')])}
        """
        
        state["messages"] = state["messages"] + [AIMessage(content=analysis_message)]
        
        writer({
            "step": "analysis_generation",
            "status": "åˆ†ææ´å¯Ÿç”Ÿæˆå®Œæˆ",
            "progress": 100,
            "insights_count": len([i for i in insights if not i.get('error')]),
            "execution_time": execution_time
        })
        
        logger.info(f"åˆ†æç”Ÿæˆå®Œæˆ: {len(insights)}ä¸ªæ´å¯Ÿ")
        return state
        
    except Exception as e:
        logger.error(f"åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}")
        writer({
            "step": "analysis_generation",
            "status": f"åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}",
            "progress": -1
        })
        
        state["error_log"] = state["error_log"] + [f"åˆ†æç”Ÿæˆé”™è¯¯: {str(e)}"]
        state["current_step"] = "analysis_failed"
        update_task_status(state, "analysis_generation", TaskStatus.FAILED)
        return state

# ============================================================================
# è·¯ç”±å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬
# ============================================================================

def route_after_outline_confirmation(state: DeepResearchState) -> str:
    """å¤§çº²ç¡®è®¤åçš„è·¯ç”± - ç®€åŒ–ç‰ˆæœ¬"""
    if not state["approval_status"].get("outline_confirmation", True):
        return "outline_generation"  # é‡æ–°ç”Ÿæˆå¤§çº²
    return "multi_agent_research"  # ç›´æ¥è¿›å…¥ç ”ç©¶é˜¶æ®µ

def route_after_analysis_approval(state: DeepResearchState) -> str:
    """åˆ†æç¡®è®¤åçš„è·¯ç”±"""
    if not state["approval_status"].get("analysis_approval", True):
        return "analysis_generation"  # é‡æ–°åˆ†æ
    return "content_creation"  # è¿›å…¥å†…å®¹åˆ›å»º

# ============================================================================
# å›¾æ„å»ºå‡½æ•°
# ============================================================================

def create_deep_research_graph(checkpointer: Optional[InMemorySaver] = None):
    """åˆ›å»ºæ·±åº¦ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå›¾ - ç®€åŒ–ç‰ˆæœ¬"""
    workflow = StateGraph(DeepResearchState)
    
    # æ·»åŠ æ ¸å¿ƒèŠ‚ç‚¹ - ç§»é™¤å†—ä½™èŠ‚ç‚¹
    workflow.add_node("outline_generation", outline_generation_node)
    workflow.add_node("outline_confirmation", outline_confirmation_node)
    workflow.add_node("multi_agent_research", multi_agent_research_node)
    workflow.add_node("analysis_generation", analysis_generation_node)
    workflow.add_node("analysis_approval", analysis_approval_node)
    workflow.add_node("content_creation", content_creation_node)
    
    # è®¾ç½®ç®€åŒ–çš„çº¿æ€§æµç¨‹
    workflow.add_edge(START, "outline_generation")
    workflow.add_edge("outline_generation", "outline_confirmation")
    
    # å¤§çº²ç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "outline_confirmation",
        route_after_outline_confirmation,
        {
            "outline_generation": "outline_generation",
            "multi_agent_research": "multi_agent_research"
        }
    )
    
    # çº¿æ€§æµç¨‹ï¼šç ”ç©¶ -> åˆ†æ -> å†…å®¹åˆ›å»º
    workflow.add_edge("multi_agent_research", "analysis_generation")
    workflow.add_edge("analysis_generation", "analysis_approval")
    
    # åˆ†æç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "analysis_approval",
        route_after_analysis_approval,
        {
            "analysis_generation": "analysis_generation",
            "content_creation": "content_creation"
        }
    )
    
    workflow.add_edge("content_creation", END)
    
    # ç¼–è¯‘å›¾
    if checkpointer is None:
        checkpointer = InMemorySaver()
    
    app = workflow.compile(checkpointer=checkpointer)
    return app
