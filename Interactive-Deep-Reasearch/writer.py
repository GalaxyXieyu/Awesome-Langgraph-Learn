"""
æ ‡å‡†åŒ–æµå¼è¾“å‡ºç³»ç»Ÿ - Interactive Deep Researchç‰ˆæœ¬
åŸºäºMulti-Agent-reportçš„Writerè®¾è®¡ï¼Œå»é™¤emojiè¡¨æƒ…ï¼Œæ·»åŠ å­å›¾ä¸“ç”¨åŠŸèƒ½
æä¾›ç»Ÿä¸€çš„æµå¼è¾“å‡ºæ ¼å¼ï¼Œä¾¿äºå‰ç«¯æ¸²æŸ“
"""

import time
import json
from typing import Dict, Any, List, Optional
from enum import Enum
from langgraph.config import get_stream_writer


# ============================================================================  
# å·¥å…·é…ç½®ç³»ç»Ÿ - æ¶ˆé™¤ç¡¬ç¼–ç çš„å·¥å…·å¤„ç†é€»è¾‘
# ============================================================================

# å·¥å…·å¤„ç†é…ç½® - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å·¥å…·çš„å¤„ç†é€»è¾‘
TOOL_PROCESSING_CONFIG = {
    # æœç´¢ç±»å·¥å…·
    "web_search_tool": {
        "param_key": "query",
        "thinking_template": "æœç´¢ç›¸å…³ä¿¡æ¯: {query}",
        "feedback_template": "æœç´¢å®Œæˆï¼Œåˆ†ææœç´¢ç»“æœçš„ç›¸å…³æ€§"
    },
    "advanced_web_search": {
        "param_key": "query", 
        "thinking_template": "é«˜çº§æœç´¢: {query}",
        "feedback_template": "é«˜çº§æœç´¢å®Œæˆ"
    },
    
    # ç ”ç©¶ç±»å·¥å…·  
    "trend_analysis_tool": {
        "param_key": "topic",
        "thinking_template": "ä½¿ç”¨è¶‹åŠ¿åˆ†æå·¥å…·ç ”ç©¶: {topic}",
        "feedback_template": "è¶‹åŠ¿åˆ†æå®Œæˆï¼Œå¼€å§‹æ•´ç†ç ”ç©¶ç»“æœ"
    },
    "multi_source_research": {
        "param_key": "topic",
        "thinking_template": "å¤šæºç ”ç©¶: {topic}", 
        "feedback_template": "å¤šæºç ”ç©¶å®Œæˆ"
    },
    "get_research_context_tool": {
        "param_key": "query",
        "thinking_template": "æŸ¥è¯¢ç ”ç©¶ä¸Šä¸‹æ–‡: {query}",
        "feedback_template": "ç ”ç©¶ä¸Šä¸‹æ–‡æŸ¥è¯¢å®Œæˆ"
    },
    
    # æ•°æ®ç±»å·¥å…·
    "industry_data_tool": {
        "param_key": "industry",
        "thinking_template": "è·å–è¡Œä¸šæ•°æ®: {industry}",
        "feedback_template": "è¡Œä¸šæ•°æ®è·å–å®Œæˆ"
    },
    
    # å†…å®¹ç±»å·¥å…·
    "content_writer_tool": {
        "param_key": "title", 
        "thinking_template": "å¼€å§‹ç”Ÿæˆå†…å®¹: {title}",
        "feedback_template": "å†…å®¹ç”Ÿæˆå®Œæˆ ({word_count}è¯)ï¼Œæ£€æŸ¥è´¨é‡"
    },
    "enhanced_writer": {
        "param_key": None,
        "thinking_template": "ä½¿ç”¨é«˜çº§å†™ä½œå·¥å…·ç”Ÿæˆå†…å®¹",
        "feedback_template": "å†…å®¹ç”Ÿæˆå®Œæˆ ({word_count}è¯)ï¼Œæ£€æŸ¥è´¨é‡"
    },
    "content_analyzer": {
        "param_key": None,
        "thinking_template": "åˆ†æå†…å®¹è´¨é‡", 
        "feedback_template": "å†…å®¹åˆ†æå®Œæˆ"
    }
}

# é»˜è®¤å·¥å…·å¤„ç†é…ç½®
DEFAULT_TOOL_CONFIG = {
    "param_key": None,
    "thinking_template": "è°ƒç”¨{tool_name}å·¥å…·",
    "feedback_template": "{tool_name}å·¥å…·æ‰§è¡Œå®Œæˆ" 
}


# ============================================================================
# æ•°æ®æ‰å¹³åŒ–å¤„ç†å™¨ - æ ¸å¿ƒç»„ä»¶
# ============================================================================

class FlatDataProcessor:
    """æ•°æ®æ‰å¹³åŒ–å¤„ç†å™¨ - å°†å¤æ‚åµŒå¥—æ•°æ®è½¬æ¢ä¸ºç®€å•æ‰å¹³å­—å…¸"""
    
    def __init__(self, custom_templates: Optional[Dict[str, str]] = None):
        """
        åˆå§‹åŒ–æ‰å¹³åŒ–å¤„ç†å™¨
        
        Args:
            custom_templates: è‡ªå®šä¹‰æ¨¡æ¿ï¼Œä¾‹å¦‚ {'web_search_tool': 'ğŸ” æ­£åœ¨æœç´¢: {query}'}
        """
        self.custom_templates = custom_templates or {}
        self.default_templates = {
            'web_search_tool': 'æ­£åœ¨æœç´¢: {query}',
            'industry_data_tool': 'æ­£åœ¨è·å–è¡Œä¸šæ•°æ®: {industry}',
            'trend_analysis_tool': 'æ­£åœ¨åˆ†æè¶‹åŠ¿: {topic}', 
            'content_writer_tool': 'æ­£åœ¨ç”Ÿæˆå†…å®¹: {title}',
            'enhanced_writer': 'æ­£åœ¨ä½¿ç”¨é«˜çº§å†™ä½œå·¥å…·',
            'content_analyzer': 'æ­£åœ¨åˆ†æå†…å®¹è´¨é‡',
            'multi_source_research': 'æ­£åœ¨è¿›è¡Œå¤šæºç ”ç©¶: {topic}',
            'default': 'æ­£åœ¨ä½¿ç”¨{tool_name}å·¥å…·'
        }
    
    def flatten_chunk(self, chunk: Any) -> Optional[Dict[str, Any]]:
        """
        æ‰å¹³åŒ–å•ä¸ªchunkæ•°æ®
        
        Args:
            chunk: LangGraphçš„chunkæ•°æ®
            
        Returns:
            æ‰å¹³åŒ–çš„å­—å…¸ {message_type, tool_name, content, length, duration, node}
        """
        if not chunk:
            return None
            
        # å¤„ç†customæ¶ˆæ¯æ ¼å¼ ('custom', data)
        if isinstance(chunk, tuple) and len(chunk) == 2 and chunk[0] == 'custom':
            return self._flatten_custom_data(chunk[1])
        
        # å¤„ç†å­å›¾åµŒå¥—æ ¼å¼ (('subgraph_id',), 'updates'/'messages', data)
        if isinstance(chunk, tuple) and len(chunk) == 3:
            subgraph_id, chunk_type, chunk_data = chunk
            # å­å›¾æ•°æ®æš‚æ—¶ä¸æ‰å¹³åŒ–ï¼Œäº¤ç»™åŸæœ‰é€»è¾‘å¤„ç†
            return None
            
        # å¤„ç†æ™®é€šæ ¼å¼ ('updates'/'messages', data)  
        if isinstance(chunk, tuple) and len(chunk) == 2:
            chunk_type, chunk_data = chunk
            if chunk_type in ['updates', 'messages']:
                # è¿™äº›æ ¼å¼éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä¸åšæ‰å¹³åŒ–
                return None
        
        return None
    
    def _flatten_custom_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰å¹³åŒ–customç±»å‹çš„æ•°æ®"""
        if not isinstance(data, dict):
            return {}
            
        message_type = data.get('message_type', '')
        content = data.get('content', '')
        node_name = data.get('node_name', '')
        metadata = data.get('metadata', {})
        
        # æ„å»ºåŸºç¡€æ‰å¹³ç»“æ„
        flat_data = {
            'message_type': message_type,
            'content': content,
            'node': node_name,
            'timestamp': data.get('timestamp', time.time())
        }
        
        # å¤„ç†ä¸åŒæ¶ˆæ¯ç±»å‹çš„ç‰¹æ®Šå­—æ®µ
        if message_type == 'tool_call':
            tool_name = metadata.get('tool_name', '')
            tool_args = metadata.get('tool_args', {})
            
            flat_data.update({
                'tool_name': tool_name,
                'content': self._get_tool_call_content(tool_name, tool_args),
                'args': tool_args
            })
            
        elif message_type == 'tool_result':
            tool_name = metadata.get('tool_name', '')
            result_length = metadata.get('result_length', 0)
            step_duration = metadata.get('step_duration', 0)
            full_result = metadata.get('full_result', content)
            
            flat_data.update({
                'tool_name': tool_name,
                'content': self._clean_tool_result(full_result),  # å»é™¤å‰ç¼€
                'length': result_length,
                'duration': round(step_duration, 2)
            })
            
        elif message_type == 'content_streaming':
            chunk_index = metadata.get('chunk_index', 0)
            
            flat_data.update({
                'length': len(content),
                'chunk_index': chunk_index
            })
            
        elif message_type == 'step_complete':
            duration = metadata.get('duration', 0)
            
            flat_data.update({
                'duration': round(duration, 2)
            })
        
        # æ·»åŠ é€šç”¨å­—æ®µ
        if 'step_duration' in metadata:
            flat_data['duration'] = round(metadata['step_duration'], 2)
            
        return flat_data
    
    def _get_tool_call_content(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """ç”Ÿæˆå·¥å…·è°ƒç”¨çš„å†…å®¹æè¿°"""
        # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰æ¨¡æ¿ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆä¸è¾“å‡ºï¼‰
        if not self.custom_templates:
            return ""
        
        # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ï¼Œæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿
        template = self.custom_templates.get(tool_name) or self.default_templates.get(tool_name)
        
        if not template:
            return ""
        
        try:
            # å°è¯•æ ¼å¼åŒ–æ¨¡æ¿
            if '{query}' in template and 'query' in tool_args:
                return template.format(query=tool_args['query'])
            elif '{topic}' in template and 'topic' in tool_args:
                return template.format(topic=tool_args['topic'])
            elif '{title}' in template and 'title' in tool_args:
                return template.format(title=tool_args['title'])
            elif '{industry}' in template and 'industry' in tool_args:
                return template.format(industry=tool_args['industry'])
            elif '{tool_name}' in template:
                return template.format(tool_name=tool_name)
            else:
                return template
        except Exception:
            return ""
    
    def _clean_tool_result(self, content: str) -> str:
        """æ¸…ç†å·¥å…·ç»“æœå†…å®¹ï¼Œç§»é™¤å·¥å…·åå‰ç¼€"""
        if not content:
            return ""
            
        # ç§»é™¤å¸¸è§çš„å·¥å…·ç»“æœå‰ç¼€
        prefixes = [
            ' æ‰§è¡Œç»“æœ: ',
            ' æ‰§è¡Œç»“æœï¼š',
            ' ç»“æœ: ',
            ' ç»“æœï¼š'
        ]
        
        for prefix in prefixes:
            if prefix in content:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå‰ç¼€å¹¶ç§»é™¤å®ƒä¹‹å‰çš„éƒ¨åˆ†ï¼ˆåŒ…æ‹¬å‰ç¼€ï¼‰
                index = content.find(prefix)
                if index >= 0:
                    return content[index + len(prefix):].strip()
        
        return content.strip()


class MessageType(Enum):
    """Agentå·¥ä½œæµç¨‹æ¶ˆæ¯ç±»å‹æšä¸¾"""
    # æ­¥éª¤çŠ¶æ€ - å½“å‰åœ¨åšä»€ä¹ˆ
    STEP_START = "step_start"
    STEP_PROGRESS = "step_progress"
    STEP_COMPLETE = "step_complete"
    
    # å·¥å…·ä½¿ç”¨ - Agentä½¿ç”¨å·¥å…·çš„è¿‡ç¨‹
    TOOL_CALL = "tool_call"
    TOOL_RESULT = "tool_result"
    
    # æ€è€ƒè¿‡ç¨‹ - Agentçš„æ¨ç†
    THINKING = "thinking"
    REASONING = "reasoning"
    
    # å†…å®¹è¾“å‡º - å®é™…äº§å‡º
    CONTENT_STREAMING = "content_streaming"
    CONTENT_COMPLETE = "content_complete"
    
    # ç»“æœçŠ¶æ€
    FINAL_RESULT = "final_result"
    ERROR = "error"


class StreamWriter:
    """æ ‡å‡†åŒ–æµå¼è¾“å‡ºWriter - æ‰å¹³åŒ–æ•°æ®ç‰ˆæœ¬"""
    
    def __init__(self, node_name: str = "", agent_name: str = "", custom_templates: Optional[Dict[str, str]] = None):
        self.node_name = node_name
        self.agent_name = agent_name
        self.step_start_time = time.time()
        self.writer = self._get_safe_writer()
        self.flat_processor = FlatDataProcessor(custom_templates)
        
    def _get_safe_writer(self):
        """å®‰å…¨è·å–writer"""
        try:
            return get_stream_writer()
        except Exception:
            return lambda _: None
    
    def _send_message(self, msg_type: MessageType, content: str, **kwargs):
        """å‘é€æ‰å¹³åŒ–æ ¼å¼æ¶ˆæ¯"""
        # æ„å»ºæ‰å¹³åŒ–æ¶ˆæ¯
        message = {
            "message_type": msg_type.value,
            "content": content,
            "node": self.node_name,
            "timestamp": time.time(),
            "duration": round(time.time() - self.step_start_time, 2)
        }
        
        # æ·»åŠ ç‰¹å®šå­—æ®µ
        for key, value in kwargs.items():
            if key not in message:  # é¿å…è¦†ç›–æ ¸å¿ƒå­—æ®µ
                message[key] = value
        
        self.writer(message)
    
    # åŸºç¡€æ­¥éª¤æ–¹æ³•
    def step_start(self, description: str):
        """æ­¥éª¤å¼€å§‹"""
        self.step_start_time = time.time()
        self._send_message(MessageType.STEP_START, description)
    
    def step_progress(self, status: str, progress: int, **kwargs):
        """æ­¥éª¤è¿›åº¦"""
        self._send_message(MessageType.STEP_PROGRESS, status, progress=progress, **kwargs)
    
    def step_complete(self, summary: str, **kwargs):
        """æ­¥éª¤å®Œæˆ"""
        calculated_duration = time.time() - self.step_start_time
        # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›durationï¼Œä½¿ç”¨è®¡ç®—çš„duration
        if "duration" not in kwargs:
            kwargs["duration"] = calculated_duration
        self._send_message(MessageType.STEP_COMPLETE, summary, **kwargs)
    
    # æ€è€ƒè¿‡ç¨‹æ–¹æ³•
    def thinking(self, thought: str):
        """Agentæ€è€ƒè¿‡ç¨‹"""
        self._send_message(MessageType.THINKING, thought)
    
    def reasoning(self, reasoning: str, **kwargs):
        """Agentæ¨ç†åˆ†æ"""
        self._send_message(MessageType.REASONING, reasoning, **kwargs)
    
    # å†…å®¹è¾“å‡ºæ–¹æ³• - æ‰å¹³åŒ–ç‰ˆæœ¬
    def content_streaming(self, content_chunk: str, chunk_index: int = 0):
        """æµå¼å†…å®¹è¾“å‡º"""
        self._send_message(
            MessageType.CONTENT_STREAMING,
            content_chunk,
            length=len(content_chunk),
            chunk_index=chunk_index
        )
    
    def content_complete(self, content_summary: str, **kwargs):
        """å†…å®¹è¾“å‡ºå®Œæˆ"""
        self._send_message(
            MessageType.CONTENT_COMPLETE,
            content_summary,
            **kwargs
        )
    
    # å·¥å…·ç›¸å…³æ–¹æ³• - æ‰å¹³åŒ–ç‰ˆæœ¬
    def tool_call(self, tool_name: str, tool_args: Dict[str, Any], custom_content: Optional[str] = None):
        """å·¥å…·è°ƒç”¨ - æ”¯æŒè‡ªå®šä¹‰å†…å®¹"""
        # ä½¿ç”¨è‡ªå®šä¹‰å†…å®¹æˆ–è‡ªåŠ¨ç”Ÿæˆ
        if custom_content:
            content = custom_content
        else:
            content = self.flat_processor._get_tool_call_content(tool_name, tool_args)
        
        self._send_message(
            MessageType.TOOL_CALL,
            content,
            tool_name=tool_name,
            args=tool_args
        )
    
    def tool_result(self, tool_name: str, result: str):
        """å·¥å…·æ‰§è¡Œç»“æœ - æ‰å¹³åŒ–ç‰ˆæœ¬"""
        # æ¸…ç†ç»“æœï¼Œç§»é™¤å·¥å…·åå‰ç¼€
        clean_result = self.flat_processor._clean_tool_result(result)
        
        self._send_message(
            MessageType.TOOL_RESULT,
            clean_result,
            tool_name=tool_name,
            length=len(result)
        )
    
    
    # ç»“æœå’Œé”™è¯¯æ–¹æ³•  
    def final_result(self, result: str, execution_summary: Dict[str, Any]):
        """æœ€ç»ˆç»“æœ"""
        self._send_message(
            MessageType.FINAL_RESULT,
            result,
            execution_summary=execution_summary,
            is_final=True
        )
    
    def error(self, error_msg: str, error_type: str = "GeneralError"):
        """é”™è¯¯ä¿¡æ¯"""
        self._send_message(MessageType.ERROR, error_msg, error_type=error_type)
    


class AgentWorkflowProcessor:
    """Agentå·¥ä½œæµç¨‹å¤„ç†å™¨ - ä½¿ç”¨æ‰å¹³åŒ–æ•°æ®æ ¼å¼"""
    
    def __init__(self, writer: StreamWriter, custom_templates: Optional[Dict[str, str]] = None):
        self.writer = writer
        self.flat_processor = FlatDataProcessor(custom_templates)
        self.chunk_count = 0
        self.current_step = ""
        self.sections_completed = []
        self.research_findings = []
        self.final_output = {}
        # æ·»åŠ å»é‡ç¼“å­˜ - åŸºäºå†…å®¹hashå»é‡reasoningæ¶ˆæ¯
        self.processed_reasoning = set()
    
    def process_chunk(self, chunk: Any) -> Dict[str, Any]:
        """ç»Ÿä¸€æ™ºèƒ½å¤„ç†å·¥ä½œæµç¨‹æ•°æ® - æ‰å¹³åŒ–+åŸæœ‰é€»è¾‘å…¼å®¹"""
        self.chunk_count += 1
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨æ‰å¹³åŒ–å¤„ç†å™¨ï¼ˆä»…å¤„ç†customæ¶ˆæ¯ï¼‰
        flat_data = self.flat_processor.flatten_chunk(chunk)
        if flat_data:
            self._handle_flat_data(flat_data)
            return {"chunk_count": self.chunk_count, "current_step": self.current_step, "flat_data": flat_data}
        
        # å¤„ç†å­å›¾å’Œå…¶ä»–æ ¼å¼çš„æ•°æ® - ä¿ç•™åŸæœ‰é€»è¾‘
        if isinstance(chunk, tuple):
            if len(chunk) == 3:
                # åµŒå¥—å­å›¾æ ¼å¼: (('subgraph_id',), 'messages'/'updates', data)
                subgraph_ids, chunk_type, chunk_data = chunk
                # æå–agentä¿¡æ¯
                agent_name = self._extract_agent_name(subgraph_ids)
                agent_hierarchy = self._extract_agent_hierarchy(subgraph_ids)
                return self._process_subgraph_chunk(chunk_type, chunk_data, agent_name, agent_hierarchy)
            elif len(chunk) == 2:
                # æ™®é€šæ ¼å¼: ('messages'/'updates', data) æˆ– ('custom', data)
                chunk_type, chunk_data = chunk
                if chunk_type == 'custom':
                    # customå·²ç»è¢«æ‰å¹³åŒ–å¤„ç†å™¨å¤„ç†äº†
                    return self._process_normal_chunk(chunk_type, chunk_data)
                else:
                    # messages/updateséœ€è¦ç‰¹æ®Šå¤„ç†
                    return self._process_normal_chunk(chunk_type, chunk_data)
        elif isinstance(chunk, dict):
            # ç›´æ¥çš„æ•°æ®æ ¼å¼
            return self._process_custom_data(chunk)
        
        return {"chunk_count": self.chunk_count, "current_step": self.current_step}
    
    def _extract_agent_name(self, subgraph_ids: tuple) -> str:
        """ä»subgraph_idsä¸­æå–æœ€å…·ä½“çš„agentåç§°"""
        if not isinstance(subgraph_ids, tuple) or not subgraph_ids:
            return "unknown"
        
        agent_names = []
        # ä»tupleä¸­æå–æ‰€æœ‰agentåç§°ï¼Œå»ºç«‹å±‚çº§
        # æ ¼å¼å¦‚: ('content_creation:xxx', 'writing:yyy') â†’ ['content_creation', 'writing']
        for subgraph_id in subgraph_ids:
            if isinstance(subgraph_id, str) and ':' in subgraph_id:
                parts = subgraph_id.split(':')
                if len(parts) >= 2:
                    agent_name = parts[0]  # å–å†’å·å‰çš„éƒ¨åˆ†
                    # éªŒè¯æ˜¯å¦ä¸ºå·²çŸ¥çš„agentç±»å‹
                    if agent_name in ['research', 'writing', 'content_creation', 'tools', 'intelligent_supervisor']:
                        agent_names.append(agent_name)
        
        # è¿”å›æœ€åä¸€ä¸ªï¼ˆæœ€å…·ä½“çš„ï¼‰agentï¼Œä¾‹å¦‚writingæ¯”content_creationæ›´å…·ä½“
        return agent_names[-1] if agent_names else "unknown"
    
    def _extract_agent_hierarchy(self, subgraph_ids: tuple) -> List[str]:
        """ä»subgraph_idsä¸­æå–å®Œæ•´çš„agentå±‚çº§"""
        if not isinstance(subgraph_ids, tuple) or not subgraph_ids:
            return ["unknown"]
        
        agent_names = []
        # ä»tupleä¸­æå–æ‰€æœ‰agentåç§°ï¼Œå»ºç«‹å±‚çº§
        for subgraph_id in subgraph_ids:
            if isinstance(subgraph_id, str) and ':' in subgraph_id:
                parts = subgraph_id.split(':')
                if len(parts) >= 2:
                    agent_name = parts[0]
                    # éªŒè¯æ˜¯å¦ä¸ºå·²çŸ¥çš„agentç±»å‹
                    if agent_name in ['research', 'writing', 'content_creation', 'tools', 'intelligent_supervisor']:
                        agent_names.append(agent_name)
        
        return agent_names if agent_names else ["unknown"]
    
    # ========================================================================
    # ç»Ÿä¸€å·¥å…·å¤„ç†æ–¹æ³• - æ¶ˆé™¤é‡å¤ä»£ç ï¼ˆæ–°å¢ï¼Œä¸å½±å“ç°æœ‰ä»£ç ï¼‰
    # ========================================================================
    
    def _get_tool_config(self, tool_name: str) -> Dict[str, str]:
        """è·å–å·¥å…·é…ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤é…ç½®"""
        return TOOL_PROCESSING_CONFIG.get(tool_name, DEFAULT_TOOL_CONFIG)
    
    def _generate_tool_thinking_content(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """ç»Ÿä¸€ç”Ÿæˆå·¥å…·è°ƒç”¨çš„æ€è€ƒå†…å®¹"""
        config = self._get_tool_config(tool_name)
        template = config["thinking_template"]
        param_key = config["param_key"]
        
        try:
            if param_key and param_key in tool_args:
                param_value = tool_args[param_key]
                return template.format(**{param_key: param_value})
            else:
                return template.format(tool_name=tool_name)
        except Exception:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
            return DEFAULT_TOOL_CONFIG["thinking_template"].format(tool_name=tool_name)
    
    def _generate_tool_feedback_content(self, tool_name: str, result: str = "") -> str:
        """ç»Ÿä¸€ç”Ÿæˆå·¥å…·ç»“æœçš„åé¦ˆå†…å®¹"""
        config = self._get_tool_config(tool_name)
        template = config["feedback_template"]
        
        try:
            # å¯¹äºå†…å®¹ç”Ÿæˆç±»å·¥å…·ï¼Œè®¡ç®—å­—æ•°
            if "{word_count}" in template:
                word_count = len(result.split()) if result else 0
                return template.format(word_count=word_count)
            else:
                return template.format(tool_name=tool_name)
        except Exception:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
            return DEFAULT_TOOL_CONFIG["feedback_template"].format(tool_name=tool_name)
    
    def _create_agent_message(self, message_type: str, content: str, agent_name: str = None, 
                             agent_hierarchy: List[str] = None, **extras) -> Dict[str, Any]:
        """ç»Ÿä¸€åˆ›å»ºå¸¦agentä¿¡æ¯çš„æ¶ˆæ¯"""
        message = {
            "message_type": message_type,
            "content": content,
            "node": self.writer.node_name,
            "timestamp": time.time(),
            "duration": round(time.time() - self.writer.step_start_time, 2)
        }
        
        # æ·»åŠ agentä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
        if agent_name:
            message["agent"] = agent_name
        if agent_hierarchy:
            message["agent_hierarchy"] = agent_hierarchy
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        for key, value in extras.items():
            if key not in message:  # é¿å…è¦†ç›–æ ¸å¿ƒå­—æ®µ
                message[key] = value
        
        return message
    
    def _send_agent_message(self, message_type: str, content: str, agent_name: str = None, 
                           agent_hierarchy: List[str] = None, **extras):
        """ç»Ÿä¸€å‘é€å¸¦agentä¿¡æ¯çš„æ¶ˆæ¯"""
        message = self._create_agent_message(message_type, content, agent_name, agent_hierarchy, **extras)
        self.writer.writer(message)
    
    def _handle_flat_data(self, flat_data: Dict[str, Any]):
        """å¤„ç†æ‰å¹³åŒ–æ•°æ® - ç›´æ¥è¾“å‡ºæ‰å¹³æ ¼å¼"""
        message_type = flat_data.get('message_type', '')
        
        # ç›´æ¥è¾“å‡ºæ‰å¹³åŒ–æ•°æ®ï¼Œä¸å†é‡å¤å¤„ç†
        # è¿™æ˜¯æœ€ç®€æ´çš„æ–¹å¼ - æ‰å¹³æ•°æ®ç›´æ¥ä¼ ç»™å‰ç«¯
        if message_type in ['tool_call', 'tool_result', 'content_streaming', 'thinking', 'reasoning']:
            # æ•°æ®å·²ç»æ˜¯æ‰å¹³æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
            pass
    
    def _process_subgraph_chunk(self, chunk_type: str, chunk_data: Any, agent_name: str = "unknown", agent_hierarchy: List[str] = None) -> Dict[str, Any]:
        """å¤„ç†å­å›¾çš„åµŒå¥—æµå¼è¾“å‡º"""
        if chunk_type == "messages":
            # å¤„ç†å­å›¾çš„messagesæ ¼å¼
            if isinstance(chunk_data, tuple) and len(chunk_data) == 2:
                # æ ¼å¼: (AIMessageChunk, metadata) 
                message, metadata = chunk_data
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯AIMessageChunkå¹¶ç›´æ¥è¾“å‡ºå†…å®¹
                if hasattr(message, '__class__') and type(message).__name__ == "AIMessageChunk":
                    if hasattr(message, 'content') and message.content:
                        content = str(message.content)
                        if content and content.strip():
                            # å‘é€å¸¦agentä¿¡æ¯çš„content_streamingæ¶ˆæ¯
                            self._send_agent_content_streaming(content, agent_name, agent_hierarchy)
                            # å¯¹äºAIMessageChunkï¼Œä¸å†ç»§ç»­è°ƒç”¨_process_message_chunké¿å…é‡å¤
                            return {"chunk_count": self.chunk_count, "current_step": self.current_step}
                
                # ç»§ç»­ä½¿ç”¨åŸæœ‰é€»è¾‘å¤„ç†å…¶ä»–ç±»å‹
                self._process_message_chunk(message)
            else:
                # ç›´æ¥çš„messageæ ¼å¼
                self._process_message_chunk(chunk_data)
        elif chunk_type == "updates" and isinstance(chunk_data, dict):
            # å¯¹äºupdatesç±»å‹ï¼Œä¹Ÿä¼ é€’agentä¿¡æ¯
            self._process_content_updates_with_agent(chunk_data, agent_name)
        
        return {"chunk_count": self.chunk_count, "current_step": self.current_step}
    
    def _send_agent_content_streaming(self, content: str, agent_name: str, agent_hierarchy: List[str] = None):
        """å‘é€å¸¦agentä¿¡æ¯çš„content_streamingæ¶ˆæ¯"""
        message = {
            "message_type": "content_streaming",
            "content": content,
            "node": self.writer.node_name,
            "agent": agent_name,  # æœ€å…·ä½“çš„agent
            "agent_hierarchy": agent_hierarchy or [agent_name],  # å®Œæ•´å±‚çº§
            "timestamp": time.time(),
            "duration": round(time.time() - self.writer.step_start_time, 2),
            "length": len(content),
            "chunk_index": 0
        }
        self.writer.writer(message)
    
    def _process_content_updates_with_agent(self, updates_data: Dict[str, Any], agent_name: str):
        """å¤„ç†å¸¦agentä¿¡æ¯çš„å†…å®¹æ›´æ–°"""
        for node_name, node_data in updates_data.items():
            if not isinstance(node_data, dict):
                continue
            
            # æ£€æµ‹Agentæ¶ˆæ¯ä¸­çš„å·¥å…·è°ƒç”¨ - é‡è¦ï¼šæ•è·å·¥å…·ä½¿ç”¨è¿‡ç¨‹
            if "messages" in node_data:
                messages = node_data["messages"]
                # å¤„ç†messages
                if isinstance(messages, list):
                    for message in messages:
                        # å¤„ç†å•ä¸ªæ¶ˆæ¯ï¼Œä¼ é€’agentä¿¡æ¯
                        self._process_agent_message_with_agent(message, node_name, agent_name)
            
            # å…¶ä»–å¤„ç†é€»è¾‘ä¿æŒä¸å˜...
            # æ£€æµ‹åˆ°æ–°ç« èŠ‚å®Œæˆ
            if "sections" in node_data:
                sections = node_data["sections"]
                if isinstance(sections, list):
                    for section in sections:
                        if isinstance(section, dict) and section.get("title"):
                            title = section["title"]
                            word_count = section.get("word_count", 0)
                            if title not in [s.get("title") for s in self.sections_completed]:
                                self.sections_completed.append(section)
                                # åœ¨æ¶ˆæ¯ä¸­æ·»åŠ agentä¿¡æ¯
                                message = {
                                    "message_type": "content_complete",
                                    "content": f"å®Œæˆç« èŠ‚: {title}",
                                    "node": self.writer.node_name,
                                    "agent": agent_name,
                                    "timestamp": time.time(),
                                    "duration": round(time.time() - self.writer.step_start_time, 2),
                                    "word_count": word_count,
                                    "section_title": title
                                }
                                self.writer.writer(message)
            
            # æ£€æµ‹åˆ°æ–°çš„ç ”ç©¶å‘ç°
            if "research_results" in node_data:
                research_data = node_data["research_results"]
                if isinstance(research_data, dict):
                    for research in research_data.values():
                        if isinstance(research, dict) and research.get("title"):
                            title = research["title"]
                            if title not in [r.get("title") for r in self.research_findings]:
                                self.research_findings.append(research)
                                # åœ¨æ¶ˆæ¯ä¸­æ·»åŠ agentä¿¡æ¯
                                message = {
                                    "message_type": "step_progress",
                                    "content": f"å‘ç°ç ”ç©¶èµ„æ–™: {title}",
                                    "node": self.writer.node_name,
                                    "agent": agent_name,
                                    "timestamp": time.time(),
                                    "duration": round(time.time() - self.writer.step_start_time, 2),
                                    "progress": 0,
                                    "research_title": title
                                }
                                self.writer.writer(message)
            
            # æ£€æµ‹åˆ°æœ€ç»ˆæŠ¥å‘Š
            if "final_report" in node_data:
                self.final_output = node_data["final_report"]
                total_words = self.final_output.get("total_words", 0)
                # åœ¨æ¶ˆæ¯ä¸­æ·»åŠ agentä¿¡æ¯
                message = {
                    "message_type": "reasoning",
                    "content": f"æ•´åˆæ‰€æœ‰å†…å®¹ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š (æ€»å­—æ•°: {total_words})",
                    "node": self.writer.node_name,
                    "agent": agent_name,
                    "timestamp": time.time(),
                    "duration": round(time.time() - self.writer.step_start_time, 2)
                }
                self.writer.writer(message)
    
    def _process_normal_chunk(self, chunk_type: str, chunk_data: Any) -> Dict[str, Any]:
        """å¤„ç†æ™®é€šAgentçš„æµå¼è¾“å‡º"""
        if chunk_type == "messages":
            self._process_message_chunk(chunk_data)
        elif chunk_type == "updates" and isinstance(chunk_data, dict):
            self._process_content_updates(chunk_data)
        elif chunk_type == "custom" and isinstance(chunk_data, dict):
            self._process_custom_data(chunk_data)
        
        return {"chunk_count": self.chunk_count, "current_step": self.current_step}
    
    def _process_custom_data(self, custom_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è‡ªå®šä¹‰æ¶ˆæ¯æ•°æ® - ä¸FlatDataProcessoré…åˆï¼Œå¤„ç†æœªè¢«æ‰å¹³åŒ–çš„æ•°æ®"""
        # Customæ¶ˆæ¯ä¼˜å…ˆç”±FlatDataProcessorå¤„ç†å¹¶æ‰å¹³åŒ–
        # è¿™é‡Œå¤„ç†é‚£äº›æ²¡æœ‰è¢«æ‰å¹³åŒ–å¤„ç†å™¨æ•è·çš„æ•°æ®
        
        message_type = custom_data.get("message_type", "")
        
        # é’ˆå¯¹reasoningæ¶ˆæ¯è¿›è¡Œå»é‡å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if message_type == "reasoning":
            content = custom_data.get("content", "")
            metadata = custom_data.get("metadata", {})
            
            # åˆ›å»ºå»é‡keyï¼Œæ’é™¤timestampç­‰æ—¶é—´ç›¸å…³å­—æ®µ
            dedup_key = (
                content,
                metadata.get("node_name", "") if metadata else custom_data.get("node", ""),
                int(metadata.get("step_duration", 0)) if metadata else int(custom_data.get("duration", 0))
            )
            
            # å¦‚æœå·²å¤„ç†è¿‡ç›¸åŒå†…å®¹ï¼Œè·³è¿‡
            if dedup_key in self.processed_reasoning:
                return {"chunk_count": self.chunk_count, "current_step": self.current_step}
            
            self.processed_reasoning.add(dedup_key)
        
        # åªä¼ é€’ç”¨æˆ·å…³å¿ƒçš„å·¥ä½œæµç¨‹æ¶ˆæ¯
        if message_type in ["step_start", "step_progress", "step_complete", 
                           "tool_call", "tool_result", "thinking", "reasoning",
                           "content_streaming", "content_complete", "final_result"]:
            
            content = custom_data.get("content", "")
            
            # å¤„ç†æ‰å¹³åŒ–æ ¼å¼å’ŒåŸå§‹æ ¼å¼
            if 'metadata' in custom_data:
                # åŸå§‹æ ¼å¼ï¼Œæœ‰metadataåµŒå¥—
                metadata = custom_data.get("metadata", {})
                
                if message_type == "step_start":
                    self.writer.step_start(content)
                elif message_type == "step_progress":
                    progress = metadata.get("progress", 0)
                    self.writer.step_progress(content, progress, **metadata)
                elif message_type == "step_complete":
                    self.writer.step_complete(content, **metadata)
                elif message_type == "thinking":
                    self.writer.thinking(content)
                elif message_type == "reasoning":
                    self.writer.reasoning(content, **metadata)
                elif message_type == "tool_call":
                    tool_name = metadata.get("tool_name", "")
                    tool_args = metadata.get("tool_args", {})
                    self.writer.tool_call(tool_name, tool_args)
                elif message_type == "tool_result":
                    tool_name = metadata.get("tool_name", "")
                    self.writer.tool_result(tool_name, content)
                elif message_type == "content_streaming":
                    self.writer.content_streaming(content, metadata.get("chunk_index", 0))
                elif message_type == "content_complete":
                    self.writer.content_complete(content, **metadata)
                elif message_type == "final_result":
                    execution_summary = metadata.get("execution_summary", {})
                    self.writer.final_result(content, execution_summary)
            else:
                # æ‰å¹³åŒ–æ ¼å¼ï¼Œæ•°æ®å·²åœ¨é¡¶å±‚ - è¿™äº›åº”è¯¥å·²ç»è¢«FlatDataProcessorå¤„ç†äº†
                # è¿™é‡Œä¸éœ€è¦é‡å¤å¤„ç†ï¼Œç›´æ¥è·³è¿‡
                pass
        
        return {"chunk_count": self.chunk_count, "current_step": self.current_step}
    
    def _process_message_chunk(self, message: Any):
        """å¤„ç†messagesç±»å‹çš„chunk - ä»AIæ¶ˆæ¯ä¸­æå–æµå¼ä¿¡æ¯"""
        if not hasattr(message, '__class__'):
            return
            
        msg_type = type(message).__name__
        
        if msg_type in ["AIMessage", "AIMessageChunk"]:
            # æ£€æµ‹å·¥å…·è°ƒç”¨ - ä½¿ç”¨ç»Ÿä¸€å¤„ç†æ–¹æ³•
            if hasattr(message, 'tool_calls') and message.tool_calls:
                for tool_call in message.tool_calls:
                    tool_name = tool_call.get('name', 'unknown_tool')
                    tool_args = tool_call.get('args', {})
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨å¤„ç†æ–¹æ³•
                    self.writer.tool_call(tool_name, tool_args)
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„æ€è€ƒå†…å®¹ç”Ÿæˆæ–¹æ³•  
                    thinking_content = self._generate_tool_thinking_content(tool_name, tool_args)
                    if thinking_content:
                        self.writer.thinking(thinking_content)
            
            # æ£€æµ‹AIå›å¤å†…å®¹
            if hasattr(message, 'content') and message.content:
                content = str(message.content)
                
                # å¯¹äºAIMessageChunkï¼Œå†…å®¹é€šå¸¸æ˜¯æµå¼çš„å°ç‰‡æ®µ
                if msg_type == "AIMessageChunk":
                    # æµå¼å†…å®¹ç‰‡æ®µ
                    if content and content.strip():
                        self.writer.content_streaming(content)
                else:
                    # å®Œæ•´çš„AIæ¶ˆæ¯
                    if len(content) > 300:
                        preview = content[:500] + "..." if len(content) > 500 else content
                        self.writer.content_streaming(preview)
                    elif len(content) > 50:
                        self.writer.reasoning(content)
                    
        elif msg_type == "ToolMessage":
            # æ£€æµ‹å·¥å…·ç»“æœ - ä½¿ç”¨ç»Ÿä¸€å¤„ç†æ–¹æ³•
            if hasattr(message, 'content') and message.content:
                tool_name = getattr(message, 'name', 'unknown_tool')
                result = str(message.content)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·ç»“æœå¤„ç†æ–¹æ³•
                self.writer.tool_result(tool_name, result)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„åé¦ˆå†…å®¹ç”Ÿæˆæ–¹æ³•
                feedback_content = self._generate_tool_feedback_content(tool_name, result)
                if feedback_content:
                    self.writer.thinking(feedback_content)
    
    # åˆ é™¤_process_workflow_step - è¯¥é€»è¾‘å·²è¢«FlatDataProcessorå¤„ç†
    
    def _process_content_updates(self, updates_data: Dict[str, Any]):
        """å¤„ç†å†…å®¹æ›´æ–° - æ¢å¤å®Œæ•´é€»è¾‘å¤„ç†å­å›¾æ•°æ®"""
        for node_name, node_data in updates_data.items():
            if not isinstance(node_data, dict):
                continue
            
            # å¤„ç†èŠ‚ç‚¹æ•°æ® - æ¢å¤åŸæœ‰å®Œæ•´é€»è¾‘
            
            # æ£€æµ‹Agentæ¶ˆæ¯ä¸­çš„å·¥å…·è°ƒç”¨ - é‡è¦ï¼šæ•è·å·¥å…·ä½¿ç”¨è¿‡ç¨‹
            if "messages" in node_data:
                messages = node_data["messages"]
                # å¤„ç†messages
                if isinstance(messages, list):
                    for message in messages:
                        # å¤„ç†å•ä¸ªæ¶ˆæ¯
                        self._process_agent_message(message, node_name)
            
            # æ£€æµ‹åˆ°æ–°ç« èŠ‚å®Œæˆ
            if "sections" in node_data:
                sections = node_data["sections"]
                if isinstance(sections, list):
                    for section in sections:
                        if isinstance(section, dict) and section.get("title"):
                            title = section["title"]
                            word_count = section.get("word_count", 0)
                            if title not in [s.get("title") for s in self.sections_completed]:
                                self.sections_completed.append(section)
                                self.writer.content_complete(
                                    f"å®Œæˆç« èŠ‚: {title}",
                                    word_count=word_count,
                                    section_title=title
                                )
            
            # æ£€æµ‹åˆ°æ–°çš„ç ”ç©¶å‘ç°
            if "research_results" in node_data:
                research_data = node_data["research_results"]
                if isinstance(research_data, dict):
                    for research in research_data.values():
                        if isinstance(research, dict) and research.get("title"):
                            title = research["title"]
                            if title not in [r.get("title") for r in self.research_findings]:
                                self.research_findings.append(research)
                                self.writer.step_progress(
                                    f"å‘ç°ç ”ç©¶èµ„æ–™: {title}",
                                    progress=0,  # ä¿®å¤progress=Noneçš„é—®é¢˜
                                    research_title=title
                                )
            
            # æ£€æµ‹åˆ°æœ€ç»ˆæŠ¥å‘Š
            if "final_report" in node_data:
                self.final_output = node_data["final_report"]
                total_words = self.final_output.get("total_words", 0)
    
    def _process_agent_message(self, message: Any, source_node: str):
        """å¤„ç†Agentæ¶ˆæ¯ï¼Œæ£€æµ‹å·¥å…·è°ƒç”¨ - æ¢å¤å®Œæ•´é€»è¾‘å¤„ç†å­å›¾ä¸­çš„å·¥å…·è°ƒç”¨"""
        # source_nodeå‚æ•°ä¿ç•™ç”¨äºåç»­æ‰©å±•ï¼Œå½“å‰ç‰ˆæœ¬æœªä½¿ç”¨
        if not hasattr(message, '__class__'):
            return
            
        msg_type = type(message).__name__
        
        if msg_type in ["AIMessage", "AIMessageChunk"]:
            # æ£€æµ‹å·¥å…·è°ƒç”¨ - è¿™æ˜¯ç”¨æˆ·æœ€å…³å¿ƒçš„éƒ¨åˆ†
            if hasattr(message, 'tool_calls') and message.tool_calls:
                # æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œå¤„ç†æ¯ä¸ªå·¥å…·
                for tool_call in message.tool_calls:
                    tool_name = tool_call.get('name', 'unknown_tool')
                    tool_args = tool_call.get('args', {})
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨å¤„ç†æ–¹æ³•
                    self.writer.tool_call(tool_name, tool_args)
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„æ€è€ƒå†…å®¹ç”Ÿæˆæ–¹æ³•
                    thinking_content = self._generate_tool_thinking_content(tool_name, tool_args)
                    if thinking_content:
                        self.writer.thinking(thinking_content)
            
            # æ£€æµ‹AIå›å¤å†…å®¹
            if hasattr(message, 'content') and message.content:
                content = str(message.content)
                
                # å¯¹äºAIMessageChunkï¼Œå†…å®¹é€šå¸¸æ˜¯æµå¼çš„å°ç‰‡æ®µ
                if msg_type == "AIMessageChunk":
                    # æµå¼å†…å®¹ç‰‡æ®µ - ç›´æ¥æ˜¾ç¤º
                    if content and content.strip():
                        self.writer.content_streaming(content)
                else:
                    # å®Œæ•´çš„AIæ¶ˆæ¯
                    if len(content) > 300:
                        self.writer.content_streaming(content[:500] + "..." if len(content) > 500 else content)
                    elif len(content) > 50:
                        self.writer.reasoning(content)
                    
        elif msg_type == "ToolMessage":
            # æ£€æµ‹å·¥å…·ç»“æœ - å±•ç¤ºå·¥å…·è¿”å›çš„å†…å®¹
            if hasattr(message, 'content') and message.content:
                tool_name = getattr(message, 'name', 'unknown_tool')
                result = str(message.content)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·ç»“æœå¤„ç†æ–¹æ³•
                self.writer.tool_result(tool_name, result)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„åé¦ˆå†…å®¹ç”Ÿæˆæ–¹æ³•
                feedback_content = self._generate_tool_feedback_content(tool_name, result)
                if feedback_content:
                    self.writer.thinking(feedback_content)
    
    def _process_agent_message_with_agent(self, message: Any, source_node: str, agent_name: str):
        """å¤„ç†Agentæ¶ˆæ¯ï¼Œæ£€æµ‹å·¥å…·è°ƒç”¨ - å¸¦agentä¿¡æ¯ç‰ˆæœ¬"""
        if not hasattr(message, '__class__'):
            return
            
        msg_type = type(message).__name__
        
        if msg_type in ["AIMessage", "AIMessageChunk"]:
            # æ£€æµ‹å·¥å…·è°ƒç”¨ - è¿™æ˜¯ç”¨æˆ·æœ€å…³å¿ƒçš„éƒ¨åˆ†
            if hasattr(message, 'tool_calls') and message.tool_calls:
                # æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œå¤„ç†æ¯ä¸ªå·¥å…·
                for tool_call in message.tool_calls:
                    tool_name = tool_call.get('name', 'unknown_tool')
                    tool_args = tool_call.get('args', {})
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨å¤„ç†æ–¹æ³•
                    self._send_agent_message("tool_call", "", agent_name, 
                                           tool_name=tool_name, args=tool_args)
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„æ€è€ƒå†…å®¹ç”Ÿæˆæ–¹æ³•
                    thinking_content = self._generate_tool_thinking_content(tool_name, tool_args)
                    if thinking_content:
                        self._send_agent_message("thinking", thinking_content, agent_name)
            
            # æ£€æµ‹AIå›å¤å†…å®¹
            if hasattr(message, 'content') and message.content:
                content = str(message.content)
                
                # å¯¹äºAIMessageChunkï¼Œå†…å®¹é€šå¸¸æ˜¯æµå¼çš„å°ç‰‡æ®µ
                if msg_type == "AIMessageChunk":
                    # æµå¼å†…å®¹ç‰‡æ®µ - ç›´æ¥æ˜¾ç¤º
                    if content and content.strip():
                        self._send_agent_message("content_streaming", content, agent_name, 
                                               length=len(content), chunk_index=0)
                else:
                    # å®Œæ•´çš„AIæ¶ˆæ¯
                    if len(content) > 300:
                        preview_content = content[:500] + "..." if len(content) > 500 else content
                        self._send_agent_message("content_streaming", preview_content, agent_name,
                                               length=len(content), chunk_index=0)
                    elif len(content) > 50:
                        self._send_agent_message("reasoning", content, agent_name)
                    
        elif msg_type == "ToolMessage":
            # æ£€æµ‹å·¥å…·ç»“æœ - å±•ç¤ºå·¥å…·è¿”å›çš„å†…å®¹
            if hasattr(message, 'content') and message.content:
                tool_name = getattr(message, 'name', 'unknown_tool')
                result = str(message.content)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·ç»“æœå¤„ç†æ–¹æ³•
                self._send_agent_message("tool_result", result, agent_name,
                                        tool_name=tool_name, length=len(result))
                
                # ä½¿ç”¨ç»Ÿä¸€çš„åé¦ˆå†…å®¹ç”Ÿæˆæ–¹æ³•
                feedback_content = self._generate_tool_feedback_content(tool_name, result)
                if feedback_content:
                    self._send_agent_message("thinking", feedback_content, agent_name)
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæ€»ç»“"""
        return {
            "total_chunks_processed": self.chunk_count,
            "sections_completed": len(self.sections_completed),
            "research_findings": len(self.research_findings),
            "sections": self.sections_completed,
            "final_output": self.final_output
        }


# ============================================================================
# ä¾¿æ·å‡½æ•° - æ”¯æŒæ‰å¹³åŒ–æ•°æ®æ ¼å¼
# ============================================================================

def create_stream_writer(node_name: str, agent_name: str = "", custom_templates: Optional[Dict[str, str]] = None) -> StreamWriter:
    """åˆ›å»ºæ‰å¹³åŒ–æµå¼writer"""
    return StreamWriter(node_name, agent_name, custom_templates)

def create_workflow_processor(node_name: str, agent_name: str = "", custom_templates: Optional[Dict[str, str]] = None) -> AgentWorkflowProcessor:
    """åˆ›å»ºæ‰å¹³åŒ–Agentå·¥ä½œæµç¨‹å¤„ç†å™¨"""
    writer = create_stream_writer(node_name, agent_name, custom_templates)
    return AgentWorkflowProcessor(writer, custom_templates)

def create_flat_processor(custom_templates: Optional[Dict[str, str]] = None) -> FlatDataProcessor:
    """åˆ›å»ºçº¯æ‰å¹³åŒ–æ•°æ®å¤„ç†å™¨ï¼ˆæ— writerè¾“å‡ºï¼‰"""
    return FlatDataProcessor(custom_templates)

def create_agent_stream_collector(node_name: str, agent_name: str = "", custom_templates: Optional[Dict[str, str]] = None):
    """åˆ›å»ºç®€åŒ–çš„Agentæµå¼è¾“å‡ºæ”¶é›†å™¨"""
    writer = create_stream_writer(node_name, agent_name, custom_templates)
    return AgentStreamCollector(writer, custom_templates)


# ============================================================================
# Agentæµå¼è¾“å‡ºå¤„ç†å™¨ - å‚è€ƒMulti-Agent-reportè®¾è®¡
# ============================================================================

class AgentStreamCollector:
    """Agentæµå¼è¾“å‡ºæ”¶é›†å™¨ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨FlatDataProcessor"""
    
    def __init__(self, writer: StreamWriter, custom_templates: Optional[Dict[str, str]] = None):
        self.writer = writer
        self.flat_processor = FlatDataProcessor(custom_templates)
        self.full_response = ""
        self.tools_used = []
        self.chunk_count = 0
    
    async def process_agent_stream(self, agent_stream, agent_name: str):
        """å¤„ç†agentçš„æ··åˆæµå¼è¾“å‡º - ç®€åŒ–ç‰ˆæœ¬"""
        self.writer.thinking(f"å¼€å§‹åˆ†æå’Œå¤„ç† {agent_name} ä»»åŠ¡...")
        
        try:
            async for chunk in agent_stream:
                self.chunk_count += 1
                
                # ä¼˜å…ˆä½¿ç”¨FlatDataProcessorå¤„ç†
                flat_data = self.flat_processor.flatten_chunk(chunk)
                if flat_data:
                    # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œè®°å½•å·¥å…·å
                    if flat_data.get('message_type') == 'tool_call':
                        tool_name = flat_data.get('tool_name', '')
                        if tool_name and tool_name not in self.tools_used:
                            self.tools_used.append(tool_name)
                    
                    # å¦‚æœæ˜¯å†…å®¹æµï¼Œç´¯ç§¯å“åº”
                    elif flat_data.get('message_type') == 'content_streaming':
                        content = flat_data.get('content', '')
                        if content:
                            self.full_response += content
                
            # å¤„ç†å®Œæˆ
            if self.full_response:
                self.writer.content_complete(
                    f"{agent_name}ä»»åŠ¡å®Œæˆ",
                    word_count=len(self.full_response.split()),
                    tools_used=self.tools_used,
                    total_chunks=self.chunk_count
                )
            
            return self.full_response
            
        except Exception as e:
            self.writer.error(f"{agent_name} å¤„ç†å¤±è´¥: {str(e)}", "StreamProcessingError")
            return ""