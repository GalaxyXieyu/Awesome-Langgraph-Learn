"""
æµ‹è¯•ç»Ÿä¸€æµå¼è¾“å‡ºç³»ç»Ÿ
éªŒè¯æ–°çš„Agentå·¥ä½œæµç¨‹æ¶ˆæ¯ç±»å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import time
from stream_writer import (
    create_stream_writer, 
    create_workflow_processor,
    MessageType,
    format_message_for_frontend
)

def test_message_types():
    """æµ‹è¯•æ–°çš„æ¶ˆæ¯ç±»å‹"""
    print("=== æµ‹è¯•æ¶ˆæ¯ç±»å‹ ===")
    
    # åˆ›å»ºwriter
    writer = create_stream_writer("test_node", "æµ‹è¯•Agent")
    
    # æµ‹è¯•å„ç§æ¶ˆæ¯ç±»å‹
    print("1. æµ‹è¯•æ­¥éª¤æµç¨‹:")
    writer.step_start("å¼€å§‹æµ‹è¯•ä»»åŠ¡")
    writer.step_progress("æ‰§è¡Œä¸­", 50, test_data="æµ‹è¯•æ•°æ®")
    writer.step_complete("æµ‹è¯•ä»»åŠ¡å®Œæˆ", duration=2.5)
    
    print("\n2. æµ‹è¯•å·¥å…·è°ƒç”¨:")
    writer.tool_call("search_tool", {"query": "äººå·¥æ™ºèƒ½", "limit": 10})
    writer.tool_result("search_tool", "æ‰¾åˆ°äº†10ä¸ªç›¸å…³ç»“æœ...")
    
    print("\n3. æµ‹è¯•æ€è€ƒè¿‡ç¨‹:")
    writer.thinking("åˆ†ææœç´¢ç»“æœçš„è´¨é‡")
    writer.reasoning("åŸºäºæœç´¢ç»“æœï¼Œæˆ‘éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶æŠ€æœ¯ç»†èŠ‚")
    
    print("\n4. æµ‹è¯•å†…å®¹è¾“å‡º:")
    writer.content_streaming("## äººå·¥æ™ºèƒ½æ¦‚è¿°\n\näººå·¥æ™ºèƒ½æ˜¯...")
    writer.content_complete("ç« èŠ‚å†™ä½œå®Œæˆ", word_count=500, section_title="äººå·¥æ™ºèƒ½æ¦‚è¿°")
    
    print("\n5. æµ‹è¯•æœ€ç»ˆç»“æœ:")
    writer.final_result("æŠ¥å‘Šç”Ÿæˆå®Œæˆ", {"sections": 5, "total_words": 2500})
    
    print("âœ… åŸºç¡€æ¶ˆæ¯ç±»å‹æµ‹è¯•å®Œæˆ\n")

def test_workflow_processor():
    """æµ‹è¯•å·¥ä½œæµç¨‹å¤„ç†å™¨"""
    print("=== æµ‹è¯•å·¥ä½œæµç¨‹å¤„ç†å™¨ ===")
    
    processor = create_workflow_processor("workflow_test", "å·¥ä½œæµæµ‹è¯•")
    
    # æ¨¡æ‹Ÿå­å›¾chunkæ•°æ®
    test_chunks = [
        ("custom", {"step": "research", "status": "å¼€å§‹ç ”ç©¶åˆ†æ", "progress": 0}),
        ("custom", {"step": "research", "status": "æ”¶é›†èµ„æ–™ä¸­", "progress": 50}),
        ("custom", {"step": "research", "status": "ç ”ç©¶å®Œæˆ", "progress": 100}),
        ("custom", {"step": "writing", "status": "å¼€å§‹å†™ä½œ", "progress": 0}),
        ("custom", {"step": "writing", "status": "æ­£åœ¨å†™ä½œ", "progress": 60, "streaming_content": "## å¼•è¨€\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç« èŠ‚..."}),
        ("custom", {"step": "writing", "status": "å†™ä½œå®Œæˆ", "progress": 100}),
        ("updates", {"writing_node": {"sections": [{"title": "å¼•è¨€", "content": "è¿™æ˜¯å¼•è¨€å†…å®¹", "word_count": 200}]}}),
        ("updates", {"research_node": {"research_results": {"section1": {"title": "AIç ”ç©¶", "content": "ç ”ç©¶å†…å®¹..."}}}})
    ]
    
    print("å¤„ç†æ¨¡æ‹Ÿçš„chunkæ•°æ®:")
    for i, chunk in enumerate(test_chunks, 1):
        print(f"  å¤„ç†chunk {i}: {chunk[0]} - {chunk[1].get('step', 'unknown')}")
        result = processor.process_chunk(chunk)
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†é—´éš”
    
    # è·å–å¤„ç†æ‘˜è¦
    summary = processor.get_summary()
    print(f"\nå¤„ç†æ‘˜è¦: {summary}")
    print("âœ… å·¥ä½œæµç¨‹å¤„ç†å™¨æµ‹è¯•å®Œæˆ\n")

def test_frontend_formatting():
    """æµ‹è¯•å‰ç«¯æ ¼å¼åŒ–"""
    print("=== æµ‹è¯•å‰ç«¯æ ¼å¼åŒ– ===")
    
    # æ¨¡æ‹Ÿå„ç§æ¶ˆæ¯ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨
    test_messages = [
        {
            "message_type": "step_start",
            "timestamp": time.time(),
            "node_name": "research",
            "agent_name": "ç ”ç©¶åŠ©æ‰‹",
            "content": "å¼€å§‹ç ”ç©¶åˆ†æ",
            "metadata": {"step_duration": 0}
        },
        {
            "message_type": "tool_call",
            "timestamp": time.time(),
            "node_name": "research",
            "agent_name": "ç ”ç©¶åŠ©æ‰‹",
            "content": "è°ƒç”¨ trends_analysis_tool å·¥å…·",
            "metadata": {
                "tool_name": "trends_analysis_tool",
                "tool_args": {"topic": "äººå·¥æ™ºèƒ½", "depth": "detailed"}
            }
        },
        {
            "message_type": "thinking",
            "timestamp": time.time(),
            "node_name": "research", 
            "agent_name": "ç ”ç©¶åŠ©æ‰‹",
            "content": "ä½¿ç”¨è¶‹åŠ¿åˆ†æå·¥å…·ç ”ç©¶: äººå·¥æ™ºèƒ½",
            "metadata": {"step_duration": 1.2}
        },
        {
            "message_type": "tool_result",
            "timestamp": time.time(),
            "node_name": "research",
            "agent_name": "ç ”ç©¶åŠ©æ‰‹",
            "content": "trends_analysis_tool æ‰§è¡Œç»“æœ: åˆ†æå®Œæˆï¼Œå‘ç°3ä¸ªä¸»è¦è¶‹åŠ¿...",
            "metadata": {
                "tool_name": "trends_analysis_tool",
                "full_result": "è¯¦ç»†çš„è¶‹åŠ¿åˆ†æç»“æœï¼ŒåŒ…å«å¤§é‡æ•°æ®å’Œè§è§£...",
                "result_length": 1250
            }
        },
        {
            "message_type": "reasoning",
            "timestamp": time.time(),
            "node_name": "research",
            "agent_name": "ç ”ç©¶åŠ©æ‰‹",
            "content": "è¶‹åŠ¿åˆ†æå®Œæˆï¼Œå¼€å§‹æ•´ç†ç ”ç©¶ç»“æœ",
            "metadata": {"step_duration": 2.5}
        },
        {
            "message_type": "content_streaming",
            "timestamp": time.time(),
            "node_name": "writer",
            "agent_name": "å†™ä½œåŠ©æ‰‹", 
            "content": "## äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹\n\näººå·¥æ™ºèƒ½æŠ€æœ¯ç»å†äº†...",
            "metadata": {"chunk_index": 1, "is_streaming": True}
        },
        {
            "message_type": "content_complete",
            "timestamp": time.time(),
            "node_name": "writer",
            "agent_name": "å†™ä½œåŠ©æ‰‹",
            "content": "ç« èŠ‚å†™ä½œå®Œæˆ",
            "metadata": {"word_count": 450, "section_title": "AIå‘å±•å†ç¨‹"}
        }
    ]
    
    print("å‰ç«¯æ ¼å¼åŒ–ç»“æœï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰:")
    for msg in test_messages:
        formatted = format_message_for_frontend(msg)
        print(f"  {formatted['type']}: {formatted['display']} [{formatted.get('icon', 'none')}]")
        if 'progress' in formatted:
            print(f"    è¿›åº¦: {formatted['progress']}%")
        if 'word_count' in formatted:
            print(f"    å­—æ•°: {formatted['word_count']}")
        if 'tool_name' in formatted:
            print(f"    å·¥å…·: {formatted['tool_name']}")
        if 'result_length' in formatted:
            print(f"    ç»“æœé•¿åº¦: {formatted['result_length']}å­—ç¬¦")
    
    print("âœ… å‰ç«¯æ ¼å¼åŒ–æµ‹è¯•å®Œæˆï¼ˆåŒ…å«å·¥å…·è°ƒç”¨æ”¯æŒï¼‰\n")

async def test_async_workflow():
    """æµ‹è¯•å¼‚æ­¥å·¥ä½œæµç¨‹"""
    print("=== æµ‹è¯•å¼‚æ­¥å·¥ä½œæµç¨‹ ===")
    
    writer = create_stream_writer("async_test", "å¼‚æ­¥æµ‹è¯•")
    
    # æ¨¡æ‹Ÿå¼‚æ­¥ä»»åŠ¡æµç¨‹
    writer.step_start("å¼€å§‹å¼‚æ­¥ç ”ç©¶ä»»åŠ¡")
    
    for i in range(1, 6):
        await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†æ—¶é—´
        writer.step_progress(f"å¤„ç†ç¬¬{i}é˜¶æ®µ", i * 20)
        
        if i == 2:
            writer.thinking("åˆ†æä¸­é—´ç»“æœ")
        elif i == 4:
            writer.content_streaming(f"ç”Ÿæˆå†…å®¹ç‰‡æ®µ {i}")
    
    writer.step_complete("å¼‚æ­¥ä»»åŠ¡å®Œæˆ")
    print("âœ… å¼‚æ­¥å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆ\n")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ç»Ÿä¸€æµå¼è¾“å‡ºç³»ç»Ÿ\n")
    
    # è¿è¡Œæµ‹è¯•
    test_message_types()
    test_workflow_processor()  
    test_frontend_formatting()
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    print("è¿è¡Œå¼‚æ­¥æµ‹è¯•...")
    asyncio.run(test_async_workflow())
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼æ–°çš„æµå¼è¾“å‡ºç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
    print("\nä¸»è¦æ”¹è¿›:")
    print("- âœ… å»é™¤äº†æ‰€æœ‰æŠ€æœ¯ç»†èŠ‚ï¼ˆå¦‚SUBGRAPH_*ï¼‰")
    print("- âœ… ä¸“æ³¨äºAgentå·¥ä½œæµç¨‹å±•ç¤º") 
    print("- âœ… æ”¯æŒå·¥å…·è°ƒç”¨æ£€æµ‹å’Œå±•ç¤º")
    print("- âœ… ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼ï¼Œä¾¿äºå‰ç«¯æ¸²æŸ“")
    print("- âœ… æ™ºèƒ½è¯†åˆ«å·¥ä½œé˜¶æ®µ")
    print("- âœ… å¤§å¹…å‡å°‘ä»£ç å¤æ‚åº¦")
    print("- âœ… æ¶ˆé™¤å†—ä½™æ—¥å¿—è¾“å‡º")
    print("\nç°åœ¨æ”¯æŒçš„æ¶ˆæ¯ç±»å‹:")
    print("  ğŸ“‹ æ­¥éª¤æµç¨‹: step_start, step_progress, step_complete")
    print("  ğŸ”§ å·¥å…·ä½¿ç”¨: tool_call, tool_result") 
    print("  ğŸ§  æ€è€ƒè¿‡ç¨‹: thinking, reasoning")
    print("  âœï¸ å†…å®¹è¾“å‡º: content_streaming, content_complete")
    print("  ğŸ¯ æœ€ç»ˆç»“æœ: final_result")
    print("  âŒ é”™è¯¯å¤„ç†: error")

if __name__ == "__main__":
    main()