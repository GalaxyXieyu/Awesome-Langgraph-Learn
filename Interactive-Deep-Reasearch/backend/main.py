"""FastAPI and Celery service for the Interactive Deep Research graph.
Provides asynchronous task execution with Redis checkpoint storage and
both API and terminal interfaces.

ğŸ¯ ç®€åŒ–ç‰ˆæ¶æ„ (2024å¹´12æœˆæ›´æ–°):
- ä½¿ç”¨æ–°çš„4ä¸ªæ ¸å¿ƒæ¶ˆæ¯ç±»å‹: processing, content, thinking, interrupt
- å…¼å®¹æ—§æ ¼å¼æ¶ˆæ¯ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºæ–°æ ¼å¼
- åŸºäº writer/WriterDocs.md çš„æœ€æ–°ç®€åŒ–è®¾è®¡
"""
import asyncio
import json
import os
import uuid
from typing import Dict, Any

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from celery import Celery
import redis
from langchain_core.runnables import RunnableConfig

from graph import create_deep_research_graph
from state import create_simple_state
from utils import process_chunk, generate_stream_events

# ---------------------------------------------------------------------------
# Redis & Celery configuration
# ---------------------------------------------------------------------------
REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
PG_URL = os.environ.get("PG_URL")
redis_client = redis.Redis.from_url(REDIS_URL, decode_responses=True)
celery_app = Celery("deep_research", broker=REDIS_URL, backend=REDIS_URL)


def get_checkpointer():
    """
    è·å– checkpoint saver

    æ ¹æ®ç¯å¢ƒé…ç½®é€‰æ‹©ä½¿ç”¨ PostgreSQL æˆ–å†…å­˜å­˜å‚¨
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ PostgreSQL checkpoint
    use_postgres = os.environ.get("USE_POSTGRES_CHECKPOINT", "false").lower() == "true"

    # å¦‚æœæœ‰ PG_URL ä¸”å¯ç”¨äº† PostgreSQL checkpointï¼Œåˆ™ä½¿ç”¨ PostgreSQL
    if use_postgres and PG_URL:
        try:
            from config.checkpoint import ResearchPostgresSaver
            print("ğŸ”— ä½¿ç”¨ PostgreSQL checkpoint saver")
            print(f"ğŸ”— æ•°æ®åº“: {PG_URL.split('@')[1] if '@' in PG_URL else 'unknown'}")
            checkpointer = ResearchPostgresSaver(PG_URL)
            checkpointer.setup()  # åˆ›å»ºè¡¨ç»“æ„
            return checkpointer
        except Exception as e:
            print(f"âŒ PostgreSQL checkpoint saver åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°å†…å­˜å­˜å‚¨")
    elif PG_URL:
        print("ğŸ’¡ æ£€æµ‹åˆ° PG_URL é…ç½®ï¼Œä½†æœªå¯ç”¨ PostgreSQL checkpoint")
        print("ğŸ’¡ è¦å¯ç”¨è¯·è®¾ç½®: USE_POSTGRES_CHECKPOINT=true")

    # é»˜è®¤ä½¿ç”¨å†…å­˜å­˜å‚¨
    print("ğŸ’¾ ä½¿ç”¨å†…å­˜ checkpoint saver")
    from langgraph.checkpoint.memory import MemorySaver
    return MemorySaver()


# ---------------------------------------------------------------------------
# Celery task that executes the research graph asynchronously
# ---------------------------------------------------------------------------
@celery_app.task(name="run_research_task")
def run_research_task(task_data: Dict[str, Any], task_id: str) -> Dict[str, Any]:
    """Execute the deep research graph and store progress in Redis streams."""

    async def _runner() -> Dict[str, Any]:
        workflow = create_deep_research_graph()
        checkpointer = get_checkpointer()
        graph = workflow.compile(checkpointer=checkpointer)

        # ä» task_data æå–å¿…è¦ä¿¡æ¯
        user_id = task_data.get("user_id", "user")
        topic = task_data.get("topic", "")
        mode = task_data.get("mode", "copilot")
        
        # åˆ›å»ºçŠ¶æ€æ—¶ä¼ é€’ mode å‚æ•°
        state = create_simple_state(topic, user_id=user_id, mode=mode)
        state["session_id"] = task_id
        config = RunnableConfig(configurable={"thread_id": task_id})

        # ä½¿ç”¨writer/core.pyçš„ç®€åŒ–ç‰ˆæ ‡å‡†åŒ–å¤„ç†å™¨
        from writer.core import AgentWorkflowProcessor, create_stream_writer
        from writer.config import get_writer_config

        # åˆ›å»ºç®€åŒ–ç‰ˆæ¶ˆæ¯å¤„ç†å™¨ - æ”¯æŒæ–°çš„4ä¸ªæ ¸å¿ƒæ¶ˆæ¯ç±»å‹
        config_obj = get_writer_config()
        writer = create_stream_writer("research_task", "main", config=config_obj)
        processor = AgentWorkflowProcessor(writer, config=config_obj)

        async for chunk in graph.astream(state, config, stream_mode=["custom", "updates", "messages"]):
            # è¶…ç®€åŒ–ï¼šgraph chunk è½¬åŒ–ä¸€å±‚åˆ° redis
            process_chunk(chunk, task_id, redis_client, processor)
        redis_client.hset(f"task:{task_id}", "status", "completed")
        return {"status": "completed"}

    return asyncio.run(_runner())

# ---------------------------------------------------------------------------
# FastAPI application
# ---------------------------------------------------------------------------
app = FastAPI(title="Interactive Deep Research")

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class CreateTask(BaseModel):
    topic: str
    user_id: str = "user"
    mode: str = "copilot"
    report_type: str = "comprehensive"
    target_audience: str = "general"
    depth_level: str = "moderate"
    max_sections: int = 5
    target_length: int = 1000
    language: str = "zh"
    style: str = "professional"

@app.post("/research/tasks")
async def create_task(req: CreateTask):
    task_id = uuid.uuid4().hex[:8]  # ç§»é™¤task_å‰ç¼€
    # ä¼ é€’å®Œæ•´çš„è¯·æ±‚æ•°æ®åˆ° Celery ä»»åŠ¡
    result = run_research_task.apply_async(args=[req.dict(), task_id])
    redis_client.hset(
        f"task:{task_id}",
        mapping={
            "status": "pending",
            "topic": req.topic,
            "user_id": req.user_id,
            "mode": req.mode,
            "report_type": req.report_type,
            "celery_id": result.id,
        },
    )
    return {"task_id": task_id}


@app.get("/research/tasks/{task_id}")
async def get_task(task_id: str):
    data = redis_client.hgetall(f"task:{task_id}")
    if not data:
        raise HTTPException(status_code=404, detail="task not found")
    return data


@app.get("/research/tasks/{task_id}/stream")
async def stream_task(task_id: str):
    """äº‹ä»¶æµ - ä½¿ç”¨æŠ½å–çš„æµå¼å¤„ç†å‡½æ•°"""
    return StreamingResponse(
        generate_stream_events(task_id, redis_client),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*"
        }
    )

@app.post("/research/tasks/{task_id}/cancel")
async def cancel_task(task_id: str):
    data = redis_client.hgetall(f"task:{task_id}")
    if not data:
        raise HTTPException(status_code=404, detail="task not found")
    celery_id = data.get("celery_id")
    if celery_id:
        celery_app.control.revoke(celery_id, terminate=True)
    redis_client.hset(f"task:{task_id}", "status", "canceled")
    redis_client.xadd(f"events:{task_id}", {"data": json.dumps({"status": "canceled"})})
    return {"status": "canceled"}


# ---------------------------------------------------------------------------
# Terminal usage
# ---------------------------------------------------------------------------
def stop(topic: str, user_id: str = "cli") -> None:
    """Run the research graph and print events to stdout - æ”¯æŒç®€åŒ–ç‰ˆæ¶ˆæ¯æ ¼å¼."""

    async def _run() -> None:
        workflow = create_deep_research_graph()
        checkpointer = get_checkpointer()
        graph = workflow.compile(checkpointer=checkpointer)
        state = create_simple_state(topic, user_id=user_id)

        # ä½¿ç”¨ç®€åŒ–ç‰ˆå¤„ç†å™¨
        from writer.core import AgentWorkflowProcessor, create_stream_writer
        from writer.config import get_writer_config

        config_obj = get_writer_config()
        writer = create_stream_writer("terminal", "cli", config=config_obj)
        processor = AgentWorkflowProcessor(writer, config=config_obj)

        try:
            async for chunk in graph.astream(state, stream_mode=["custom", "updates", "messages"]):
                # è¶…ç®€åŒ–ï¼šç›´æ¥å¤„ç†chunkè¾“å‡ºåˆ°ç»ˆç«¯
                if isinstance(chunk, tuple) and len(chunk) == 2 and chunk[0] == "custom":
                    data = chunk[1]
                    # ç®€å•è½¬æ¢
                    if data.get('message_type') == 'interrupt_request':
                        data['message_type'] = 'interrupt'
                    print(json.dumps(data, ensure_ascii=False))
                else:
                    # ä½¿ç”¨processorå¤„ç†å…¶ä»–æ ¼å¼
                    result = processor.process_chunk(chunk)
                    if 'flat_data' in result:
                        print(json.dumps(result['flat_data'], ensure_ascii=False))
        except KeyboardInterrupt:
            pass
    asyncio.run(_run())


if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆå™¨åç«¯æœåŠ¡...")
    print("ğŸ“Š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ”— å‰ç«¯åœ°å€: http://localhost:3000")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
