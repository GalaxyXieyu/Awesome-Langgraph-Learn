"""
å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
ä½¿ç”¨æ™ºèƒ½Supervisorè¿›è¡ŒåŠ¨æ€è°ƒåº¦å’Œåä½œç®¡ç†
æ”¯æŒå¼‚æ­¥æ‰§è¡Œå’Œæµå¼è¾“å‡º
"""



import json
import time
import asyncio
from typing import Dict, Any, List, TypedDict, Annotated, Optional, AsyncGenerator
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from agent.tools.tools import get_search_tools, get_analysis_tools, get_writing_tools
from agent.writer.writer import Collector, create_writer
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class MultiAgentState(TypedDict):
    """å¤šæ™ºèƒ½ä½“ç³»ç»ŸçŠ¶æ€"""
    messages: Annotated[List, add_messages]  # æ¶ˆæ¯å†å²
    user_input: str  # ç”¨æˆ·è¾“å…¥
    current_agent: str  # å½“å‰æ‰§è¡Œçš„Agent
    execution_path: List[str]  # æ‰§è¡Œè·¯å¾„è®°å½•
    agent_results: Dict[str, str]  # å„Agentæ‰§è¡Œç»“æœ
    final_result: str  # æœ€ç»ˆè¾“å‡ºç»“æœ
    iteration_count: int  # å½“å‰è¿­ä»£æ¬¡æ•°
    max_iterations: int  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    context: Dict[str, Any]  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    error_log: List[str]  # é”™è¯¯æ—¥å¿—è®°å½•
    supervisor_reasoning: str  # Supervisoræ¨ç†è¿‡ç¨‹
    next_action: str  # ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    task_completed: bool  # ä»»åŠ¡æ˜¯å¦å®Œæˆ

# ============================================================================
# LLMé…ç½®
# ============================================================================

def create_llm():
    """åˆ›å»ºLLMå®ä¾‹"""
    return ChatOpenAI(
        model="qwen2.5-72b-instruct-awq",
        temperature=0.7,
        base_url="https://llm.3qiao.vip:23436/v1",
        api_key="sk-0rnrrSH0OsiaWCiv6b37C1E4E60c4b9394325001Ec19A197",
    )

# ============================================================================
# ä¸“ä¸šåŒ–Agentåˆ›å»º
# ============================================================================

def create_agents():
    """åˆ›å»ºä¸“ä¸šåŒ–çš„agents"""
    llm = create_llm()
    
    # Search Agent - ä¸“é—¨è´Ÿè´£æœç´¢
    search_agent = create_react_agent(
        llm,
        tools=get_search_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·æœç´¢ä¿¡æ¯ã€‚

        ä½ çš„èƒ½åŠ›ï¼š
        - ä½¿ç”¨web_searchå·¥å…·è¿›è¡Œç½‘ç»œæœç´¢
        - åˆ†ææœç´¢ç»“æœçš„ç›¸å…³æ€§å’Œè´¨é‡
        - æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯æ‘˜è¦

        å·¥ä½œåŸåˆ™ï¼š
        1. ç†è§£ç”¨æˆ·çš„æœç´¢æ„å›¾
        2. é€‰æ‹©åˆé€‚çš„æœç´¢å…³é”®è¯
        3. åˆ†æå’Œç­›é€‰æœç´¢ç»“æœ
        4. æä¾›æ¸…æ™°ã€ç»“æ„åŒ–çš„ä¿¡æ¯æ‘˜è¦

        è¯·å§‹ç»ˆæä¾›é«˜è´¨é‡ã€ç›¸å…³çš„æœç´¢ç»“æœã€‚"""
            )
    
    # Writing Agent - ä¸“é—¨è´Ÿè´£å†™ä½œ
    writing_agent = create_react_agent(
        llm,
        tools=get_writing_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªå†™ä½œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·ç”Ÿæˆé«˜è´¨é‡çš„å†…å®¹ã€‚

        ä½ çš„èƒ½åŠ›ï¼š
        - ä½¿ç”¨content_writerå·¥å…·ç”Ÿæˆå„ç§é£æ ¼çš„å†…å®¹
        - æ ¹æ®ç”¨æˆ·éœ€æ±‚è°ƒæ•´å†™ä½œé£æ ¼å’Œé•¿åº¦
        - åˆ›ä½œç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥å¯†çš„æ–‡ç« 

        å·¥ä½œåŸåˆ™ï¼š
        1. ç†è§£ç”¨æˆ·çš„å†™ä½œéœ€æ±‚å’Œç›®æ ‡å—ä¼—
        2. é€‰æ‹©åˆé€‚çš„å†™ä½œé£æ ¼å’Œç»“æ„
        3. ç¡®ä¿å†…å®¹çš„å‡†ç¡®æ€§å’Œå¯è¯»æ€§
        4. æä¾›æœ‰ä»·å€¼ã€æœ‰æ·±åº¦çš„å†…å®¹

        è¯·å§‹ç»ˆåˆ›ä½œé«˜è´¨é‡ã€æœ‰ä»·å€¼çš„å†…å®¹ã€‚"""
            )
    
    # Analysis Agent - ä¸“é—¨è´Ÿè´£åˆ†æ
    analysis_agent = create_react_agent(
        llm,
        tools=get_analysis_tools(),
        prompt="""ä½ æ˜¯ä¸€ä¸ªåˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·åˆ†ææ•°æ®å’Œæ–‡æœ¬ã€‚

        ä½ çš„èƒ½åŠ›ï¼š
        - ä½¿ç”¨text_analyzerå·¥å…·è¿›è¡Œæ–‡æœ¬åˆ†æ
        - ä½¿ç”¨calculatorå·¥å…·è¿›è¡Œæ•°å­¦è®¡ç®—
        - æä¾›æ·±å…¥çš„åˆ†æè§è§£å’Œå»ºè®®

        å·¥ä½œåŸåˆ™ï¼š
        1. ä»”ç»†ç†è§£åˆ†æéœ€æ±‚
        2. é€‰æ‹©åˆé€‚çš„åˆ†ææ–¹æ³•å’Œå·¥å…·
        3. æä¾›å‡†ç¡®ã€å®¢è§‚çš„åˆ†æç»“æœ
        4. ç»™å‡ºæœ‰ä»·å€¼çš„å»ºè®®å’Œè§è§£

        è¯·å§‹ç»ˆæä¾›å‡†ç¡®ã€æœ‰æ·±åº¦çš„åˆ†æç»“æœã€‚"""
            )
    
    return {
        "search": search_agent,
        "writing": writing_agent,
        "analysis": analysis_agent
    }

# ============================================================================
# æ™ºèƒ½SupervisorèŠ‚ç‚¹
# ============================================================================

async def intelligent_supervisor_node(state: MultiAgentState, config=None) -> MultiAgentState:
    """æ™ºèƒ½SupervisorèŠ‚ç‚¹ - ä½¿ç”¨ç»Ÿä¸€çš„å¢å¼ºwriter"""
    # åˆ›å»ºwriter
    writer = create_writer("supervisor", "æ™ºèƒ½è°ƒåº¦å™¨")
    
    try:
        writer.step_start("å¼€å§‹æ™ºèƒ½è°ƒåº¦åˆ†æ")

        llm = create_llm()

        # æ„å»ºSupervisorçš„å†³ç­–æç¤º
        supervisor_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè°ƒåº¦å™¨ã€‚ä½ éœ€è¦åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œå†³å®šè°ƒç”¨å“ªä¸ªAgentæˆ–æ˜¯å¦ç»“æŸæµç¨‹ã€‚
            å¯ç”¨çš„Agentsï¼š
            1. search - æœç´¢ä¸“å®¶ï¼šè´Ÿè´£ç½‘ç»œæœç´¢ã€ä¿¡æ¯æ”¶é›†
            2. writing - å†™ä½œä¸“å®¶ï¼šè´Ÿè´£å†…å®¹ç”Ÿæˆã€æ–‡ç« å†™ä½œ
            3. analysis - åˆ†æä¸“å®¶ï¼šè´Ÿè´£æ–‡æœ¬åˆ†æã€æ•°æ®è®¡ç®—

            å†³ç­–è§„åˆ™ï¼š
            - å¦‚æœç”¨æˆ·éœ€è¦æœç´¢ä¿¡æ¯ã€æŸ¥æ‰¾èµ„æ–™ï¼Œé€‰æ‹© "search"
            - å¦‚æœç”¨æˆ·éœ€è¦è®¡ç®—ã€æ•°å­¦è¿ç®—ã€æ•°æ®åˆ†æï¼Œé€‰æ‹© "analysis"
            - å¦‚æœç”¨æˆ·éœ€è¦å†™ä½œã€ç”Ÿæˆå†…å®¹ã€åˆ›ä½œæ–‡ç« ï¼Œé€‰æ‹© "writing"
            - å¦‚æœå·²ç»æœ‰è¶³å¤Ÿçš„ç»“æœï¼Œé€‰æ‹© "finish"

            è¯·åªè¿”å›ä¸€ä¸ªè¯ä½œä¸ºå†³ç­–ç»“æœï¼Œä¸è¦è¿”å›JSONæ ¼å¼ï¼š
            - search
            - analysis
            - writing
            - finish"""),
                        ("human", """
            ç”¨æˆ·è¾“å…¥ï¼š{user_input}
            å½“å‰æ‰§è¡Œè·¯å¾„ï¼š{execution_path}
            å·²æœ‰ç»“æœï¼š{agent_results}

            è¯·åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œåªè¿”å›ä¸€ä¸ªå†³ç­–è¯ï¼šsearchã€analysisã€writing æˆ– finish
            """)
                    ])

        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = {
            "user_input": state.get("user_input", ""),
            "execution_path": state.get("execution_path", []),
            "agent_results": state.get("agent_results", {}),
            "iteration_count": state.get("iteration_count", 0),
            "max_iterations": state.get("max_iterations", 5),
            "context": state.get("context", {})
        }

        writer.step_progress("æ­£åœ¨åˆ†æç”¨æˆ·éœ€æ±‚...", 30)

        # æµå¼è°ƒç”¨LLMè¿›è¡Œå†³ç­–
        full_response = ""
        chunk_count = 0

        async for chunk in llm.astream(supervisor_prompt.format_messages(**input_data), config=config):
            if chunk.content and isinstance(chunk.content, str):
                full_response += chunk.content
                chunk_count += 1
                
                # å‘é€AIæµå¼è¾“å‡º
                writer.ai_streaming(chunk.content, chunk_count)
                
                # æ¯5ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°
                if chunk_count % 5 == 0:
                    progress = min(80, 30 + (chunk_count // 5) * 10)
                    writer.step_progress(
                        "æ­£åœ¨åˆ†æå†³ç­–...", 
                        progress,
                        current_reasoning=full_response[:200] + "..." if len(full_response) > 200 else full_response
                    )

        writer.step_progress("è§£æå†³ç­–ç»“æœ...", 85)

        # è§£æLLMå“åº” - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥ä»å“åº”ä¸­æå–å…³é”®è¯
        content = full_response.lower().strip()

        # ç›´æ¥åŒ¹é…å†³ç­–è¯
        if "search" in content:
            next_action = "search"
            reasoning = "æ£€æµ‹åˆ°æœç´¢éœ€æ±‚"
        elif "analysis" in content:
            next_action = "analysis"
            reasoning = "æ£€æµ‹åˆ°åˆ†æéœ€æ±‚"
        elif "writing" in content:
            next_action = "writing"
            reasoning = "æ£€æµ‹åˆ°å†™ä½œéœ€æ±‚"
        elif "finish" in content:
            next_action = "finish"
            reasoning = "ä»»åŠ¡å®Œæˆ"
        else:
            # åŸºäºç”¨æˆ·è¾“å…¥çš„æ™ºèƒ½åˆ¤æ–­
            user_input_lower = state.get("user_input", "").lower()
            if any(keyword in user_input_lower for keyword in ["æœç´¢", "æŸ¥æ‰¾", "search", "find", "ä»€ä¹ˆæ˜¯", "ä»‹ç»"]):
                next_action = "search"
                reasoning = "ç”¨æˆ·éœ€è¦æœç´¢ä¿¡æ¯"
            elif any(keyword in user_input_lower for keyword in ["è®¡ç®—", "åˆ†æ", "ç»Ÿè®¡", "æ•°æ®", "æƒ…æ„Ÿ", "calculate", "analyze"]):
                next_action = "analysis"
                reasoning = "ç”¨æˆ·éœ€è¦åˆ†æè®¡ç®—"
            elif any(keyword in user_input_lower for keyword in ["å†™", "ç”Ÿæˆ", "åˆ›ä½œ", "æ–‡ç« ", "write", "generate"]):
                next_action = "writing"
                reasoning = "ç”¨æˆ·éœ€è¦å†™ä½œç”Ÿæˆ"
            else:
                next_action = "analysis"  # é»˜è®¤ä½¿ç”¨åˆ†æ
                reasoning = "é»˜è®¤ä½¿ç”¨åˆ†æå¤„ç†"

        # æ›´æ–°çŠ¶æ€
        state["next_action"] = next_action
        state["supervisor_reasoning"] = reasoning
        state["execution_path"] = state.get("execution_path", []) + ["supervisor"]

        # æ·»åŠ Supervisorçš„åˆ†ææ¶ˆæ¯
        supervisor_message = f"""
        ğŸ§  æ™ºèƒ½è°ƒåº¦åˆ†æï¼š
        - å†³ç­–ï¼š{next_action}
        - ç†ç”±ï¼š{reasoning}
        - ç”¨æˆ·è¾“å…¥ï¼š{state.get('user_input', '')[:50]}...
        """

        state["messages"] = state.get("messages", []) + [
            AIMessage(content=supervisor_message)
        ]

        # å‘é€AIå®Œæˆæ¶ˆæ¯
        writer.ai_complete(supervisor_message)
        
        # å‘é€æ­¥éª¤å®Œæˆ
        writer.step_complete(
            "æ™ºèƒ½è°ƒåº¦åˆ†æå®Œæˆ",
            decision=next_action,
            reasoning=reasoning,
            confidence=0.8
        )

        logger.info(f"Supervisorå†³ç­–: {next_action} - {reasoning}")

        return state

    except Exception as e:
        logger.error(f"Supervisorå†³ç­–å¤±è´¥: {str(e)}")
        writer.error(f"å†³ç­–å¤±è´¥: {str(e)}", "SupervisorError")
        # é”™è¯¯å¤„ç†ï¼šé»˜è®¤ç»“æŸæµç¨‹
        state["next_action"] = "finish"
        state["supervisor_reasoning"] = f"å†³ç­–å¤±è´¥ï¼š{str(e)}"
        state["error_log"] = state.get("error_log", []) + [f"Supervisoré”™è¯¯: {str(e)}"]
        return state

# ============================================================================
# Agentæ‰§è¡ŒèŠ‚ç‚¹
# ============================================================================

async def agent_execution_node(state: MultiAgentState) -> MultiAgentState:
    """æ‰§è¡Œé€‰å®šçš„agentï¼ˆå¢å¼ºwriterç‰ˆæœ¬ï¼‰"""
    next_action = state.get("next_action")
    user_input = state.get("user_input", "")

    if next_action not in ["search", "writing", "analysis"]:
        return state

    # åˆ›å»ºwriter
    writer = create_writer(f"{next_action}_agent", f"{next_action.title()} Agent")
    
    try:
        writer.step_start(f"å¼€å§‹æ‰§è¡Œ{next_action}ä»»åŠ¡")

        # åˆ›å»ºagents
        agents = create_agents()
        agent = agents[next_action]

        # æ„å»ºAgentè¾“å…¥æ¶ˆæ¯
        context_info = ""
        if state.get("agent_results"):
            context_info = f"\n\nå·²æœ‰ä¿¡æ¯ï¼š\n{json.dumps(state['agent_results'], ensure_ascii=False, indent=2)}"

        agent_input = f"{user_input}{context_info}"

        writer.step_progress(f"æ­£åœ¨æ‰§è¡Œ{next_action}ä»»åŠ¡...", 20)

        # æ­£ç¡®çš„ Agent æµå¼æ‰§è¡Œ
        start_time = time.time()

        # æ­£ç¡®çš„ Agent è¾“å…¥æ ¼å¼
        agent_input_dict = {"messages": [HumanMessage(content=agent_input)]}

        # ä½¿ç”¨ Agent çš„æ­£å¸¸æ‰§è¡Œï¼Œä½†ç›‘æ§è¿›åº¦
        writer.step_progress(f"Agentå¼€å§‹æ‰§è¡Œ{next_action}ä»»åŠ¡...", 30)
        # Agent æ‰§è¡Œï¼ˆä½¿ç”¨æµå¼å¤„ç†ï¼‰
        collector = Collector(writer)
        full_response = await collector.process_agent_stream(
            agent.astream(agent_input_dict, stream_mode=["updates","messages"]),
            next_action
        )

        execution_time = time.time() - start_time

        writer.step_progress("Agentæ‰§è¡Œå®Œæˆ", 90)

        writer.step_progress("å¤„ç†æ‰§è¡Œç»“æœ...", 95)

        # ä½¿ç”¨æµå¼è¾“å‡ºçš„ç»“æœ
        result_text = full_response.strip() if full_response.strip() else "Agentæ‰§è¡Œå®Œæˆ"

        # æ›´æ–°çŠ¶æ€
        state["current_agent"] = next_action
        state["agent_results"] = state.get("agent_results", {})
        state["agent_results"][next_action] = result_text
        state["execution_path"] = state.get("execution_path", []) + [next_action]
        state["iteration_count"] = state.get("iteration_count", 0) + 1

        # æ·»åŠ æ‰§è¡Œç»“æœæ¶ˆæ¯
        execution_message = f"""
            ğŸ¤– {next_action.title()} Agent æ‰§è¡Œå®Œæˆï¼š
            â±ï¸ æ‰§è¡Œæ—¶é—´ï¼š{execution_time:.2f}ç§’
            ğŸ“Š ç»“æœï¼š{result_text[:300]}{'...' if len(result_text) > 300 else ''}
            """

        state["messages"] = state.get("messages", []) + [
            AIMessage(content=execution_message)
        ]

        writer.step_complete(
            f"{next_action}ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            execution_time=execution_time,
            result_preview=result_text[:200] + "..." if len(result_text) > 200 else result_text,
            result_length=len(result_text)
        )

        logger.info(f"{next_action} Agentæ‰§è¡Œå®Œæˆï¼Œè€—æ—¶{execution_time:.2f}ç§’")

        return state

    except Exception as e:
        logger.error(f"Agentæ‰§è¡Œå¤±è´¥: {str(e)}")
        next_action = state.get("next_action", "unknown")
        error_msg = f"{next_action} Agentæ‰§è¡Œå¤±è´¥ï¼š{str(e)}"

        writer.error(f"{next_action} Agentæ‰§è¡Œå¤±è´¥: {str(e)}", "AgentExecutionError")

        state["error_log"] = state.get("error_log", []) + [error_msg]
        state["messages"] = state.get("messages", []) + [
            AIMessage(content=f"âŒ {error_msg}")
        ]
        return state

# ============================================================================
# ç»“æœæ•´åˆèŠ‚ç‚¹
# ============================================================================

async def result_integration_node(state: MultiAgentState, config=None) -> MultiAgentState:
    """ç»“æœæ•´åˆèŠ‚ç‚¹ - æ•´åˆæ‰€æœ‰Agentçš„ç»“æœï¼ˆå¢å¼ºwriterç‰ˆæœ¬ï¼‰"""
    # åˆ›å»ºå¢å¼ºwriter
    writer = create_writer("result_integration", "ç»“æœæ•´åˆå™¨")
    
    try:
        writer.step_start("å¼€å§‹ç»“æœæ•´åˆ")

        llm = create_llm()

        # æ„å»ºç»“æœæ•´åˆæç¤º
        integration_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªç»“æœæ•´åˆä¸“å®¶ã€‚è¯·å°†å¤šä¸ªAgentçš„æ‰§è¡Œç»“æœæ•´åˆæˆä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„æœ€ç»ˆç­”æ¡ˆã€‚
            æ•´åˆåŸåˆ™ï¼š
            1. ä¿æŒä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
            2. ç¡®ä¿é€»è¾‘æ¸…æ™°ã€ç»“æ„åˆç†
            3. å»é™¤é‡å¤ä¿¡æ¯ï¼Œçªå‡ºå…³é”®å†…å®¹
            4. æä¾›æœ‰ä»·å€¼çš„ç»¼åˆè§è§£

            è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€ä¸“ä¸šçš„æœ€ç»ˆå›ç­”ã€‚"""),
                        ("human", """
            ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{user_input}

            å„Agentæ‰§è¡Œç»“æœï¼š
            {agent_results}

            æ‰§è¡Œè·¯å¾„ï¼š{execution_path}

            è¯·æ•´åˆä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
            """)
        ])

        # å‡†å¤‡æ•´åˆæ•°æ®
        agent_results = state.get("agent_results", {})
        agent_results_text = "\n\n".join([
            f"**{agent.title()} Agentç»“æœï¼š**\n{result}"
            for agent, result in agent_results.items()
        ])

        integration_data = {
            "user_input": state.get("user_input", ""),
            "agent_results": agent_results_text,
            "execution_path": " â†’ ".join(state.get("execution_path", []))
        }

        writer.step_progress("æ­£åœ¨æ•´åˆç»“æœ...", 20)

        # æµå¼è°ƒç”¨LLMè¿›è¡Œç»“æœæ•´åˆ
        final_result = ""
        chunk_count = 0

        async for chunk in llm.astream(integration_prompt.format_messages(**integration_data), config=config):
            if chunk.content and isinstance(chunk.content, str):
                final_result += chunk.content
                chunk_count += 1
                
                # å‘é€AIæµå¼è¾“å‡º
                writer.ai_streaming(chunk.content, chunk_count)
                
                # æ¯5ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°
                if chunk_count % 5 == 0:
                    progress = min(90, 20 + (chunk_count // 5) * 10)
                    writer.step_progress(
                        "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç»“æœ...",
                        progress,
                        current_content=final_result[:300] + "..." if len(final_result) > 300 else final_result,
                        total_chars=len(final_result)
                    )

        # æ›´æ–°çŠ¶æ€
        state["final_result"] = final_result
        state["task_completed"] = True

        # æ·»åŠ æœ€ç»ˆç»“æœæ¶ˆæ¯
        final_message = f"""
            ğŸ¯ æœ€ç»ˆæ•´åˆç»“æœï¼š

            {final_result}

            ---
            ğŸ“ˆ æ‰§è¡Œæ‘˜è¦ï¼š
            - æ‰§è¡Œè·¯å¾„ï¼š{' â†’ '.join(state.get('execution_path', []))}
            - è¿­ä»£æ¬¡æ•°ï¼š{state.get('iteration_count', 0)}
            - å‚ä¸Agentï¼š{', '.join(agent_results.keys())}
        """

        state["messages"] = state.get("messages", []) + [
            AIMessage(content=final_message)
        ]

        # å‘é€æœ€ç»ˆç»“æœ
        execution_summary = {
            "execution_path": state.get('execution_path', []),
            "iteration_count": state.get('iteration_count', 0),
            "agents_used": list(agent_results.keys())
        }
        
        writer.final_result(final_result, execution_summary)
        
        writer.step_complete(
            "ç»“æœæ•´åˆå®Œæˆ",
            final_result_length=len(final_result),
            execution_summary=execution_summary
        )

        logger.info("ç»“æœæ•´åˆå®Œæˆ")

        return state

    except Exception as e:
        logger.error(f"ç»“æœæ•´åˆå¤±è´¥: {str(e)}")
        writer.error(f"ç»“æœæ•´åˆå¤±è´¥: {str(e)}", "ResultIntegrationError")

        # ä½¿ç”¨ç®€å•çš„ç»“æœæ•´åˆä½œä¸ºåå¤‡
        agent_results = state.get("agent_results", {})
        if agent_results:
            final_result = "\n\n".join([
                f"**{agent.title()}ç»“æœï¼š**\n{result}"
                for agent, result in agent_results.items()
            ])
        else:
            final_result = "æŠ±æ­‰ï¼Œæ²¡æœ‰è·å¾—æœ‰æ•ˆçš„æ‰§è¡Œç»“æœã€‚"

        state["final_result"] = final_result
        state["task_completed"] = True
        state["error_log"] = state.get("error_log", []) + [f"ç»“æœæ•´åˆé”™è¯¯: {str(e)}"]
        return state

# ============================================================================
# è·¯ç”±å‡½æ•°
# ============================================================================

def route_after_supervisor(state: MultiAgentState) -> str:
    """Supervisorå†³ç­–åçš„è·¯ç”±"""
    next_action = state.get("next_action", "finish")

    if next_action in ["search", "writing", "analysis"]:
        return "agent_execution"
    else:
        return "result_integration"

def route_after_agent_execution(state: MultiAgentState) -> str:
    """Agentæ‰§è¡Œåçš„è·¯ç”±"""
    iteration_count = state.get("iteration_count", 0)
    max_iterations = state.get("max_iterations", 5)

    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç›´æ¥è¿›è¡Œç»“æœæ•´åˆ
    if iteration_count >= max_iterations:
        return "result_integration"

    # ç»§ç»­è®©Supervisorå†³ç­–ä¸‹ä¸€æ­¥
    return "supervisor"



def should_end(state: MultiAgentState) -> str:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸ"""
    if state.get("task_completed", False):
        return END
    else:
        return "supervisor"

# ============================================================================
# å›¾æ„å»º
# ============================================================================

def create_multi_agent_graph():
    """åˆ›å»ºå¤šæ™ºèƒ½ä½“å·¥ä½œæµå›¾ï¼ŒLangGraph Studioä¼šè‡ªåŠ¨å¤„ç†æŒä¹…åŒ–"""
    workflow = StateGraph(MultiAgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("supervisor", intelligent_supervisor_node)
    workflow.add_node("agent_execution", agent_execution_node)
    workflow.add_node("result_integration", result_integration_node)

    # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
    workflow.add_edge(START, "supervisor") 

    # æ·»åŠ æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "supervisor",
        route_after_supervisor,
        {
            "agent_execution": "agent_execution",
            "result_integration": "result_integration"
        }
    )

    workflow.add_conditional_edges(
        "agent_execution",
        route_after_agent_execution,
        {
            "supervisor": "supervisor",
            "result_integration": "result_integration"
        }
    )

    # ç»“æœæ•´åˆåç»“æŸ
    workflow.add_edge("result_integration", END)

    # ç¼–è¯‘å›¾ï¼Œä¸ä½¿ç”¨è‡ªå®šä¹‰checkpointerï¼ˆLangGraph Studioä¼šè‡ªåŠ¨å¤„ç†ï¼‰
    app = workflow.compile()

    return app

# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

async def run_multi_agent_system_async(
    user_input: str,
    max_iterations: int = 5,
    context: Optional[Dict[str, Any]] = None,
    thread_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    å¼‚æ­¥è¿è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        thread_id: çº¿ç¨‹IDï¼Œç”¨äºä¼šè¯æŒä¹…åŒ–

    Returns:
        æ‰§è¡Œç»“æœ
    """
    try:
        # åˆ›å»ºå›¾ï¼ˆä¸ä½¿ç”¨checkpointerï¼ŒLangGraph Studioä¼šè‡ªåŠ¨å¤„ç†ï¼‰
        app = create_multi_agent_graph()

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_input": user_input,
            "current_agent": "",
            "execution_path": [],
            "agent_results": {},
            "final_result": "",
            "iteration_count": 0,
            "max_iterations": max_iterations,
            "context": context or {},
            "error_log": [],
            "supervisor_reasoning": "",
            "next_action": "",
            "task_completed": False
        }

        # é…ç½®ï¼ˆå¦‚æœéœ€è¦thread_idï¼‰
        config = {"configurable": {"thread_id": thread_id or f"thread_{int(time.time())}"}} if thread_id else {}

        # å¼‚æ­¥è¿è¡Œå·¥ä½œæµ
        start_time = time.time()
        result = await app.ainvoke(initial_state, config=config if config else None)
        execution_time = time.time() - start_time

        # æ„å»ºè¿”å›ç»“æœ
        return {
            "success": True,
            "user_input": user_input,
            "final_result": result.get("final_result", ""),
            "execution_path": result.get("execution_path", []),

            "execution_time": execution_time,
            "agent_results": result.get("agent_results", {}),
            "iteration_count": result.get("iteration_count", 0),
            "error_log": result.get("error_log", []),
            "metadata": {
                "total_iterations": result.get("iteration_count", 0),
                "max_iterations": max_iterations,
                "supervisor_reasoning": result.get("supervisor_reasoning", ""),
                "messages_count": len(result.get("messages", []))
            }
        }

    except Exception as e:
        logger.error(f"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error_type": "SystemExecutionError",
            "error_message": str(e),
            "user_input": user_input,
            "partial_results": {}
        }

async def stream_multi_agent_system(
    user_input: str,
    max_iterations: int = 5,
    context: Optional[Dict[str, Any]] = None,
    thread_id: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    å¼‚æ­¥æµå¼è¿è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        thread_id: çº¿ç¨‹IDï¼Œç”¨äºä¼šè¯æŒä¹…åŒ–

    Yields:
        æµå¼æ‰§è¡Œç»“æœ
    """
    try:
        # åˆ›å»ºå›¾ï¼ˆä¸ä½¿ç”¨checkpointerï¼ŒLangGraph Studioä¼šè‡ªåŠ¨å¤„ç†ï¼‰
        app = create_multi_agent_graph()

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_input": user_input,
            "current_agent": "",
            "execution_path": [],
            "agent_results": {},
            "final_result": "",

            "iteration_count": 0,
            "max_iterations": max_iterations,
            "context": context or {},
            "error_log": [],
            "supervisor_reasoning": "",
            "next_action": "",
            "task_completed": False
        }

        # é…ç½®ï¼ˆå¦‚æœéœ€è¦thread_idï¼‰
        config = {"configurable": {"thread_id": thread_id or f"thread_{int(time.time())}"}} if thread_id else {}

        # å¼‚æ­¥æµå¼æ‰§è¡Œ
        start_time = time.time()
        async for chunk in app.astream(initial_state, config=config if config else None):
            # è®¡ç®—å½“å‰æ‰§è¡Œæ—¶é—´
            current_time = time.time() - start_time

            # æ„å»ºæµå¼è¾“å‡º
            stream_chunk = {
                "type": "chunk",
                "timestamp": time.time(),
                "execution_time": current_time,
                "chunk_data": chunk
            }

            # å¦‚æœæ˜¯æœ€ç»ˆç»“æœï¼Œæ·»åŠ å®Œæ•´æ‘˜è¦
            if any("final_result" in node_data for node_data in chunk.values() if isinstance(node_data, dict)):
                stream_chunk["type"] = "final"
                stream_chunk["summary"] = {
                    "total_execution_time": current_time,
                    "user_input": user_input
                }

            yield stream_chunk

    except Exception as e:
        logger.error(f"æµå¼æ‰§è¡Œå¤±è´¥: {str(e)}")
        yield {
            "type": "error",
            "timestamp": time.time(),
            "error_type": "StreamExecutionError",
            "error_message": str(e),
            "user_input": user_input
        }

def run_multi_agent_system(
    user_input: str,
    max_iterations: int = 5,
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    åŒæ­¥è¿è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯

    Returns:
        æ‰§è¡Œç»“æœ
    """
    return asyncio.run(run_multi_agent_system_async(user_input, max_iterations, context))

# å¯¼å‡ºç»™LangGraph Studioä½¿ç”¨çš„graphå®ä¾‹
graph = create_multi_agent_graph()

if __name__ == "__main__":
    result = run_multi_agent_system("è®¡ç®— 2+3*4 çš„ç»“æœ", max_iterations=2)
    if result["success"]:
        print(f"âœ… åŒæ­¥æ‰§è¡ŒæˆåŠŸ: {result['final_result'][:100]}...")
    else:
        print(f"âŒ åŒæ­¥æ‰§è¡Œå¤±è´¥: {result['error_message']}")
