# Dataset æ•è·è£…é¥°å™¨ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`@capture_dataset` è£…é¥°å™¨å¯ä»¥è‡ªåŠ¨æ•è· LLM èŠ‚ç‚¹çš„è¾“å…¥å‚æ•°ï¼Œå¹¶é€‰æ‹©æ€§åœ°æ¨é€åˆ° LangSmith Datasetã€‚

## æ ¸å¿ƒå‚æ•°

```python
@capture_dataset(
    prompt_name: str,           # æç¤ºè¯åç§°
    dataset_name: str,          # Dataset åç§°ï¼ˆæ¨èä¸ prompt_name ç›¸åŒï¼‰
    capture_output: bool = True,  # æ˜¯å¦æ•è·è¾“å‡º
    auto_sync: bool = True      # ğŸ”‘ æ˜¯å¦è‡ªåŠ¨æ¨é€åˆ° LangSmith
)
```

### auto_sync å‚æ•°è¯¦è§£

| å€¼ | è¡Œä¸º | é€‚ç”¨åœºæ™¯ |
|----|------|---------|
| `True` (é»˜è®¤) | è¿è¡Œå**ç«‹å³æ¨é€**åˆ° LangSmith | æ—¥å¸¸å¼€å‘ã€å¿«é€Ÿè¿­ä»£ |
| `False` | åªä¿å­˜åˆ°æœ¬åœ° `.dataset_cache/` | ç¦»çº¿å¼€å‘ã€æ‰¹é‡æ”¶é›†åç»Ÿä¸€æ¨é€ |

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1ï¼šè‡ªåŠ¨æ¨é€ï¼ˆæ¨èï¼‰

```python
from tools.capture import capture_dataset, capture_inputs

@traceable
@capture_dataset(
    prompt_name="report_generator",
    dataset_name="report_generator",
    auto_sync=True  # é»˜è®¤å€¼ï¼Œå¯çœç•¥
)
def generate_report_node(self, state: ReportState):
    # å‡†å¤‡ LLM è¾“å…¥å‚æ•°
    inputs = {
        "topic": state.get("topic", ""),
        "year_range": state.get("year_range", ""),
        "style": state.get("style", "formal"),
        "depth": state.get("depth", "medium"),
        "focus_areas": state.get("focus_areas", ""),
        "search_results": state.get("search_results_formatted", "")
    }
    
    # æ˜¾å¼æ ‡è®°æ•è·ï¼ˆæ¨èï¼‰
    capture_inputs(inputs, metadata={"user_query": state.get("user_query")})
    
    # è°ƒç”¨ LLM
    chain = prompt | self.llm | StrOutputParser()
    report = chain.invoke(inputs)
    
    return {"report": report}
```

**æ•ˆæœ**ï¼š
- âœ… æ•°æ®ä¿å­˜åˆ°æœ¬åœ°ï¼š`.dataset_cache/report_generator/run_xxx.json`
- âœ… **ç«‹å³æ¨é€åˆ° LangSmith**ï¼š`report_generator` Dataset
- âœ… æ— éœ€æ‰‹åŠ¨è¿è¡Œ `dataset_sync.py`

### æ–¹å¼ 2ï¼šä»…æœ¬åœ°ä¿å­˜

```python
@traceable
@capture_dataset(
    prompt_name="report_generator",
    dataset_name="report_generator",
    auto_sync=False  # å…³é—­è‡ªåŠ¨æ¨é€
)
def generate_report_node(self, state: ReportState):
    inputs = {...}
    capture_inputs(inputs)
    ...
```

**æ•ˆæœ**ï¼š
- âœ… æ•°æ®ä¿å­˜åˆ°æœ¬åœ°ï¼š`.dataset_cache/report_generator/run_xxx.json`
- âŒ ä¸æ¨é€åˆ° LangSmith
- ğŸ“Œ éœ€è¦æ—¶æ‰‹åŠ¨è¿è¡Œï¼š`python tools/dataset_sync.py`

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šä¸¤ä¸ªèŠ‚ç‚¹ï¼Œéƒ½è‡ªåŠ¨æ¨é€

```python
class ReportNodes:
    def __init__(self):
        self.llm = AzureConfig.get_llm()
        self.fast_llm = AzureConfig.get_fast_llm()
        self.prompt_manager = PromptManager()
    
    @traceable
    @capture_dataset(
        prompt_name="parameter_parser",
        dataset_name="parameter_parser"  # auto_sync=True é»˜è®¤
    )
    def parse_parameters_node(self, state):
        inputs = {"user_query": state.get("user_query", "")}
        capture_inputs(inputs)
        
        prompt = self.prompt_manager.create_chat_prompt(...)
        response = self.fast_llm.invoke(prompt.format_messages(**inputs))
        ...
    
    @traceable
    @capture_dataset(
        prompt_name="report_generator",
        dataset_name="report_generator"  # auto_sync=True é»˜è®¤
    )
    def generate_report_node(self, state):
        inputs = {
            "topic": state.get("topic", ""),
            "style": state.get("style", "formal"),
            ...
        }
        capture_inputs(inputs, metadata={"user_query": state.get("user_query")})
        
        chain = prompt | self.llm | StrOutputParser()
        report = chain.invoke(inputs)
        ...
```

**è¿è¡Œä¸€æ¬¡æµç¨‹**ï¼š
```bash
python main.py --query "ç”ŸæˆAIè¡Œä¸šæŠ¥å‘Š"
```

**è‡ªåŠ¨åˆ›å»ºä¸¤ä¸ª Dataset**ï¼š
- âœ… `parameter_parser` Datasetï¼ˆåŒ…å« `user_query` å‚æ•°ï¼‰
- âœ… `report_generator` Datasetï¼ˆåŒ…å« `topic`, `style` ç­‰å‚æ•°ï¼‰

### ç¤ºä¾‹ 2ï¼šæ··åˆæ¨¡å¼

```python
# parameter_parser: è‡ªåŠ¨æ¨é€
@capture_dataset(
    prompt_name="parameter_parser",
    dataset_name="parameter_parser",
    auto_sync=True
)
def parse_parameters_node(self, state):
    ...

# report_generator: ä»…æœ¬åœ°ä¿å­˜
@capture_dataset(
    prompt_name="report_generator",
    dataset_name="report_generator",
    auto_sync=False  # å…ˆæ”¶é›†ï¼Œç¨åæ‰¹é‡æ¨é€
)
def generate_report_node(self, state):
    ...
```

**åœºæ™¯**ï¼š
- `parameter_parser` æ•°æ®å°‘ä¸”é‡è¦ï¼Œç«‹å³æ¨é€
- `report_generator` æ•°æ®å¤šï¼Œå…ˆæœ¬åœ°æ”¶é›†ï¼Œæµ‹è¯•å®Œå†æ¨é€

## å·¥ä½œæµç¨‹

### è‡ªåŠ¨æ¨é€æ¨¡å¼ï¼ˆauto_sync=Trueï¼‰

```
è¿è¡Œæµç¨‹
  â†“
æ•è· inputs
  â†“
ä¿å­˜åˆ°æœ¬åœ° (.dataset_cache/)
  â†“
ç«‹å³æ¨é€åˆ° LangSmith âœ¨
  â†“
å®Œæˆ
```

**æ§åˆ¶å°è¾“å‡º**ï¼š
```
[Capture] å·²ä¿å­˜: parameter_parser â†’ run_20251027_143022.json
[Sync] å·²åŒæ­¥åˆ° LangSmith: parameter_parser
```

### æœ¬åœ°ä¿å­˜æ¨¡å¼ï¼ˆauto_sync=Falseï¼‰

```
è¿è¡Œæµç¨‹
  â†“
æ•è· inputs
  â†“
ä¿å­˜åˆ°æœ¬åœ° (.dataset_cache/)
  â†“
å®Œæˆï¼ˆæš‚ä¸æ¨é€ï¼‰
```

**ç¨åæ‰‹åŠ¨æ¨é€**ï¼š
```bash
python tools/dataset_sync.py
```

## åœ¨ Playground ä¸­ä½¿ç”¨

1. **è®¿é—® LangSmith**ï¼šhttps://smith.langchain.com/datasets

2. **é€‰æ‹© Dataset**ï¼š
   - `parameter_parser`ï¼ˆåŒ…å« `user_query`ï¼‰
   - `report_generator`ï¼ˆåŒ…å« `topic`, `style`, `depth` ç­‰ï¼‰

3. **æ‰“å¼€ Playground**ï¼š
   - é€‰æ‹©å¯¹åº”çš„æç¤ºè¯
   - ä» Dataset é€‰æ‹©ä¸€ä¸ª example
   - **åˆ‡æ¢æç¤ºè¯ç‰ˆæœ¬** â†’ inputs è‡ªåŠ¨åŒ¹é… âœ…

4. **å¯¹æ¯”ä¸åŒç‰ˆæœ¬**ï¼š
   - ä½¿ç”¨ç›¸åŒçš„æµ‹è¯•æ•°æ®
   - æµ‹è¯•ä¸åŒæç¤ºè¯ç‰ˆæœ¬çš„æ•ˆæœ
   - é€‰æ‹©æœ€ä¼˜ç‰ˆæœ¬

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **æ¯ä¸ªæç¤ºè¯ç‹¬ç«‹ Dataset**
   ```python
   # âœ… Good
   @capture_dataset(prompt_name="report_generator", dataset_name="report_generator")
   
   # âŒ Bad - ä¸åŒæç¤ºè¯å…±ç”¨åŒä¸€ä¸ª Dataset
   @capture_dataset(prompt_name="report_generator", dataset_name="shared_dataset")
   @capture_dataset(prompt_name="parameter_parser", dataset_name="shared_dataset")
   ```

2. **æ—¥å¸¸å¼€å‘ç”¨è‡ªåŠ¨æ¨é€**
   ```python
   # å¼€å‘é˜¶æ®µï¼šauto_sync=Trueï¼ˆé»˜è®¤ï¼‰
   @capture_dataset(prompt_name="xxx", dataset_name="xxx")
   ```

3. **æ˜¾å¼è°ƒç”¨ capture_inputs**
   ```python
   # âœ… æ¸…æ™°æ˜ç¡®
   inputs = {...}
   capture_inputs(inputs, metadata={...})
   chain.invoke(inputs)
   ```

4. **åˆç†ä½¿ç”¨ metadata**
   ```python
   capture_inputs(inputs, metadata={
       "user_query": state.get("user_query"),  # åŸå§‹æŸ¥è¯¢
       "prompt_version": prompt_config.get("version"),  # æç¤ºè¯ç‰ˆæœ¬
       "scenario": "production"  # åœºæ™¯æ ‡è®°
   })
   ```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **è‡ªåŠ¨æ¨é€ä¼šå¢åŠ å»¶è¿Ÿ**
   - æ¯æ¬¡æ•è·éƒ½ä¼šè°ƒç”¨ LangSmith API
   - é€šå¸¸å»¶è¿Ÿ < 100msï¼Œå¯æ¥å—

2. **ç½‘ç»œå¼‚å¸¸ä¸å½±å“ä¸»æµç¨‹**
   ```python
   # åŒæ­¥å¤±è´¥åªä¼šæ‰“å°è­¦å‘Šï¼Œä¸ä¼šä¸­æ–­æµç¨‹
   [WARN] è‡ªåŠ¨åŒæ­¥å¤±è´¥: Network error
   ```

3. **ç¦»çº¿å¼€å‘æ—¶å…³é—­è‡ªåŠ¨æ¨é€**
   ```python
   @capture_dataset(..., auto_sync=False)
   ```

## å¸¸è§åœºæ™¯

### åœºæ™¯ 1ï¼šå¿«é€Ÿè¿­ä»£æç¤ºè¯

```python
# è‡ªåŠ¨æ¨é€ï¼Œç«‹å³åœ¨ Playground æŸ¥çœ‹
@capture_dataset(prompt_name="xxx", dataset_name="xxx", auto_sync=True)
```

**æµç¨‹**ï¼š
1. ä¿®æ”¹æç¤ºè¯
2. è¿è¡Œæµ‹è¯•ï¼š`python main.py --query "æµ‹è¯•"`
3. ç«‹å³å» Playground æŸ¥çœ‹æ•ˆæœ
4. ç»§ç»­è¿­ä»£

### åœºæ™¯ 2ï¼šæ‰¹é‡æ”¶é›†æµ‹è¯•æ•°æ®

```python
# å…ˆæœ¬åœ°æ”¶é›†ï¼Œç»Ÿä¸€æ¨é€
@capture_dataset(prompt_name="xxx", dataset_name="xxx", auto_sync=False)
```

**æµç¨‹**ï¼š
1. è¿è¡Œå¤šæ¬¡æµ‹è¯•æ”¶é›†æ•°æ®ï¼š
   ```bash
   for i in {1..20}; do
     python main.py --query "æµ‹è¯•åœºæ™¯ $i"
   done
   ```

2. æŸ¥çœ‹æ•°æ®ï¼š
   ```bash
   python tools/dataset_sync.py --list
   ```

3. ç»Ÿä¸€æ¨é€ï¼š
   ```bash
   python tools/dataset_sync.py
   ```

### åœºæ™¯ 3ï¼šç”Ÿäº§ç¯å¢ƒå…³é—­æ•è·

```python
import os

# æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šæ˜¯å¦å¯ç”¨æ•è·
ENABLE_CAPTURE = os.getenv("ENABLE_DATASET_CAPTURE", "false").lower() == "true"

if ENABLE_CAPTURE:
    @capture_dataset(prompt_name="xxx", dataset_name="xxx")
    def my_node(self, state):
        ...
else:
    # ç”Ÿäº§ç¯å¢ƒä¸æ•è·
    @traceable
    def my_node(self, state):
        ...
```

## æ§åˆ¶å°è¾“å‡ºè¯´æ˜

### è‡ªåŠ¨æ¨é€æ¨¡å¼

```
[Capture] å·²ä¿å­˜: parameter_parser â†’ run_20251027_143022.json
[Sync] å·²åŒæ­¥åˆ° LangSmith: parameter_parser
```

### ä»…æœ¬åœ°æ¨¡å¼

```
[Capture] å·²ä¿å­˜: parameter_parser â†’ run_20251027_143022.json
```

### åŒæ­¥å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰

```
[Capture] å·²ä¿å­˜: parameter_parser â†’ run_20251027_143022.json
[WARN] è‡ªåŠ¨åŒæ­¥å¤±è´¥: Authentication failed
```

## æ•…éšœæ’æŸ¥

### Q: è‡ªåŠ¨æ¨é€å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**æ£€æŸ¥**ï¼š
1. `.env` æ–‡ä»¶ä¸­ `LANGSMITH_API_KEY` æ˜¯å¦æ­£ç¡®
2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
3. æŸ¥çœ‹é”™è¯¯ä¿¡æ¯ï¼š`[WARN] è‡ªåŠ¨åŒæ­¥å¤±è´¥: ...`

**ä¸´æ—¶æ–¹æ¡ˆ**ï¼š
```python
# æ”¹ä¸ºæœ¬åœ°ä¿å­˜
@capture_dataset(..., auto_sync=False)

# ç¨åæ‰‹åŠ¨æ¨é€
python tools/dataset_sync.py
```

### Q: å¦‚ä½•æŸ¥çœ‹æœ¬åœ°ç¼“å­˜ï¼Ÿ

```bash
# æŸ¥çœ‹ç¼“å­˜ç›®å½•
ls -la .dataset_cache/

# æŸ¥çœ‹å…·ä½“æ•°æ®
cat .dataset_cache/report_generator/run_xxx.json | python -m json.tool

# åˆ—å‡ºæ‰€æœ‰æ•è·
python tools/dataset_sync.py --list
```

### Q: å¦‚ä½•æ¸…ç†ç¼“å­˜ï¼Ÿ

```bash
# åˆ é™¤æ‰€æœ‰æœ¬åœ°ç¼“å­˜
rm -rf .dataset_cache/

# åªæ¸…ç†å·²åŒæ­¥çš„
python tools/dataset_sync.py --clean
```

## å‚æ•°é€ŸæŸ¥è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `prompt_name` | str | å¿…éœ€ | æç¤ºè¯åç§°ï¼ˆå¦‚ "report_generator"ï¼‰ |
| `dataset_name` | str | "default" | Dataset åç§°ï¼ˆæ¨èä¸ prompt_name ç›¸åŒï¼‰ |
| `capture_output` | bool | True | æ˜¯å¦æ•è·èŠ‚ç‚¹çš„è¾“å‡ºç»“æœ |
| `auto_sync` | bool | **True** | ğŸ”‘ **æ˜¯å¦è‡ªåŠ¨æ¨é€åˆ° LangSmith** |

## æ€»ç»“

### ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

- **è‡ªåŠ¨æ¨é€**ï¼šè¿è¡Œå³ä¸Šä¼ ï¼Œæ— éœ€æ‰‹åŠ¨åŒæ­¥
- **çµæ´»æ§åˆ¶**ï¼š`auto_sync` å‚æ•°éšæ—¶åˆ‡æ¢æ¨¡å¼
- **ä¸å½±å“ä¸»æµç¨‹**ï¼šåŒæ­¥å¤±è´¥ä¸ä¼šä¸­æ–­ç¨‹åº
- **åŒé‡ä¿é™©**ï¼šæœ¬åœ°+è¿œç¨‹éƒ½æœ‰å¤‡ä»½

### ğŸš€ æ¨èé…ç½®

**æ—¥å¸¸å¼€å‘**ï¼š
```python
@capture_dataset(prompt_name="xxx", dataset_name="xxx")  # auto_sync=True é»˜è®¤
```

**æ‰¹é‡æ”¶é›†**ï¼š
```python
@capture_dataset(prompt_name="xxx", dataset_name="xxx", auto_sync=False)
```

**ç”Ÿäº§ç¯å¢ƒ**ï¼šä¸ä½¿ç”¨è£…é¥°å™¨æˆ–è®¾ç½®ç¯å¢ƒå˜é‡æ§åˆ¶

