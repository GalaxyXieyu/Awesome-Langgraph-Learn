"""
åŸºäºRediså­˜å‚¨çš„LangGraphæ™ºèƒ½å†™ä½œåŠ©æ‰‹
å‚è€ƒInterative-Report-Workflowï¼Œå°†å†…å­˜å­˜å‚¨æ›¿æ¢ä¸ºRediså­˜å‚¨
"""

from typing import Dict, Any, List, Optional, TypedDict, Annotated
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.redis import RedisSaver
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
import logging
import time
from langgraph.config import get_stream_writer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç¡®è®¤èŠ‚ç‚¹é…ç½®
CONFIRMATION_CONFIGS = {
    "outline": {
        "type": "outline_confirmation",
        "message_template": "è¯·ç¡®è®¤ä»¥ä¸‹å¤§çº²æ˜¯å¦æ»¡æ„ï¼š\n\n{outline_text}",
        "instructions": "è¯·å›å¤ 'yes' ç¡®è®¤ç»§ç»­ï¼Œæˆ– 'no' é‡æ–°ç”Ÿæˆå¤§çº²",
        "state_key": "user_confirmation",
        "copilot_message": "Copilotæ¨¡å¼ï¼šè‡ªåŠ¨ç¡®è®¤å¤§çº²"
    },
    "search": {
        "type": "search_permission", 
        "message_template": "æ˜¯å¦å…è®¸ä¸ºä¸»é¢˜ã€Œ{topic}ã€è¿›è¡Œè”ç½‘æœç´¢ï¼Ÿ",
        "instructions": "è¯·å›å¤ 'yes' å…è®¸æœç´¢ï¼Œ'no' è·³è¿‡æœç´¢",
        "state_key": "search_permission",
        "copilot_message": "Copilotæ¨¡å¼ï¼šè‡ªåŠ¨å…è®¸è”ç½‘æœç´¢"
    }
}

# å®šä¹‰å¤§çº²æ•°æ®æ¨¡å‹
class OutlineSection(BaseModel):
    """å¤§çº²ç« èŠ‚æ¨¡å‹"""
    title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    description: str = Field(description="ç« èŠ‚æè¿°")
    key_points: List[str] = Field(description="ç« èŠ‚è¦ç‚¹åˆ—è¡¨")

class ArticleOutline(BaseModel):
    """æ–‡ç« å¤§çº²æ¨¡å‹"""
    title: str = Field(description="æ–‡ç« æ ‡é¢˜")
    sections: List[OutlineSection] = Field(description="ç« èŠ‚åˆ—è¡¨")

class WritingState(TypedDict):
    """å†™ä½œåŠ©æ‰‹çš„çŠ¶æ€å®šä¹‰"""
    # åŸºæœ¬ä¿¡æ¯
    topic: str  # æ–‡ç« ä¸»é¢˜
    user_id: str  # ç”¨æˆ·ID
    
    # é…ç½®å‚æ•°
    max_words: int  # æœ€å¤§å­—æ•°
    style: str  # å†™ä½œé£æ ¼
    language: str  # è¯­è¨€
    mode: str  # è¿è¡Œæ¨¡å¼ï¼šcopilotï¼ˆè‡ªåŠ¨é€šè¿‡æ‰€æœ‰ä¸­æ–­ï¼‰æˆ– interactiveï¼ˆäº¤äº’æ¨¡å¼ï¼‰
    
    # æ ¸å¿ƒå†…å®¹
    outline: Optional[Dict[str, Any]]  # æ–‡ç« å¤§çº²
    article: Optional[str]  # ç”Ÿæˆçš„æ–‡ç« 
    search_results: List[Dict[str, Any]]  # æœç´¢ç»“æœ
    
    # ç”¨æˆ·äº¤äº’
    user_confirmation: Optional[str]  # ç”¨æˆ·ç¡®è®¤ä¿¡æ¯
    search_permission: Optional[str]  # æœç´¢æƒé™ç¡®è®¤
    
    # æ¶ˆæ¯å†å²
    messages: Annotated[List, add_messages]  # å¯¹è¯æ¶ˆæ¯

def create_llm() -> ChatOpenAI:
    """åˆ›å»ºLLMå®ä¾‹"""
    return ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7
    )

async def generate_outline_node(state: WritingState, config=None) -> WritingState:
    """å¤§çº²ç”ŸæˆèŠ‚ç‚¹"""
    writer = get_stream_writer()
    writer({"step": "outline_generation", "status": "å¼€å§‹ç”Ÿæˆå¤§çº²", "progress": 0})

    parser = JsonOutputParser(pydantic_object=ArticleOutline)
    
    outline_prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡ç« å¤§çº²ã€‚
        è¦æ±‚ï¼š
        1. å¤§çº²åº”è¯¥åŒ…å«æ ‡é¢˜å’Œ3-6ä¸ªä¸»è¦ç« èŠ‚
        2. æ¯ä¸ªç« èŠ‚åº”è¯¥æœ‰æ¸…æ™°çš„ä¸»é¢˜å’Œç®€è¦è¯´æ˜
        3. æ•´ä½“ç»“æ„è¦é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
        4. é€‚åˆ{style}é£æ ¼çš„å†™ä½œ
        5. ä½¿ç”¨{language}è¯­è¨€

        {format_instructions}"""),
        ("human", "è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆæ–‡ç« å¤§çº²ï¼š{topic}")
    ])

    llm_chain = outline_prompt | create_llm() | parser
    
    writer({"step": "outline_generation", "status": "æ­£åœ¨ç”Ÿæˆå¤§çº²", "progress": 50})

    input_data = {
        "topic": state['topic'],
        "style": state.get("style", "formal"),
        "language": state.get("language", "zh"),
        "format_instructions": parser.get_format_instructions()
    }
    
    outline_data = None
    async for chunk in llm_chain.astream(input_data, config=config):
        outline_data = chunk
        
        writer({
            "step": "outline_generation", 
            "status": "æ­£åœ¨ç”Ÿæˆå¤§çº²...",
            "progress": 100,
            "current_content": chunk,
            "total_chars": 2,
            "chunk_count": 1
        })
    
    # å¦‚æœæ²¡æœ‰è·å¾—æœ‰æ•ˆç»“æœï¼Œåˆ›å»ºé»˜è®¤å¤§çº²
    if not outline_data:
        outline_data = {
            "title": f"{state['topic']}",
            "sections": [
                {"title": "å¼•è¨€", "description": "ä»‹ç»ä¸»é¢˜èƒŒæ™¯", "key_points": ["èƒŒæ™¯ä»‹ç»", "é‡è¦æ€§"]},
                {"title": "ä¸»è¦å†…å®¹", "description": "è¯¦ç»†é˜è¿°ä¸»é¢˜", "key_points": ["æ ¸å¿ƒè§‚ç‚¹", "å…·ä½“åˆ†æ"]},
                {"title": "ç»“è®º", "description": "æ€»ç»“è¦ç‚¹", "key_points": ["æ€»ç»“", "å±•æœ›"]}
            ]
        }

    # å¤„ç†è§£æç»“æœ
    if isinstance(outline_data, dict):
        outline = outline_data
    else:
        outline = {
            "title": outline_data.title,
            "sections": [
                {
                    "title": section.title,
                    "description": section.description,
                    "key_points": section.key_points
                }
                for section in outline_data.sections
            ]
        }

    writer({
        "step": "outline_generation",
        "status": "å¤§çº²ç”Ÿæˆå®Œæˆ",
        "progress": 100,
        "outline": outline
    })

    # æ›´æ–°çŠ¶æ€
    state["outline"] = outline
    state["messages"] = state.get("messages", []) + [
        AIMessage(content=f"å·²ç”Ÿæˆæ–‡ç« å¤§çº²ï¼š\næ ‡é¢˜ï¼š{outline['title']}\nç« èŠ‚æ•°ï¼š{len(outline['sections'])}")
    ]

    return state

def create_confirmation_node(config_key: str):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºç¡®è®¤èŠ‚ç‚¹"""
    config = CONFIRMATION_CONFIGS[config_key]
    
    def confirmation_node(state: WritingState) -> WritingState:
        from langgraph.types import interrupt
        
        mode = state.get("mode", "interactive")
        
        # copilotæ¨¡å¼è‡ªåŠ¨é€šè¿‡
        if mode == "copilot":
            state.update({
                config["state_key"]: "yes",
                "messages": state.get("messages", []) + [
                    AIMessage(content=config["copilot_message"])
                ]
            })
            return state
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        if config_key == "outline":
            # æ„å»ºå¤§çº²å±•ç¤ºæ–‡æœ¬
            outline = state.get("outline") or {}
            outline_text = f"æ–‡ç« æ ‡é¢˜ï¼š{outline.get('title', 'æœªçŸ¥')}\n\n"
            sections = outline.get("sections") or []
            for i, section in enumerate(sections, 1):
                outline_text += f"{i}. {section.get('title', 'æœªçŸ¥ç« èŠ‚')}\n"
                outline_text += f"   æè¿°ï¼š{section.get('description', 'æ— æè¿°')}\n"
                if section.get('key_points'):
                    outline_text += f"   è¦ç‚¹ï¼š{', '.join(section['key_points'])}\n"
                outline_text += "\n"
            message = config["message_template"].format(outline_text=outline_text)
        else:
            topic = state.get("topic", "")
            message = config["message_template"].format(topic=topic)
        
        # interactiveæ¨¡å¼éœ€è¦ç”¨æˆ·ç¡®è®¤
        user_response = interrupt({
            "type": config["type"],
            "message": message,
            "instructions": config["instructions"]
        })

        # å¤„ç†ç”¨æˆ·ç¡®è®¤ç»“æœ
        confirmation = user_response.lower().strip() if isinstance(user_response, str) else str(user_response).lower().strip()

        # æ›´æ–°çŠ¶æ€
        state.update({
            config["state_key"]: confirmation,
            "messages": state.get("messages", []) + [
                AIMessage(content=f"{config['type']}ç¡®è®¤ç»“æœ: {confirmation}")
            ]
        })

        return state
    
    return confirmation_node

# åˆ›å»ºç¡®è®¤èŠ‚ç‚¹å®ä¾‹
outline_confirmation_node = create_confirmation_node("outline")
search_confirmation_node = create_confirmation_node("search")

def simple_search_node(state: WritingState) -> WritingState:
    """ç®€åŒ–çš„æœç´¢èŠ‚ç‚¹"""
    writer = get_stream_writer()
    
    # æ£€æŸ¥æœç´¢æƒé™
    if state.get("search_permission") != "yes":
        writer({"step": "search_execution", "status": "è·³è¿‡æœç´¢", "progress": 100})
        state.update({"search_results": []})
        return state

    writer({"step": "search_execution", "status": "æ¨¡æ‹Ÿæœç´¢", "progress": 50})
    
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    topic = state.get("topic", "")
    mock_results = [
        {"title": f"{topic}ç›¸å…³èµ„æ–™1", "snippet": f"å…³äº{topic}çš„è¯¦ç»†ä»‹ç»...", "url": "https://example1.com"},
        {"title": f"{topic}ç›¸å…³èµ„æ–™2", "snippet": f"{topic}çš„åº”ç”¨æ¡ˆä¾‹...", "url": "https://example2.com"},
        {"title": f"{topic}ç›¸å…³èµ„æ–™3", "snippet": f"{topic}çš„å‘å±•è¶‹åŠ¿...", "url": "https://example3.com"}
    ]
    
    writer({"step": "search_execution", "status": "æœç´¢å®Œæˆ", "progress": 100})
    
    state.update({
        "search_results": mock_results,
        "messages": state.get("messages", []) + [
            AIMessage(content=f"æœç´¢å®Œæˆï¼Œè·å¾— {len(mock_results)} ä¸ªç›¸å…³èµ„æ–™ã€‚")
        ]
    })
    
    return state

async def article_generation_node(state: WritingState, config=None) -> WritingState:
    """æ–‡ç« ç”ŸæˆèŠ‚ç‚¹"""
    try:
        start_time = time.time()

        # åˆ›å»ºLLM
        llm = create_llm()

        # æ„å»ºæ–‡ç« ç”Ÿæˆæç¤º
        outline = state.get("outline") or {}
        outline_text = f"æ ‡é¢˜ï¼š{outline.get('title', '')}\n"

        sections = outline.get("sections") or []
        for i, section in enumerate(sections, 1):
            outline_text += f"{i}. {section.get('title', '')}\n"
            outline_text += f"   {section.get('description', '')}\n"
            if section.get('key_points'):
                outline_text += f"   è¦ç‚¹ï¼š{', '.join(section['key_points'])}\n"

        # æ·»åŠ æœç´¢ç»“æœåˆ°æç¤ºä¸­
        search_results = state.get("search_results", [])
        search_context = ""
        if search_results:
            search_context = "\n\nå‚è€ƒèµ„æ–™ï¼š\n"
            for i, result in enumerate(search_results[:3], 1):
                search_context += f"{i}. {result.get('title', '')}: {result.get('snippet', '')}\n"

        # æ„å»ºç”ŸæˆæŒ‡ä»¤
        generation_prompt = f"""
            è¯·æ ¹æ®ä»¥ä¸‹å¤§çº²ç”Ÿæˆä¸€ç¯‡å®Œæ•´çš„æ–‡ç« ï¼š

            {outline_text}

            {search_context}

            è¦æ±‚ï¼š
            1. æ–‡ç« é£æ ¼ï¼š{state.get('style', 'formal')}
            2. è¯­è¨€ï¼š{state.get('language', 'zh')}
            3. ç›®æ ‡å­—æ•°ï¼šçº¦{state.get('max_words', 1000)}å­—
            4. å†…å®¹è¦æ±‚ï¼šé€»è¾‘æ¸…æ™°ã€è®ºè¯å……åˆ†ã€è¯­è¨€æµç•…
            5. å¦‚æœæœ‰å‚è€ƒèµ„æ–™ï¼Œè¯·åˆç†å¼•ç”¨å’Œæ•´åˆ

            è¯·ç”Ÿæˆå®Œæ•´çš„æ–‡ç« å†…å®¹ã€‚
        """

        # è·å–æµå¼å†™å…¥å™¨
        writer = get_stream_writer()
        writer({"step": "article_generation", "status": "å¼€å§‹ç”Ÿæˆæ–‡ç« ", "progress": 0})

        # åˆ›å»ºæ¶ˆæ¯
        messages = [HumanMessage(content=generation_prompt)]

        # æµå¼ç”Ÿæˆæ–‡ç« 
        full_article = ""
        chunk_count = 0

        writer({"step": "article_generation", "status": "æ­£åœ¨ç”Ÿæˆæ–‡ç« ...", "progress": 10})

        async for chunk in llm.astream(messages, config=config):
            if chunk.content and isinstance(chunk.content, str):
                full_article += chunk.content
                chunk_count += 1

                # æ¯10ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°
                if chunk_count % 10 == 0:
                    progress = min(90, 10 + (chunk_count // 10) * 5)
                    writer({
                        "step": "article_generation",
                        "status": "æ­£åœ¨ç”Ÿæˆæ–‡ç« ...",
                        "progress": progress,
                        "current_content": full_article,
                        "total_chars": len(full_article),
                        "chunk_count": chunk_count
                    })

        # è®¡ç®—ç”Ÿæˆæ—¶é—´
        generation_time = time.time() - start_time

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        state.update({
            "article": full_article,
            "messages": state.get("messages", []) + [
                AIMessage(content=f"æ–‡ç« ç”Ÿæˆå®Œæˆï¼\nå­—æ•°ï¼š{len(full_article)}\nç”Ÿæˆæ—¶é—´ï¼š{generation_time:.1f}ç§’")
            ]
        })

        writer({
            "step": "article_generation",
            "status": "æ–‡ç« ç”Ÿæˆå®Œæˆ",
            "progress": 100,
            "current_content": full_article,
            "total_chars": len(full_article),
            "chunk_count": chunk_count
        })

        return state

    except Exception as e:
        logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}")
        state.update({
            "messages": state.get("messages", []) + [
                AIMessage(content=f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}")
            ]
        })
        return state

# è·¯ç”±å‡½æ•°
def route_after_confirmation(state: WritingState) -> str:
    """ç¡®è®¤åçš„è·¯ç”±é€»è¾‘"""
    user_confirmation = (state.get("user_confirmation") or "").lower().strip()

    if user_confirmation == "yes":
        return "search_confirmation"
    elif user_confirmation == "no":
        return "generate_outline"
    else:
        return "search_confirmation"

def route_after_search_confirmation(state: WritingState) -> str:
    """æœç´¢ç¡®è®¤åçš„è·¯ç”±é€»è¾‘"""
    search_permission = (state.get("search_permission") or "").lower().strip()

    if search_permission == "yes":
        return "search_execution"
    else:
        return "article_generation"

def should_continue_after_search(_: WritingState) -> str:
    """æœç´¢å®Œæˆåçš„è·¯ç”±é€»è¾‘"""
    return "article_generation"

def create_redis_writing_assistant_graph():
    """åˆ›å»ºåŸºäºRediså­˜å‚¨çš„æ™ºèƒ½å†™ä½œåŠ©æ‰‹å›¾"""
    workflow = StateGraph(WritingState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("generate_outline", generate_outline_node)
    workflow.add_node("outline_confirmation", outline_confirmation_node)
    workflow.add_node("search_confirmation", search_confirmation_node)
    workflow.add_node("search_execution", simple_search_node)
    workflow.add_node("article_generation", article_generation_node)

    # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
    workflow.add_edge(START, "generate_outline")

    # æ·»åŠ è¾¹
    workflow.add_edge("generate_outline", "outline_confirmation")

    # å¤§çº²ç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "outline_confirmation",
        route_after_confirmation,
        {
            "search_confirmation": "search_confirmation",
            "generate_outline": "generate_outline"
        }
    )

    # æœç´¢ç¡®è®¤åçš„æ¡ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "search_confirmation",
        route_after_search_confirmation,
        {
            "search_execution": "search_execution",
            "article_generation": "article_generation"
        }
    )

    # æœç´¢å®Œæˆåç›´æ¥ç”Ÿæˆæ–‡ç« 
    workflow.add_conditional_edges(
        "search_execution",
        should_continue_after_search,
        {
            "article_generation": "article_generation"
        }
    )

    # æ–‡ç« ç”Ÿæˆå®Œæˆåç»“æŸ
    workflow.add_edge("article_generation", END)

    # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨Rediså­˜å‚¨æ›¿ä»£å†…å­˜å­˜å‚¨
    redis_url = "redis://default:mfzstl2v@dbconn.sealoshzh.site:41277"
    checkpointer = RedisSaver.from_conn_string(redis_url)
    checkpointer.setup()

    print(f"âœ… ä½¿ç”¨Rediså­˜å‚¨: {redis_url}")

    # ç¼–è¯‘å›¾
    app = workflow.compile(checkpointer=checkpointer)

    return app

# ä¾¿æ·å‡½æ•°
def run_writing_assistant(topic: str, mode: str = "interactive", thread_id: str = "default"):
    """è¿è¡Œå†™ä½œåŠ©æ‰‹"""
    app = create_redis_writing_assistant_graph()

    # åˆå§‹çŠ¶æ€
    initial_state = {
        "topic": topic,
        "user_id": "demo_user",
        "max_words": 1000,
        "style": "formal",
        "language": "zh",
        "mode": mode,
        "outline": None,
        "article": None,
        "search_results": [],
        "user_confirmation": None,
        "search_permission": None,
        "messages": [HumanMessage(content=f"è¯·ä¸ºä¸»é¢˜ã€Œ{topic}ã€ç”Ÿæˆæ–‡ç« ")]
    }

    # é…ç½®
    config = {"configurable": {"thread_id": thread_id}}

    # è¿è¡Œ
    try:
        result = app.invoke(initial_state, config=config)
        return result
    except Exception as e:
        logger.error(f"è¿è¡Œå†™ä½œåŠ©æ‰‹å¤±è´¥: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    # æµ‹è¯•è¿è¡Œ
    print("ğŸš€ Rediså†™ä½œåŠ©æ‰‹æ¼”ç¤º")
    print("=" * 40)

    # åˆ›å»ºå›¾
    app = create_redis_writing_assistant_graph()

    # æµ‹è¯•çŠ¶æ€
    test_state = {
        "topic": "äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
        "user_id": "test_user",
        "max_words": 800,
        "style": "academic",
        "language": "zh",
        "mode": "copilot",  # è‡ªåŠ¨æ¨¡å¼ï¼Œä¸éœ€è¦ç”¨æˆ·äº¤äº’
        "messages": []
    }

    config = {"configurable": {"thread_id": "redis_test_001"}}

    try:
        print("å¼€å§‹ç”Ÿæˆæ–‡ç« ...")
        result = app.invoke(test_state, config=config)

        if "article" in result and result["article"]:
            print(f"\nâœ… æ–‡ç« ç”ŸæˆæˆåŠŸï¼")
            print(f"æ ‡é¢˜: {result.get('outline', {}).get('title', 'æœªçŸ¥')}")
            print(f"å­—æ•°: {len(result['article'])}")
            print(f"æ–‡ç« é¢„è§ˆ: {result['article'][:200]}...")
        else:
            print("âŒ æ–‡ç« ç”Ÿæˆå¤±è´¥")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
